{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f6482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "\n",
    "import boto3\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9c280",
   "metadata": {},
   "source": [
    "### Download Movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6eb865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-22 01:18:12--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "100%[======================================>] 978,202     3.68MB/s   in 0.3s   \n",
      "\n",
      "2024-05-22 01:18:13 (3.68 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d06f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_preprocessing.ipynb  ml-latest-small.zip  ratings.csv\r\n",
      "links.csv                 movies.csv           tags.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f733bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-latest-small.zip\r\n",
      "   creating: ml-latest-small/\r\n",
      "  inflating: ml-latest-small/links.csv  \r\n",
      "  inflating: ml-latest-small/tags.csv  \r\n",
      "  inflating: ml-latest-small/ratings.csv  \r\n",
      "  inflating: ml-latest-small/README.txt  \r\n",
      "  inflating: ml-latest-small/movies.csv  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3a626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(r'ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc33754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2986c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74734dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = df_movies.genres.map(lambda value: value.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a829d00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Adventure, Animation, Children, Comedy, Fantasy]\n",
       "1                       [Adventure, Children, Fantasy]\n",
       "2                                    [Comedy, Romance]\n",
       "3                             [Comedy, Drama, Romance]\n",
       "4                                             [Comedy]\n",
       "5                            [Action, Crime, Thriller]\n",
       "6                                    [Comedy, Romance]\n",
       "7                                [Adventure, Children]\n",
       "8                                             [Action]\n",
       "9                        [Action, Adventure, Thriller]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b25bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_genres (genre_list):\n",
    "    unique_list = set()\n",
    "    \n",
    "    for items in genre_list:\n",
    "        for item in items:\n",
    "            unique_list.add(item)\n",
    "    \n",
    "    return sorted(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fdc1508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(no genres listed)',\n",
       " 'Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Children',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'Horror',\n",
       " 'IMAX',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = get_unique_genres(genre_list)\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b96862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of genre for each movie\n",
    "df_genre = pd.DataFrame(index=range(df_movies.shape[0]),columns=genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a553d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15749/747498278.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_genre = df_genre.fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
       "0                   0       0          0          0         0       0      0   \n",
       "1                   0       0          0          0         0       0      0   \n",
       "2                   0       0          0          0         0       0      0   \n",
       "3                   0       0          0          0         0       0      0   \n",
       "4                   0       0          0          0         0       0      0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "0            0      0        0          0       0     0        0        0   \n",
       "1            0      0        0          0       0     0        0        0   \n",
       "2            0      0        0          0       0     0        0        0   \n",
       "3            0      0        0          0       0     0        0        0   \n",
       "4            0      0        0          0       0     0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         0    0        0  \n",
       "2        0       0         0    0        0  \n",
       "3        0       0         0    0        0  \n",
       "4        0       0         0    0        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genre = df_genre.fillna(0)\n",
    "df_genre.shape\n",
    "df_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bab6207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
       "0                   0       0          1          1         1       1      0   \n",
       "1                   0       0          1          0         1       0      0   \n",
       "2                   0       0          0          0         0       1      0   \n",
       "3                   0       0          0          0         0       1      0   \n",
       "4                   0       0          0          0         0       1      0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "0            0      0        1          0       0     0        0        0   \n",
       "1            0      0        1          0       0     0        0        0   \n",
       "2            0      0        0          0       0     0        0        0   \n",
       "3            0      1        0          0       0     0        0        0   \n",
       "4            0      0        0          0       0     0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         0    0        0  \n",
       "2        1       0         0    0        0  \n",
       "3        1       0         0    0        0  \n",
       "4        0       0         0    0        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill genre for each movie\n",
    "for row, movie_genre in enumerate(genre_list):\n",
    "    df_genre.loc[row,movie_genre] = 1\n",
    "    \n",
    "df_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250d3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8836</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      (no genres listed)  Action  Adventure  Animation  Children  Comedy  \\\n",
       "8517                   1       0          0          0         0       0   \n",
       "8684                   1       0          0          0         0       0   \n",
       "8687                   1       0          0          0         0       0   \n",
       "8782                   1       0          0          0         0       0   \n",
       "8836                   1       0          0          0         0       0   \n",
       "\n",
       "      Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  \\\n",
       "8517      0            0      0        0          0       0     0        0   \n",
       "8684      0            0      0        0          0       0     0        0   \n",
       "8687      0            0      0        0          0       0     0        0   \n",
       "8782      0            0      0        0          0       0     0        0   \n",
       "8836      0            0      0        0          0       0     0        0   \n",
       "\n",
       "      Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "8517        0        0       0         0    0        0  \n",
       "8684        0        0       0         0    0        0  \n",
       "8687        0        0       0         0    0        0  \n",
       "8782        0        0       0         0    0        0  \n",
       "8836        0        0       0         0    0        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some movies don't have genre listed\n",
    "df_genre[df_genre['(no genres listed)'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e782d347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  (no genres listed)  Action  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy                   0       0   \n",
       "1                   Adventure|Children|Fantasy                   0       0   \n",
       "2                               Comedy|Romance                   0       0   \n",
       "3                         Comedy|Drama|Romance                   0       0   \n",
       "4                                       Comedy                   0       0   \n",
       "\n",
       "   Adventure  Animation  Children  Comedy  Crime  ...  Film-Noir  Horror  \\\n",
       "0          1          1         1       1      0  ...          0       0   \n",
       "1          1          0         1       0      0  ...          0       0   \n",
       "2          0          0         0       1      0  ...          0       0   \n",
       "3          0          0         0       1      0  ...          0       0   \n",
       "4          0          0         0       1      0  ...          0       0   \n",
       "\n",
       "   IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0     0        0        0        0       0         0    0        0  \n",
       "1     0        0        0        0       0         0    0        0  \n",
       "2     0        0        0        1       0         0    0        0  \n",
       "3     0        0        0        1       0         0    0        0  \n",
       "4     0        0        0        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with movie description\n",
    "df_movies = df_movies.join(df_genre)\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab9d104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_csv(r'ml-latest-small/movies_genre.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e366680",
   "metadata": {},
   "source": [
    "### Load ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c195a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(r'ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d50c088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98782f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610,)\n",
      "(9724,)\n"
     ]
    }
   ],
   "source": [
    "print(df_ratings.userId.unique().shape)\n",
    "print(df_ratings.movieId.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9144080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.drop(axis=1,columns=['timestamp'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f0acd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                    title  \\\n",
       "0       1        1     4.0         Toy Story (1995)   \n",
       "1       1        3     4.0  Grumpier Old Men (1995)   \n",
       "\n",
       "                                        genres  (no genres listed)  Action  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy                   0       0   \n",
       "1                               Comedy|Romance                   0       0   \n",
       "\n",
       "   Adventure  Animation  Children  ...  Film-Noir  Horror  IMAX  Musical  \\\n",
       "0          1          1         1  ...          0       0     0        0   \n",
       "1          0          0         0  ...          0       0     0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        1       0         0    0        0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge rating and movie description\n",
    "df_movie_ratings = pd.merge(df_ratings,df_movies,on='movieId')\n",
    "df_movie_ratings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4142a6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Logan (2017)</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The Fate of the Furious (2017)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                           title  \\\n",
       "100834     610   168252     5.0                    Logan (2017)   \n",
       "100835     610   170875     3.0  The Fate of the Furious (2017)   \n",
       "\n",
       "                             genres  (no genres listed)  Action  Adventure  \\\n",
       "100834                Action|Sci-Fi                   0       1          0   \n",
       "100835  Action|Crime|Drama|Thriller                   0       1          0   \n",
       "\n",
       "        Animation  Children  ...  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "100834          0         0  ...          0       0     0        0        0   \n",
       "100835          0         0  ...          0       0     0        0        0   \n",
       "\n",
       "        Romance  Sci-Fi  Thriller  War  Western  \n",
       "100834        0       1         0    0        0  \n",
       "100835        0       0         1    0        0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie_ratings.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9fdac",
   "metadata": {},
   "source": [
    "### Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6803393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training = 70% of the data\n",
    "# Validation = 30% of the data\n",
    "# Randomize the datset\n",
    "np.random.seed(5)\n",
    "l = list(df_movie_ratings.index)\n",
    "np.random.shuffle(l)\n",
    "df = df_movie_ratings.iloc[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e9e84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.shape[0]\n",
    "train = int(.7 * rows)\n",
    "test = rows-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc9a6657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 70585, 30251)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows,train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6f6d76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92163</th>\n",
       "      <td>597</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71427</th>\n",
       "      <td>459</td>\n",
       "      <td>72998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Avatar (2009)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|IMAX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating                           title  \\\n",
       "92163     597       11     3.0  American President, The (1995)   \n",
       "71427     459    72998     5.0                   Avatar (2009)   \n",
       "\n",
       "                             genres  (no genres listed)  Action  Adventure  \\\n",
       "92163          Comedy|Drama|Romance                   0       0          0   \n",
       "71427  Action|Adventure|Sci-Fi|IMAX                   0       1          1   \n",
       "\n",
       "       Animation  Children  ...  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "92163          0         0  ...          0       0     0        0        0   \n",
       "71427          0         0  ...          0       0     1        0        0   \n",
       "\n",
       "       Romance  Sci-Fi  Thriller  War  Western  \n",
       "92163        1       0         0    0        0  \n",
       "71427        0       1         0    0        0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ad7effb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15749/1299668826.py:3: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  y = df['rating'].astype(np.float32).ravel()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3. , 5. , 1. , ..., 3. , 3.5, 3. ], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SageMaker Factorization Machine expects all columns to be of float32\n",
    "# Let's get the target variable as float32\n",
    "y = df['rating'].astype(np.float32).ravel()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40ef9bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c5d3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create two different training datasets.\n",
    "# Training 1: rating, user id, movie id\n",
    "# Training 2: rating, user id, movie id, and movie genre attributes\n",
    "columns_user_movie = ['userId','movieId']\n",
    "columns_all = columns_user_movie + genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9b87160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a copy of user id, movie id and rating\n",
    "# Train and Test\n",
    "df[['rating','userId','movieId']][:train].to_csv(r'ml-latest-small/user_movie_train.csv', index=False)\n",
    "df[['rating','userId','movieId']][train:].to_csv(r'ml-latest-small/user_movie_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fcd0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "# Training 1: user id, movie id\n",
    "# Training 2: user id, movie id, and movie genre attributes\n",
    "encoder = preprocessing.OneHotEncoder(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0347ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoder.fit_transform(df[columns_user_movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "154ba32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610,), (9724,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId.unique().shape, df.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c693f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Dimensions - we need it for training and prediction\n",
    "# Number of unique users and movies\n",
    "dim_movie = df.userId.unique().shape[0] + df.movieId.unique().shape[0]\n",
    "with open(r'ml-latest-small/movie_dimension.txt','w') as f:\n",
    "    f.write(str(dim_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6850e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8e38e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spare matrix recordio file\n",
    "def write_sparse_recordio_file (filename, x, y=None):\n",
    "    with open(filename, 'wb') as f:\n",
    "        smac.write_spmatrix_to_sparse_tensor (f, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fee44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training recordIO file\n",
    "write_sparse_recordio_file(r'ml-latest-small/user_movie_train.recordio',X[:train],y[:train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "227b39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test recordIO file\n",
    "write_sparse_recordio_file(r'ml-latest-small/user_movie_test.recordio',X[train:],y[train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e444b5e",
   "metadata": {},
   "source": [
    "### Cloud Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2034aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5afd981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 'swati-ml-sagemaker'\n",
    "training_file_key = 'movie/user_movie_train.recordio'\n",
    "test_file_key = 'movie/user_movie_test.recordio'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/movie/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_test_file_location = r's3://{0}/{1}'.format(bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b02937fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dimension: Number of unique users + Number of unique movies in our dataset\n",
    "dim_movie = 0\n",
    "\n",
    "# Update movie dimension - from file used for training \n",
    "with open(r'ml-latest-small/movie_dimension.txt','r') as f:\n",
    "    dim_movie = int(f.read())\n",
    "    \n",
    "dim_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbabad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://swati-ml-sagemaker/movie/model\n",
      "s3://swati-ml-sagemaker/movie/user_movie_train.recordio\n",
      "s3://swati-ml-sagemaker/movie/user_movie_test.recordio\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e70f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7056f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_train.recordio',bucket_name,training_file_key)\n",
    "write_to_s3(r'ml-latest-small/user_movie_test.recordio',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b865b2",
   "metadata": {},
   "source": [
    "Training Algorithm Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f269e528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: s3://swati-ml-sagemaker/movie/checkpoints/fm-movie-v1\n"
     ]
    }
   ],
   "source": [
    "# We will use spot for training\n",
    "use_spot_instances = True\n",
    "max_run = 3600 # in seconds\n",
    "max_wait = 3600 if use_spot_instances else None # in seconds\n",
    "\n",
    "job_name = 'fm-movie-v1'\n",
    "\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if use_spot_instances:\n",
    "    checkpoint_s3_uri = f's3://{bucket_name}/movie/checkpoints/{job_name}'\n",
    "    \n",
    "print (f'Checkpoint uri: {checkpoint_s3_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be85eb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::637423580352:role/service-role/AmazonSageMaker-ExecutionRole-20240325T165146\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78642f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FM Container 382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "# Use factorization-machines\n",
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\",sess.boto_region_name)\n",
    "\n",
    "print (f'Using FM Container {container}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467c77",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cd8202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                          role,                                        \n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          output_path=s3_model_output_location,\n",
    "                                          sagemaker_session=sess,\n",
    "                                          base_job_name = job_name,\n",
    "                                          use_spot_instances=use_spot_instances,\n",
    "                                          max_run=max_run,\n",
    "                                          max_wait=max_wait,\n",
    "                                          checkpoint_s3_uri=checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce83f6d",
   "metadata": {},
   "source": [
    "### New Configuration After Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9289525",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                              num_factors=8,\n",
    "                              predictor_type='regressor', \n",
    "                              mini_batch_size=1000,\n",
    "                              epochs=500,\n",
    "                              bias_init_method='normal',\n",
    "                              bias_lr=0.010000000000000004,\n",
    "                              factors_init_method='normal',\n",
    "                              factors_lr=0.00012163193136767434,\n",
    "                              linear_init_method='normal',\n",
    "                              linear_lr=0.00010000000000000009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4b2e2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 10334,\n",
       " 'num_factors': 8,\n",
       " 'predictor_type': 'regressor',\n",
       " 'mini_batch_size': 1000,\n",
       " 'epochs': 500,\n",
       " 'bias_init_method': 'normal',\n",
       " 'bias_lr': 0.010000000000000004,\n",
       " 'factors_init_method': 'normal',\n",
       " 'factors_lr': 0.00012163193136767434,\n",
       " 'linear_init_method': 'normal',\n",
       " 'linear_lr': 0.00010000000000000009}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e23d7",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "396a8293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: fm-movie-v1-2024-05-22-04-39-37-105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 04:39:37 Starting - Starting the training job...\n",
      "2024-05-22 04:39:52 Starting - Preparing the instances for training...\n",
      "2024-05-22 04:40:34 Downloading - Downloading the training image.....................\n",
      "2024-05-22 04:43:55 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 INFO 140374101440320] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 INFO 140374101440320] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'bias_init_method': 'normal', 'bias_lr': '0.010000000000000004', 'epochs': '500', 'factors_init_method': 'normal', 'factors_lr': '0.00012163193136767434', 'feature_dim': '10334', 'linear_init_method': 'normal', 'linear_lr': '0.00010000000000000009', 'mini_batch_size': '1000', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 INFO 140374101440320] Final configuration: {'epochs': '500', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.010000000000000004', 'linear_lr': '0.00010000000000000009', 'factors_lr': '0.00012163193136767434', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '10334', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 WARNING 140374101440320] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 INFO 140374101440320] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:04 INFO 140374101440320] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:04.963] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:04.968] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353044.9604418, \"EndTime\": 1716353045.0043159, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 37.6131534576416, \"count\": 1, \"min\": 37.6131534576416, \"max\": 37.6131534576416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.004439, \"EndTime\": 1716353045.0044794, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[04:44:05] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[04:44:05] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[04:44:05] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.6450879297521754\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.286666015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.50290185546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:05.300] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=3.3139820721559223\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, train mse <loss>=10.982477174570862\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=3.1353949954610476\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.004385, \"EndTime\": 1716353045.301281, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 500.0, \"count\": 1, \"min\": 500, \"max\": 500}, \"update.time\": {\"sum\": 296.5714931488037, \"count\": 1, \"min\": 296.5714931488037, \"max\": 296.5714931488037}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 0.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.0046847, \"EndTime\": 1716353045.301479, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 71585.0, \"count\": 1, \"min\": 71585, \"max\": 71585}, \"Total Batches Seen\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=237739.57078305393 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=2.983746988896679\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=8.90274609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=2.812211181640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:05.580] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=2.7019329578742015\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, train mse <loss>=7.300441708846831\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=2.504424667143486\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.301345, \"EndTime\": 1716353045.5809813, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.27374839782715, \"count\": 1, \"min\": 279.27374839782715, \"max\": 279.27374839782715}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 0.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.301682, \"EndTime\": 1716353045.581168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 142170.0, \"count\": 1, \"min\": 142170, \"max\": 142170}, \"Total Batches Seen\": {\"sum\": 143.0, \"count\": 1, \"min\": 143, \"max\": 143}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252461.85449980898 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=2.413557693983614\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=5.8252607421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=2.22269091796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:05.859] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=2.1882218062151337\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, train mse <loss>=4.788314673195423\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=1.9853133235447844\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.5810406, \"EndTime\": 1716353045.8603556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.95426750183105, \"count\": 1, \"min\": 278.95426750183105, \"max\": 278.95426750183105}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 0.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.5813763, \"EndTime\": 1716353045.8606641, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 212755.0, \"count\": 1, \"min\": 212755, \"max\": 212755}, \"Total Batches Seen\": {\"sum\": 214.0, \"count\": 1, \"min\": 214, \"max\": 214}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252634.8489805601 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.9458653205458811\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=3.786391845703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.73750048828125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:06.160] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 297, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.7818050710773952\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, train mse <loss>=3.1748293113171213\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=1.5760759483659772\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.860418, \"EndTime\": 1716353046.161832, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 300.82106590270996, \"count\": 1, \"min\": 300.82106590270996, \"max\": 300.82106590270996}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 0.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353045.8609853, \"EndTime\": 1716353046.1622887, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 283340.0, \"count\": 1, \"min\": 283340, \"max\": 283340}, \"Total Batches Seen\": {\"sum\": 285.0, \"count\": 1, \"min\": 285, \"max\": 285}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=234171.40684001625 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.5864803565991608\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=2.516919921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.3809310302734374\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:06.484] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 319, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.4848517453918941\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, train mse <loss>=2.204784705793354\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=1.289083827918684\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.1618972, \"EndTime\": 1716353046.4852326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 322.46994972229004, \"count\": 1, \"min\": 322.46994972229004, \"max\": 322.46994972229004}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.1627367, \"EndTime\": 1716353046.4854581, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 353925.0, \"count\": 1, \"min\": 353925, \"max\": 353925}, \"Total Batches Seen\": {\"sum\": 356.0, \"count\": 1, \"min\": 356, \"max\": 356}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=218628.36740767435 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.3335526044472805\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.778362548828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=1.1320992431640624\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:06.792] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 304, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.2890184471505908\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.6615685570945202\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=1.0913593492104974\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.4853013, \"EndTime\": 1716353046.793236, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 307.5063228607178, \"count\": 1, \"min\": 307.5063228607178, \"max\": 307.5063228607178}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 1.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.4857037, \"EndTime\": 1716353046.793552, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 424510.0, \"count\": 1, \"min\": 424510, \"max\": 424510}, \"Total Batches Seen\": {\"sum\": 427.0, \"count\": 1, \"min\": 427, \"max\": 427}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=229164.02996847258 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.1737670143202399\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.37772900390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.963226806640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:07.125] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 328, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.1740577207659515\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.3784115316901409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.9580166058607504\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.793329, \"EndTime\": 1716353047.125516, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 331.5885066986084, \"count\": 1, \"min\": 331.5885066986084, \"max\": 331.5885066986084}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 1.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353046.793903, \"EndTime\": 1716353047.125665, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 495095.0, \"count\": 1, \"min\": 495095, \"max\": 495095}, \"Total Batches Seen\": {\"sum\": 498.0, \"count\": 1, \"min\": 498, \"max\": 498}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=212695.98728658914 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.0836261373133955\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.17424560546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.880267578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:07.444] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 316, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.1135759609607534\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.2400514208296656\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.9094500998913402\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.1255727, \"EndTime\": 1716353047.445192, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 319.34046745300293, \"count\": 1, \"min\": 319.34046745300293, \"max\": 319.34046745300293}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 1.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.1258304, \"EndTime\": 1716353047.44534, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 565680.0, \"count\": 1, \"min\": 565680, \"max\": 565680}, \"Total Batches Seen\": {\"sum\": 569.0, \"count\": 1, \"min\": 569, \"max\": 569}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=220858.23893769 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.0373213795787928\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.07603564453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.8524598999023437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:07.771] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 323, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.084123815538116\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.1753244474169233\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.8830009705449494\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.4452496, \"EndTime\": 1716353047.7721004, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 326.57313346862793, \"count\": 1, \"min\": 326.57313346862793, \"max\": 326.57313346862793}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 1.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.4455001, \"EndTime\": 1716353047.7724617, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 636265.0, \"count\": 1, \"min\": 636265, \"max\": 636265}, \"Total Batches Seen\": {\"sum\": 640.0, \"count\": 1, \"min\": 640, \"max\": 640}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=215794.49960274942 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.0146390647124843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.029492431640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.8332590942382813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:08.097] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 322, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.0700193240364142\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.1449413538113447\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.8650331988267496\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.7721725, \"EndTime\": 1716353048.098725, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 325.61302185058594, \"count\": 1, \"min\": 325.61302185058594, \"max\": 325.61302185058594}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353047.7730873, \"EndTime\": 1716353048.0990434, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 706850.0, \"count\": 1, \"min\": 706850, \"max\": 706850}, \"Total Batches Seen\": {\"sum\": 711.0, \"count\": 1, \"min\": 711, \"max\": 711}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=216470.92687199803 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.0032434582510057\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.0064974365234376\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.8202696533203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:08.425] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 323, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0627246843263294\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.1293837546764964\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.8530178772832306\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.0987878, \"EndTime\": 1716353048.4261553, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 326.7374038696289, \"count\": 1, \"min\": 326.7374038696289, \"max\": 326.7374038696289}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 2.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.0993905, \"EndTime\": 1716353048.426383, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 777435.0, \"count\": 1, \"min\": 777435, \"max\": 777435}, \"Total Batches Seen\": {\"sum\": 782.0, \"count\": 1, \"min\": 782, \"max\": 782}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=215783.96151011993 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.9968094242734228\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=0.9936290283203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.8114842529296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:08.711] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.0582163248780947\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.1198217902385013\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.8449683330697073\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.4262302, \"EndTime\": 1716353048.7114515, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.79576110839844, \"count\": 1, \"min\": 284.79576110839844, \"max\": 284.79576110839844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 2.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.4266326, \"EndTime\": 1716353048.7115986, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 848020.0, \"count\": 1, \"min\": 848020, \"max\": 848020}, \"Total Batches Seen\": {\"sum\": 853.0, \"count\": 1, \"min\": 853, \"max\": 853}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247613.35646192732 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.9924428805194534\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=0.98494287109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.805385986328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:08.979] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.0547750562737597\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.112550419337313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.8394616914131272\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.7115085, \"EndTime\": 1716353048.9803514, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.42474937438965, \"count\": 1, \"min\": 268.42474937438965, \"max\": 268.42474937438965}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 2.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.7119048, \"EndTime\": 1716353048.9805217, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 918605.0, \"count\": 1, \"min\": 918605, \"max\": 918605}, \"Total Batches Seen\": {\"sum\": 924.0, \"count\": 1, \"min\": 924, \"max\": 924}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262684.5529690267 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.9889011766144153\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.977925537109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.8009848022460937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:09.246] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.0517064028848038\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.106086357868893\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.8354503388740647\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.9804204, \"EndTime\": 1716353049.2464726, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.5022144317627, \"count\": 1, \"min\": 265.5022144317627, \"max\": 265.5022144317627}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 2.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353048.9809487, \"EndTime\": 1716353049.2466214, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 989190.0, \"count\": 1, \"min\": 989190, \"max\": 989190}, \"Total Batches Seen\": {\"sum\": 995.0, \"count\": 1, \"min\": 995, \"max\": 995}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265599.69339694583 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.9856594113067942\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.9715244750976563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.7975545654296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:09.529] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.0487333754855612\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.0998416928573393\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.8322168338399538\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.2465324, \"EndTime\": 1716353049.5301104, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.3094596862793, \"count\": 1, \"min\": 283.3094596862793, \"max\": 283.3094596862793}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.2467816, \"EndTime\": 1716353049.530311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1059775.0, \"count\": 1, \"min\": 1059775, \"max\": 1059775}, \"Total Batches Seen\": {\"sum\": 1066.0, \"count\": 1, \"min\": 1066, \"max\": 1066}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248868.27799143412 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.9824913463259963\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.9652892456054688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.7945732421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:09.808] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.0457432048761657\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.0935788505446742\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.8293406913649868\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.5301723, \"EndTime\": 1716353049.8088276, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.06735038757324, \"count\": 1, \"min\": 278.06735038757324, \"max\": 278.06735038757324}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 3.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.5307357, \"EndTime\": 1716353049.8090284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1130360.0, \"count\": 1, \"min\": 1130360, \"max\": 1130360}, \"Total Batches Seen\": {\"sum\": 1137.0, \"count\": 1, \"min\": 1137, \"max\": 1137}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253544.20514085362 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.9792966101166375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.9590218505859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.791777587890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:10.075] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.0426891765235715\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.0872007188394035\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.8265907274702905\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.8089006, \"EndTime\": 1716353050.0760365, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.5743827819824, \"count\": 1, \"min\": 266.5743827819824, \"max\": 266.5743827819824}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 3.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353049.8094392, \"EndTime\": 1716353050.0761867, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1200945.0, \"count\": 1, \"min\": 1200945, \"max\": 1200945}, \"Total Batches Seen\": {\"sum\": 1208.0, \"count\": 1, \"min\": 1208, \"max\": 1208}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264528.9201896392 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.9760315744264341\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.9526376342773437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.789015380859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:10.353] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.0395536468777073\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.0806717847367409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.8238533669055348\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.0760934, \"EndTime\": 1716353050.3535845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.9589424133301, \"count\": 1, \"min\": 276.9589424133301, \"max\": 276.9589424133301}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 3.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.0766, \"EndTime\": 1716353050.3538275, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1271530.0, \"count\": 1, \"min\": 1271530, \"max\": 1271530}, \"Total Batches Seen\": {\"sum\": 1279.0, \"count\": 1, \"min\": 1279, \"max\": 1279}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254500.38025271668 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.9726797185923728\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.9461058349609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.7862151489257813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:10.624] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.0363328036633954\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.0739856799488336\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.8210782212808099\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.3536582, \"EndTime\": 1716353050.6256328, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.2576389312744, \"count\": 1, \"min\": 271.2576389312744, \"max\": 271.2576389312744}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 3.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.354351, \"EndTime\": 1716353050.6258414, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1342115.0, \"count\": 1, \"min\": 1342115, \"max\": 1342115}, \"Total Batches Seen\": {\"sum\": 1350.0, \"count\": 1, \"min\": 1350, \"max\": 1350}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259876.27255610222 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.9692385360909614\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.93942333984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.7833324584960938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:10.908] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.0330299901614708\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.0671509605730083\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.8182410596390846\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.6256912, \"EndTime\": 1716353050.9095533, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.2653522491455, \"count\": 1, \"min\": 283.2653522491455, \"max\": 283.2653522491455}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.6262615, \"EndTime\": 1716353050.9099612, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1412700.0, \"count\": 1, \"min\": 1412700, \"max\": 1412700}, \"Total Batches Seen\": {\"sum\": 1421.0, \"count\": 1, \"min\": 1421, \"max\": 1421}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248715.2359709897 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.9657127286200333\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.93260107421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.780367431640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:11.174] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.029652411694573\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.0601840889084506\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.8153327301455215\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.909684, \"EndTime\": 1716353051.1753235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.81175422668457, \"count\": 1, \"min\": 264.81175422668457, \"max\": 264.81175422668457}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 4.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353050.9104898, \"EndTime\": 1716353051.1754642, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1483285.0, \"count\": 1, \"min\": 1483285, \"max\": 1483285}, \"Total Batches Seen\": {\"sum\": 1492.0, \"count\": 1, \"min\": 1492, \"max\": 1492}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266298.0093780667 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.9621104693203277\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.9256565551757813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.7773289184570312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:11.457] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.0262091001122111\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.053105117153114\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.8123535121863996\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.1753755, \"EndTime\": 1716353051.4581401, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.24730491638184, \"count\": 1, \"min\": 282.24730491638184, \"max\": 282.24730491638184}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 4.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.1758664, \"EndTime\": 1716353051.4583926, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1553870.0, \"count\": 1, \"min\": 1553870, \"max\": 1553870}, \"Total Batches Seen\": {\"sum\": 1563.0, \"count\": 1, \"min\": 1563, \"max\": 1563}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249729.60639459064 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.9584417857847608\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.9186106567382812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.7742083129882813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:11.739] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.0227100397481332\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.0459358254016284\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.8093046006753412\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.4582188, \"EndTime\": 1716353051.739593, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.6689739227295, \"count\": 1, \"min\": 280.6689739227295, \"max\": 280.6689739227295}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 4.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.4589, \"EndTime\": 1716353051.7397375, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1624455.0, \"count\": 1, \"min\": 1624455, \"max\": 1624455}, \"Total Batches Seen\": {\"sum\": 1634.0, \"count\": 1, \"min\": 1634, \"max\": 1634}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251254.29670340862 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.9547176115341318\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.9114857177734375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.7710172119140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:12.007] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.019165727606877\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.038698780328455\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.8061891101246149\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.739647, \"EndTime\": 1716353052.0079763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.8210735321045, \"count\": 1, \"min\": 267.8210735321045, \"max\": 267.8210735321045}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 4.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353051.7401333, \"EndTime\": 1716353052.0081298, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1695040.0, \"count\": 1, \"min\": 1695040, \"max\": 1695040}, \"Total Batches Seen\": {\"sum\": 1705.0, \"count\": 1, \"min\": 1705, \"max\": 1705}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263289.3749905509 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.9509491044313307\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.90430419921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.767752685546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:12.278] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.015586650735216\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.0314162451515736\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.8030125629263865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.008033, \"EndTime\": 1716353052.2789721, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.33472061157227, \"count\": 1, \"min\": 270.33472061157227, \"max\": 270.33472061157227}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.0086145, \"EndTime\": 1716353052.2791197, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1765625.0, \"count\": 1, \"min\": 1765625, \"max\": 1765625}, \"Total Batches Seen\": {\"sum\": 1776.0, \"count\": 1, \"min\": 1776, \"max\": 1776}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260848.02857517946 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.9471472703123608\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.8970879516601562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.7644219360351563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:12.565] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.0119831270959256\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.0241098495268486\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.7997796433139854\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.2790284, \"EndTime\": 1716353052.5658169, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.27967834472656, \"count\": 1, \"min\": 286.27967834472656, \"max\": 286.27967834472656}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 5.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.2795107, \"EndTime\": 1716353052.56607, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1836210.0, \"count\": 1, \"min\": 1836210, \"max\": 1836210}, \"Total Batches Seen\": {\"sum\": 1847.0, \"count\": 1, \"min\": 1847, \"max\": 1847}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246220.83559825548 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.9433231909468383\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.889858642578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.76103125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:12.830] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.0083652612741185\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.0168005001444211\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.7964962416098151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.56589, \"EndTime\": 1716353052.8311687, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.6198272705078, \"count\": 1, \"min\": 264.6198272705078, \"max\": 264.6198272705078}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 5.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.5665271, \"EndTime\": 1716353052.8313177, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1906795.0, \"count\": 1, \"min\": 1906795, \"max\": 1906795}, \"Total Batches Seen\": {\"sum\": 1918.0, \"count\": 1, \"min\": 1918, \"max\": 1918}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266478.73906942375 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.9394873142167587\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.8826364135742187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.7575850219726562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:13.098] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.004742699196072\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.0095078915878082\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.7931678664516395\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.8312242, \"EndTime\": 1716353053.0986128, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.843318939209, \"count\": 1, \"min\": 266.843318939209, \"max\": 266.843318939209}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 5.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353052.8317468, \"EndTime\": 1716353053.0987663, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1977380.0, \"count\": 1, \"min\": 1977380, \"max\": 1977380}, \"Total Batches Seen\": {\"sum\": 1989.0, \"count\": 1, \"min\": 1989, \"max\": 1989}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264256.6775711821 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.9356497040304901\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.8754403686523438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.7540897216796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:13.372] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.001124646970874\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.0022505587725572\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.789800107284331\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.0986712, \"EndTime\": 1716353053.3735573, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.37424659729004, \"count\": 1, \"min\": 274.37424659729004, \"max\": 274.37424659729004}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 5.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.099155, \"EndTime\": 1716353053.3746161, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2047965.0, \"count\": 1, \"min\": 2047965, \"max\": 2047965}, \"Total Batches Seen\": {\"sum\": 2060.0, \"count\": 1, \"min\": 2060, \"max\": 2060}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256110.65027055316 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.9318201314224858\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.8682887573242187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.7505523071289063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:13.642] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.9975198288925844\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, train mse <loss>=0.9950458090338908\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.7864022354340889\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.373632, \"EndTime\": 1716353053.6428585, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.55523681640625, \"count\": 1, \"min\": 267.55523681640625, \"max\": 267.55523681640625}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.375276, \"EndTime\": 1716353053.6430376, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2118550.0, \"count\": 1, \"min\": 2118550, \"max\": 2118550}, \"Total Batches Seen\": {\"sum\": 2131.0, \"count\": 1, \"min\": 2131, \"max\": 2131}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263499.1062629945 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.9280075420204703\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.861197998046875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.7469774169921874\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:44:13.904] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.993936349476479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.9879094668106294\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.782980528065856\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.6429179, \"EndTime\": 1716353053.905269, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.7621421813965, \"count\": 1, \"min\": 261.7621421813965, \"max\": 261.7621421813965}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 6.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.6434827, \"EndTime\": 1716353053.9054945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2189135.0, \"count\": 1, \"min\": 2189135, \"max\": 2189135}, \"Total Batches Seen\": {\"sum\": 2202.0, \"count\": 1, \"min\": 2202, \"max\": 2202}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269275.00958659407 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.9242203679719565\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.8541832885742188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.7433739624023438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:14.177] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.9903817506642858\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.9808560120488556\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7795447869099362\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.9053369, \"EndTime\": 1716353054.1785285, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.4778652191162, \"count\": 1, \"min\": 272.4778652191162, \"max\": 272.4778652191162}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 6.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353053.9060256, \"EndTime\": 1716353054.1787484, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2259720.0, \"count\": 1, \"min\": 2259720, \"max\": 2259720}, \"Total Batches Seen\": {\"sum\": 2273.0, \"count\": 1, \"min\": 2273, \"max\": 2273}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258706.5220742315 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.9204664822370638\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.847258544921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.7397468872070313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:14.478] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 297, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.9868629457048753\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.9738984736053037\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.7761054704693002\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.1785972, \"EndTime\": 1716353054.4791121, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 299.851655960083, \"count\": 1, \"min\": 299.851655960083, \"max\": 299.851655960083}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 6.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.1792364, \"EndTime\": 1716353054.479409, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2330305.0, \"count\": 1, \"min\": 2330305, \"max\": 2330305}, \"Total Batches Seen\": {\"sum\": 2344.0, \"count\": 1, \"min\": 2344, \"max\": 2344}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=235037.36705387707 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.9167529848090215\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.84043603515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.7361026611328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:14.763] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.9833862706664266\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.9670485573352223\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.7726749130034111\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.4792025, \"EndTime\": 1716353054.7640936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.076452255249, \"count\": 1, \"min\": 284.076452255249, \"max\": 284.076452255249}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 6.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.4799924, \"EndTime\": 1716353054.764335, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2400890.0, \"count\": 1, \"min\": 2400890, \"max\": 2400890}, \"Total Batches Seen\": {\"sum\": 2415.0, \"count\": 1, \"min\": 2415, \"max\": 2415}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248138.63332838824 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.9130863511028475\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.8337266845703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.7324813842773438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:15.052] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 285, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.9799573750777915\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.9603164569693552\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.7692641532790493\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.7641642, \"EndTime\": 1716353055.0530403, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.1026268005371, \"count\": 1, \"min\": 288.1026268005371, \"max\": 288.1026268005371}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353054.7649126, \"EndTime\": 1716353055.0532637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2471475.0, \"count\": 1, \"min\": 2471475, \"max\": 2471475}, \"Total Batches Seen\": {\"sum\": 2486.0, \"count\": 1, \"min\": 2486, \"max\": 2486}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=244701.01419663697 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.9094725167860008\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.8271402587890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.7289755249023437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:15.319] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.976581388461698\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.9537112082897777\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.7658922179316131\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.0531068, \"EndTime\": 1716353055.3201852, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.3707733154297, \"count\": 1, \"min\": 266.3707733154297, \"max\": 266.3707733154297}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 7.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.0537922, \"EndTime\": 1716353055.3203607, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2542060.0, \"count\": 1, \"min\": 2542060, \"max\": 2542060}, \"Total Batches Seen\": {\"sum\": 2557.0, \"count\": 1, \"min\": 2557, \"max\": 2557}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264700.3922739713 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.9059166277994005\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.8206849365234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.7255039672851562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:15.597] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.9732627407143782\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.9472403624628631\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.7625587863116197\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.3202412, \"EndTime\": 1716353055.5983493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.42671966552734, \"count\": 1, \"min\": 277.42671966552734, \"max\": 277.42671966552734}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 7.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.3208966, \"EndTime\": 1716353055.5985813, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2612645.0, \"count\": 1, \"min\": 2612645, \"max\": 2612645}, \"Total Batches Seen\": {\"sum\": 2628.0, \"count\": 1, \"min\": 2628, \"max\": 2628}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254085.59708473727 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.9024232919487188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.8143677978515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.7220986938476562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:15.872] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.9700053858257849\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.9409104485310299\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.7592652673855633\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.5984204, \"EndTime\": 1716353055.8729904, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.13392066955566, \"count\": 1, \"min\": 274.13392066955566, \"max\": 274.13392066955566}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 7.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.598828, \"EndTime\": 1716353055.8732154, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2683230.0, \"count\": 1, \"min\": 2683230, \"max\": 2683230}, \"Total Batches Seen\": {\"sum\": 2699.0, \"count\": 1, \"min\": 2699, \"max\": 2699}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257144.1519161935 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.8989964972948657\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.8081947021484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.718708251953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:16.149] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.966812601460156\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.9347266063421545\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.7560226663938711\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.8730628, \"EndTime\": 1716353056.1497424, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.2718200683594, \"count\": 1, \"min\": 276.2718200683594, \"max\": 276.2718200683594}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 7.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353055.8734438, \"EndTime\": 1716353056.149966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2753815.0, \"count\": 1, \"min\": 2753815, \"max\": 2753815}, \"Total Batches Seen\": {\"sum\": 2770.0, \"count\": 1, \"min\": 2770, \"max\": 2770}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255155.5538088688 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.8956396653544605\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.80217041015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.7153233642578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:16.429] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.9636872532681834\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.9286931221115757\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.7528386668890295\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.1498065, \"EndTime\": 1716353056.4309013, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.6670665740967, \"count\": 1, \"min\": 280.6670665740967, \"max\": 280.6670665740967}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.150209, \"EndTime\": 1716353056.4311204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2824400.0, \"count\": 1, \"min\": 2824400, \"max\": 2824400}, \"Total Batches Seen\": {\"sum\": 2841.0, \"count\": 1, \"min\": 2841, \"max\": 2841}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251157.7392194007 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.8923555350189218\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.7962984008789062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.7119750366210937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:16.721] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 287, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.9606315350634684\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.9228129461583957\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.7497192262461487\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.4309719, \"EndTime\": 1716353056.7218764, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 290.09437561035156, \"count\": 1, \"min\": 290.09437561035156, \"max\": 290.09437561035156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 8.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.431755, \"EndTime\": 1716353056.7220936, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2894985.0, \"count\": 1, \"min\": 2894985, \"max\": 2894985}, \"Total Batches Seen\": {\"sum\": 2912.0, \"count\": 1, \"min\": 2912, \"max\": 2912}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=243012.78932649523 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.8891464563829952\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.7905814208984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.7087879638671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:16.998] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.9576473185067146\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.9170883866431008\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.7466719093860035\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.7219465, \"EndTime\": 1716353056.9992056, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.59058570861816, \"count\": 1, \"min\": 276.59058570861816, \"max\": 276.59058570861816}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 8.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.7225914, \"EndTime\": 1716353056.999439, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2965570.0, \"count\": 1, \"min\": 2965570, \"max\": 2965570}, \"Total Batches Seen\": {\"sum\": 2983.0, \"count\": 1, \"min\": 2983, \"max\": 2983}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254865.82671823874 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.8860141060354231\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.78502099609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.7056588745117187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:17.283] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.9547358395316484\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.9115205232862016\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.7437056910555128\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.9992821, \"EndTime\": 1716353057.2838893, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.20114517211914, \"count\": 1, \"min\": 284.20114517211914, \"max\": 284.20114517211914}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 8.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353056.9996622, \"EndTime\": 1716353057.2840981, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3036155.0, \"count\": 1, \"min\": 3036155, \"max\": 3036155}, \"Total Batches Seen\": {\"sum\": 3054.0, \"count\": 1, \"min\": 3054, \"max\": 3054}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247922.1098275335 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.8829598535762222\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.7796181030273438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.702607666015625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:17.568] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.9518980595210316\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.9061099157199054\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.7408113695601343\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.28396, \"EndTime\": 1716353057.5693667, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.8069667816162, \"count\": 1, \"min\": 284.8069667816162, \"max\": 284.8069667816162}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 8.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.284533, \"EndTime\": 1716353057.569597, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3106740.0, \"count\": 1, \"min\": 3106740, \"max\": 3106740}, \"Total Batches Seen\": {\"sum\": 3125.0, \"count\": 1, \"min\": 3125, \"max\": 3125}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247506.74693537343 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.8799845121928106\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.7743727416992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.69965283203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:17.843] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.9491344475112968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.9008561994525748\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.7379962364519146\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.569437, \"EndTime\": 1716353057.8441284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.25456047058105, \"count\": 1, \"min\": 274.25456047058105, \"max\": 274.25456047058105}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.5698478, \"EndTime\": 1716353057.8443358, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3177325.0, \"count\": 1, \"min\": 3177325, \"max\": 3177325}, \"Total Batches Seen\": {\"sum\": 3196.0, \"count\": 1, \"min\": 3196, \"max\": 3196}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257046.1397619986 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.8770884674236117\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.7692841796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.6967740478515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:18.122] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.9464451191356562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.8957583635357065\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.7352591140102333\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.844185, \"EndTime\": 1716353058.1233692, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.7935733795166, \"count\": 1, \"min\": 278.7935733795166, \"max\": 278.7935733795166}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 9.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353057.8445508, \"EndTime\": 1716353058.1236491, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3247910.0, \"count\": 1, \"min\": 3247910, \"max\": 3247910}, \"Total Batches Seen\": {\"sum\": 3267.0, \"count\": 1, \"min\": 3267, \"max\": 3267}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252794.48108619972 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.8742717393458111\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.76435107421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.6940239868164062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:18.392] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.9438298550404808\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.890814795265735\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.7326059157680458\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.1234448, \"EndTime\": 1716353058.3930871, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.1648006439209, \"count\": 1, \"min\": 269.1648006439209, \"max\": 269.1648006439209}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 9.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.1238947, \"EndTime\": 1716353058.3932688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3318495.0, \"count\": 1, \"min\": 3318495, \"max\": 3318495}, \"Total Batches Seen\": {\"sum\": 3338.0, \"count\": 1, \"min\": 3338, \"max\": 3338}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261928.0767873052 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.871534081532924\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.7595716552734375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.6913629150390626\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:18.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 284, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.9412881401093092\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.8860233627104424\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.7300354450924296\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.3931458, \"EndTime\": 1716353058.680544, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.0481014251709, \"count\": 1, \"min\": 287.0481014251709, \"max\": 287.0481014251709}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 9.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.393471, \"EndTime\": 1716353058.6807678, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3389080.0, \"count\": 1, \"min\": 3389080, \"max\": 3389080}, \"Total Batches Seen\": {\"sum\": 3409.0, \"count\": 1, \"min\": 3409, \"max\": 3409}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=245577.68298985108 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.8688748013437588\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.7549434204101563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.6887681274414063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:18.939] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 256, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.9388191757717298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.88138144479671\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.7275462680870378\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.6806178, \"EndTime\": 1716353058.9401782, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 259.1230869293213, \"count\": 1, \"min\": 259.1230869293213, \"max\": 259.1230869293213}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 9.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.681032, \"EndTime\": 1716353058.9403803, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3459665.0, \"count\": 1, \"min\": 3459665, \"max\": 3459665}, \"Total Batches Seen\": {\"sum\": 3480.0, \"count\": 1, \"min\": 3480, \"max\": 3480}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=272053.3160819831 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.8662929648661372\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.7504635009765624\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.6862260131835938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:19.204] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.9364219070736358\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.8768859880474251\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.7251391231912963\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.940235, \"EndTime\": 1716353059.2053602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.77861404418945, \"count\": 1, \"min\": 264.77861404418945, \"max\": 264.77861404418945}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353058.9405596, \"EndTime\": 1716353059.2055085, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3530250.0, \"count\": 1, \"min\": 3530250, \"max\": 3530250}, \"Total Batches Seen\": {\"sum\": 3551.0, \"count\": 1, \"min\": 3551, \"max\": 3551}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266321.964731483 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.8637873233840969\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.7461285400390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.68377978515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:19.469] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.9340950753212928\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.8725336097394917\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.7228177567602883\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.205416, \"EndTime\": 1716353059.4695122, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.8118267059326, \"count\": 1, \"min\": 263.8118267059326, \"max\": 263.8118267059326}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 10.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.2056751, \"EndTime\": 1716353059.4697354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3600835.0, \"count\": 1, \"min\": 3600835, \"max\": 3600835}, \"Total Batches Seen\": {\"sum\": 3622.0, \"count\": 1, \"min\": 3622, \"max\": 3622}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267197.6063537906 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.8613566286383467\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.7419352416992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.6813934326171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:19.740] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.9318372205705673\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.86832060564068\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.7205768002792143\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.4695807, \"EndTime\": 1716353059.7406757, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.672082901001, \"count\": 1, \"min\": 270.672082901001, \"max\": 270.672082901001}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 10.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.4699774, \"EndTime\": 1716353059.7408657, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3671420.0, \"count\": 1, \"min\": 3671420, \"max\": 3671420}, \"Total Batches Seen\": {\"sum\": 3693.0, \"count\": 1, \"min\": 3693, \"max\": 3693}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260462.7174943914 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.8589991365546082\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.7378795166015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.6790397338867188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:20.004] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.9296467911662198\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.8642431563256492\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.7184159932740977\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.7407358, \"EndTime\": 1716353060.0052748, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.1735076904297, \"count\": 1, \"min\": 264.1735076904297, \"max\": 264.1735076904297}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 10.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353059.7410758, \"EndTime\": 1716353060.0054667, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3742005.0, \"count\": 1, \"min\": 3742005, \"max\": 3742005}, \"Total Batches Seen\": {\"sum\": 3764.0, \"count\": 1, \"min\": 3764, \"max\": 3764}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266853.9235479216 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.8567131716602084\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.7339574584960937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.6767872314453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:20.292] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 284, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.927522024205476\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.8602971053862236\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.7163240872235366\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.0053298, \"EndTime\": 1716353060.2932148, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.473201751709, \"count\": 1, \"min\": 287.473201751709, \"max\": 287.473201751709}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 10.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.0057137, \"EndTime\": 1716353060.2934566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3812590.0, \"count\": 1, \"min\": 3812590, \"max\": 3812590}, \"Total Batches Seen\": {\"sum\": 3835.0, \"count\": 1, \"min\": 3835, \"max\": 3835}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=245205.2615258213 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.8544967723091286\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.7301647338867188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.6746784057617188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:20.565] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.92546107388359\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.8564781992737676\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.7143031796737456\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.293291, \"EndTime\": 1716353060.566272, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.5381851196289, \"count\": 1, \"min\": 272.5381851196289, \"max\": 272.5381851196289}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.293707, \"EndTime\": 1716353060.5664723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3883175.0, \"count\": 1, \"min\": 3883175, \"max\": 3883175}, \"Total Batches Seen\": {\"sum\": 3906.0, \"count\": 1, \"min\": 3906, \"max\": 3906}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258639.6227357945 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.8523480107019997\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.7264971313476563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.6726773681640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:20.829] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.9234620523274053\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.8527821620887434\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.7123534451336928\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.5663338, \"EndTime\": 1716353060.8303156, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.5457515716553, \"count\": 1, \"min\": 263.5457515716553, \"max\": 263.5457515716553}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 11.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.5667431, \"EndTime\": 1716353060.8305326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3953760.0, \"count\": 1, \"min\": 3953760, \"max\": 3953760}, \"Total Batches Seen\": {\"sum\": 3977.0, \"count\": 1, \"min\": 3977, \"max\": 3977}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267467.00452802645 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.8502646359645184\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.722949951171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.6707489013671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:21.092] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.9215229203352948\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.84920449270329\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.7104699388960718\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.8303823, \"EndTime\": 1716353061.0926082, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.81769371032715, \"count\": 1, \"min\": 261.81769371032715, \"max\": 261.81769371032715}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 11.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353060.8307657, \"EndTime\": 1716353061.0927567, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4024345.0, \"count\": 1, \"min\": 4024345, \"max\": 4024345}, \"Total Batches Seen\": {\"sum\": 4048.0, \"count\": 1, \"min\": 4048, \"max\": 4048}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269314.2020864338 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.8482446834308778\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.71951904296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.6688720703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:21.368] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.9196417329249309\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.8457409169371699\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.7086491363955215\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.0926638, \"EndTime\": 1716353061.3691368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.18956565856934, \"count\": 1, \"min\": 276.18956565856934, \"max\": 276.18956565856934}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 11.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.0929246, \"EndTime\": 1716353061.3693566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4094930.0, \"count\": 1, \"min\": 4094930, \"max\": 4094930}, \"Total Batches Seen\": {\"sum\": 4119.0, \"count\": 1, \"min\": 4119, \"max\": 4119}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255241.12605967914 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.8462858305745465\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.71619970703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.6670308837890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:21.654] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.917816424281091\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.8423869886801276\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.7068913814920774\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.369217, \"EndTime\": 1716353061.6548426, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.20655632019043, \"count\": 1, \"min\": 285.20655632019043, \"max\": 285.20655632019043}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 11.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.3696098, \"EndTime\": 1716353061.6550565, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4165515.0, \"count\": 1, \"min\": 4165515, \"max\": 4165515}, \"Total Batches Seen\": {\"sum\": 4190.0, \"count\": 1, \"min\": 4190, \"max\": 4190}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247137.12048536737 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.8443858642782746\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.7129874877929687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.6652510375976562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:21.924] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.9160449429319043\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.8391383374711158\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.7051916409344741\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.654902, \"EndTime\": 1716353061.9253888, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.02668380737305, \"count\": 1, \"min\": 270.02668380737305, \"max\": 270.02668380737305}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.6553392, \"EndTime\": 1716353061.9255352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4236100.0, \"count\": 1, \"min\": 4236100, \"max\": 4236100}, \"Total Batches Seen\": {\"sum\": 4261.0, \"count\": 1, \"min\": 4261, \"max\": 4261}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261145.76536350301 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.8425425750207857\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.7098779907226562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.6635082397460937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:22.194] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.914325283209373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.8359907235159001\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.7035420085208517\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.9254448, \"EndTime\": 1716353062.1948173, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.0896987915039, \"count\": 1, \"min\": 269.0896987915039, \"max\": 269.0896987915039}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 12.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353061.9257035, \"EndTime\": 1716353062.1950073, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4306685.0, \"count\": 1, \"min\": 4306685, \"max\": 4306685}, \"Total Batches Seen\": {\"sum\": 4332.0, \"count\": 1, \"min\": 4332, \"max\": 4332}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261997.1520531543 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.8407537947338537\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.706866943359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.6617988891601563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:22.463] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.9126554232755635\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.832939921634298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.7019445714816241\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.1948748, \"EndTime\": 1716353062.464051, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.7852382659912, \"count\": 1, \"min\": 268.7852382659912, \"max\": 268.7852382659912}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 12.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.1952271, \"EndTime\": 1716353062.4642036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4377270.0, \"count\": 1, \"min\": 4377270, \"max\": 4377270}, \"Total Batches Seen\": {\"sum\": 4403.0, \"count\": 1, \"min\": 4403, \"max\": 4403}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262330.52281807654 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.8390172532027426\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.703949951171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.660151611328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:22.742] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.9110333723337949\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.8299818055058868\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.7003971471652178\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.464109, \"EndTime\": 1716353062.743077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.6581516265869, \"count\": 1, \"min\": 278.6581516265869, \"max\": 278.6581516265869}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 12.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.464395, \"EndTime\": 1716353062.7432835, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4447855.0, \"count\": 1, \"min\": 4447855, \"max\": 4447855}, \"Total Batches Seen\": {\"sum\": 4474.0, \"count\": 1, \"min\": 4474, \"max\": 4474}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252993.44034564795 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.8373307970984534\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.7011228637695313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.658553955078125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:23.021] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.9094572069559463\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.827112411284111\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.6988955078125\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.7431397, \"EndTime\": 1716353063.0217602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.20467948913574, \"count\": 1, \"min\": 278.20467948913574, \"max\": 278.20467948913574}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 12.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353062.7435298, \"EndTime\": 1716353063.0219882, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4518440.0, \"count\": 1, \"min\": 4518440, \"max\": 4518440}, \"Total Batches Seen\": {\"sum\": 4545.0, \"count\": 1, \"min\": 4545, \"max\": 4545}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253349.7990179383 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.835692429029664\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.6983818359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.6570317993164062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:23.301] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.9079250849861915\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.8243279599471831\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.6974369188765405\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.0218303, \"EndTime\": 1716353063.3026512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.3506851196289, \"count\": 1, \"min\": 280.3506851196289, \"max\": 280.3506851196289}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.022263, \"EndTime\": 1716353063.3030434, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4589025.0, \"count\": 1, \"min\": 4589025, \"max\": 4589025}, \"Total Batches Seen\": {\"sum\": 4616.0, \"count\": 1, \"min\": 4616, \"max\": 4616}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251257.06876461327 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.8341000175970917\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.6957228393554687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.6555689697265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:23.573] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.9064351798268715\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.8216247352277729\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.6960217620419784\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.3027225, \"EndTime\": 1716353063.5741487, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.632266998291, \"count\": 1, \"min\": 270.632266998291, \"max\": 270.632266998291}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 13.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.3034883, \"EndTime\": 1716353063.5743668, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4659610.0, \"count\": 1, \"min\": 4659610, \"max\": 4659610}, \"Total Batches Seen\": {\"sum\": 4687.0, \"count\": 1, \"min\": 4687, \"max\": 4687}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260452.86444097044 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.8325516638318722\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.6931422729492187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.6541554565429688\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:44:23.845] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.904985720861917\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.8189991549639635\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.6946435426523988\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.5742202, \"EndTime\": 1716353063.8464816, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.8493938446045, \"count\": 1, \"min\": 271.8493938446045, \"max\": 271.8493938446045}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 13.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.574608, \"EndTime\": 1716353063.846637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4730195.0, \"count\": 1, \"min\": 4730195, \"max\": 4730195}, \"Total Batches Seen\": {\"sum\": 4758.0, \"count\": 1, \"min\": 4758, \"max\": 4758}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259385.1503628966 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.8310453005124969\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.6906362915039063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.652810302734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:24.116] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.9035750037670384\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.8164477874326034\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.6933047493948064\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.8465424, \"EndTime\": 1716353064.1170025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.1730728149414, \"count\": 1, \"min\": 270.1730728149414, \"max\": 270.1730728149414}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 13.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353063.8468075, \"EndTime\": 1716353064.1171572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4800780.0, \"count\": 1, \"min\": 4800780, \"max\": 4800780}, \"Total Batches Seen\": {\"sum\": 4829.0, \"count\": 1, \"min\": 4829, \"max\": 4829}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261000.49355201586 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.8295792066802602\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.68820166015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.651544677734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:24.382] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.9022014137060587\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.8139673908932108\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.6920025058800066\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.1170614, \"EndTime\": 1716353064.3834772, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.12401008605957, \"count\": 1, \"min\": 266.12401008605957, \"max\": 266.12401008605957}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 13.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.1173308, \"EndTime\": 1716353064.3836446, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4871365.0, \"count\": 1, \"min\": 4871365, \"max\": 4871365}, \"Total Batches Seen\": {\"sum\": 4900.0, \"count\": 1, \"min\": 4900, \"max\": 4900}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264958.37331433623 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.8281515325938242\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.6858349609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.6503421020507812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:24.666] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.9008634009475956\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.8115548671668684\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.6907388426015075\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.3835366, \"EndTime\": 1716353064.666765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.9318046569824, \"count\": 1, \"min\": 282.9318046569824, \"max\": 282.9318046569824}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.3838089, \"EndTime\": 1716353064.666961, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4941950.0, \"count\": 1, \"min\": 4941950, \"max\": 4941950}, \"Total Batches Seen\": {\"sum\": 4971.0, \"count\": 1, \"min\": 4971, \"max\": 4971}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249192.33559304345 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.8267606316763297\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.6835331420898437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.6492160034179687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:24.928] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.8995594891562063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.809207274530975\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.6895121906978984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.6668303, \"EndTime\": 1716353064.92856, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.3670825958252, \"count\": 1, \"min\": 261.3670825958252, \"max\": 261.3670825958252}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 14.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.6671705, \"EndTime\": 1716353064.928714, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5012535.0, \"count\": 1, \"min\": 5012535, \"max\": 5012535}, \"Total Batches Seen\": {\"sum\": 5042.0, \"count\": 1, \"min\": 5042, \"max\": 5042}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269777.5366592431 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.8254048781601822\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.681293212890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.6481204223632813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:25.196] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.8982882147865371\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.8069217168243839\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.6883179467429578\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.928619, \"EndTime\": 1716353065.1973445, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.4354782104492, \"count\": 1, \"min\": 268.4354782104492, \"max\": 268.4354782104492}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 14.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353064.9288871, \"EndTime\": 1716353065.1974952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5083120.0, \"count\": 1, \"min\": 5083120, \"max\": 5083120}, \"Total Batches Seen\": {\"sum\": 5113.0, \"count\": 1, \"min\": 5113, \"max\": 5113}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262675.4633365127 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.8240827790688339\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.6791124267578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.6470455322265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:25.477] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.8970482844044583\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.8046956245529819\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.6871564021580656\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.1974013, \"EndTime\": 1716353065.4784431, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.45654296875, \"count\": 1, \"min\": 280.45654296875, \"max\": 280.45654296875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 14.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.1979594, \"EndTime\": 1716353065.4786706, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5153705.0, \"count\": 1, \"min\": 5153705, \"max\": 5153705}, \"Total Batches Seen\": {\"sum\": 5184.0, \"count\": 1, \"min\": 5184, \"max\": 5184}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251315.08284642998 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.8227927533948404\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.6769879150390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.6459874877929688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:25.777] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 296, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.8958383978708755\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.802526435099857\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.6860245559047645\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.4785156, \"EndTime\": 1716353065.7780848, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 298.89893531799316, \"count\": 1, \"min\": 298.89893531799316, \"max\": 298.89893531799316}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 14.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.47916, \"EndTime\": 1716353065.7783759, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5224290.0, \"count\": 1, \"min\": 5224290, \"max\": 5224290}, \"Total Batches Seen\": {\"sum\": 5255.0, \"count\": 1, \"min\": 5255, \"max\": 5255}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=235788.0052692024 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.8215334663470046\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.674917236328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.644939697265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:26.048] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.8946572895782802\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.8004116657955546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.684922226596886\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.7781558, \"EndTime\": 1716353066.0493608, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.4813480377197, \"count\": 1, \"min\": 270.4813480377197, \"max\": 270.4813480377197}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353065.7788541, \"EndTime\": 1716353066.0495691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5294875.0, \"count\": 1, \"min\": 5294875, \"max\": 5294875}, \"Total Batches Seen\": {\"sum\": 5326.0, \"count\": 1, \"min\": 5326, \"max\": 5326}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260630.10409183745 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.8203036457855485\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.6728980712890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.6439254760742188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:26.319] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.8935038229072363\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.798349081549846\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.6838481943909551\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.0494297, \"EndTime\": 1716353066.320474, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.4157829284668, \"count\": 1, \"min\": 270.4157829284668, \"max\": 270.4157829284668}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 15.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.0500329, \"EndTime\": 1716353066.3206713, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5365460.0, \"count\": 1, \"min\": 5365460, \"max\": 5365460}, \"Total Batches Seen\": {\"sum\": 5397.0, \"count\": 1, \"min\": 5397, \"max\": 5397}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260711.81178691823 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.8191019713996428\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.6709280395507813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.64292822265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:26.592] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.8923769201539866\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.7963365676235146\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.6828004485654159\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.3205404, \"EndTime\": 1716353066.5926971, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.6023921966553, \"count\": 1, \"min\": 271.6023921966553, \"max\": 271.6023921966553}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 15.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.3210738, \"EndTime\": 1716353066.592892, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5436045.0, \"count\": 1, \"min\": 5436045, \"max\": 5436045}, \"Total Batches Seen\": {\"sum\": 5468.0, \"count\": 1, \"min\": 5468, \"max\": 5468}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259574.36638785136 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.8179272986751137\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.6690050659179687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.641944091796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:26.857] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.8912755261058722\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.7943720634352993\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.6817796329981844\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.5927567, \"EndTime\": 1716353066.8579013, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.5280361175537, \"count\": 1, \"min\": 264.5280361175537, \"max\": 264.5280361175537}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 15.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.5933483, \"EndTime\": 1716353066.8581247, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5506630.0, \"count\": 1, \"min\": 5506630, \"max\": 5506630}, \"Total Batches Seen\": {\"sum\": 5539.0, \"count\": 1, \"min\": 5539, \"max\": 5539}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266482.8167046514 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.8167785111218762\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.6671271362304687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.6409749755859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:27.137] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.8901986244262275\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.7924535909303477\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.6807825506505832\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.8579824, \"EndTime\": 1716353067.1377416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.1860103607178, \"count\": 1, \"min\": 279.1860103607178, \"max\": 279.1860103607178}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 15.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353066.8585336, \"EndTime\": 1716353067.1378963, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5577215.0, \"count\": 1, \"min\": 5577215, \"max\": 5577215}, \"Total Batches Seen\": {\"sum\": 5610.0, \"count\": 1, \"min\": 5610, \"max\": 5610}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252574.9311647771 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.8156545582527186\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.6652923583984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.6400387573242188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:27.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.8891453155273494\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.7905793921242298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.6798077151876101\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.1378, \"EndTime\": 1716353067.408174, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.79827880859375, \"count\": 1, \"min\": 269.79827880859375, \"max\": 269.79827880859375}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.138354, \"EndTime\": 1716353067.4083617, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5647800.0, \"count\": 1, \"min\": 5647800, \"max\": 5647800}, \"Total Batches Seen\": {\"sum\": 5681.0, \"count\": 1, \"min\": 5681, \"max\": 5681}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261332.94597326248 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.8145544563762105\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.6634989624023437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.6391199340820313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:27.675] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.8881146800736451\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.788747684962313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.6788559707856514\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.4082327, \"EndTime\": 1716353067.6764255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.5135135650635, \"count\": 1, \"min\": 267.5135135650635, \"max\": 267.5135135650635}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 16.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.4088883, \"EndTime\": 1716353067.6765761, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5718385.0, \"count\": 1, \"min\": 5718385, \"max\": 5718385}, \"Total Batches Seen\": {\"sum\": 5752.0, \"count\": 1, \"min\": 5752, \"max\": 5752}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263593.4183679829 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.8134772143229682\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.6617451782226562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.6382176513671876\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:27.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 284, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.8871059007198264\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.7869568790919345\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.677925546565526\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.6764805, \"EndTime\": 1716353067.9635239, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.4725589752197, \"count\": 1, \"min\": 286.4725589752197, \"max\": 286.4725589752197}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 16.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.6770294, \"EndTime\": 1716353067.9637327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5788970.0, \"count\": 1, \"min\": 5788970, \"max\": 5788970}, \"Total Batches Seen\": {\"sum\": 5823.0, \"count\": 1, \"min\": 5823, \"max\": 5823}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246099.66835911912 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.8124220214984482\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.660029541015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.6373363037109375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:28.232] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.8861181426137145\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.7852053626691792\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.6770152106486576\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.9635892, \"EndTime\": 1716353068.2326236, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.627405166626, \"count\": 1, \"min\": 268.627405166626, \"max\": 268.627405166626}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 16.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353067.9639728, \"EndTime\": 1716353068.2328708, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5859555.0, \"count\": 1, \"min\": 5859555, \"max\": 5859555}, \"Total Batches Seen\": {\"sum\": 5894.0, \"count\": 1, \"min\": 5894, \"max\": 5894}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262386.78723583394 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.8113879860259132\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=0.6583504638671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.6364640502929687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:28.505] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.8851507079179273\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.7834917757276079\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.6761245916662082\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.2327285, \"EndTime\": 1716353068.5060847, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.998571395874, \"count\": 1, \"min\": 272.998571395874, \"max\": 272.998571395874}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 16.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.2330606, \"EndTime\": 1716353068.5063045, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 83, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5930140.0, \"count\": 1, \"min\": 5930140, \"max\": 5930140}, \"Total Batches Seen\": {\"sum\": 5965.0, \"count\": 1, \"min\": 5965, \"max\": 5965}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 85.0, \"count\": 1, \"min\": 85, \"max\": 85}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258221.60882326006 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.8103743227476732\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=0.65670654296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.6356260375976562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:28.794] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 286, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.884202795139307\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.7818145829321633\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.6752520365110586\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.5061555, \"EndTime\": 1716353068.7955418, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.97571563720703, \"count\": 1, \"min\": 288.97571563720703, \"max\": 288.97571563720703}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.5065403, \"EndTime\": 1716353068.796077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 84, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6000725.0, \"count\": 1, \"min\": 6000725, \"max\": 6000725}, \"Total Batches Seen\": {\"sum\": 6036.0, \"count\": 1, \"min\": 6036, \"max\": 6036}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 86.0, \"count\": 1, \"min\": 86, \"max\": 86}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=243488.0658216896 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.8093803541087389\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=0.6550965576171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.634809814453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:29.072] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.8832737946109485\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.7801725962464239\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.6743960674447073\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.7957962, \"EndTime\": 1716353069.0732636, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.54099464416504, \"count\": 1, \"min\": 276.54099464416504, \"max\": 276.54099464416504}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 17.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353068.796697, \"EndTime\": 1716353069.07349, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 85, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6071310.0, \"count\": 1, \"min\": 6071310, \"max\": 6071310}, \"Total Batches Seen\": {\"sum\": 6107.0, \"count\": 1, \"min\": 6107, \"max\": 6107}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 87.0, \"count\": 1, \"min\": 87, \"max\": 87}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254895.66959254397 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.8084052844977612\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=0.6535191040039062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.6340042114257812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:29.345] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.8823630183249435\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.7785644961075044\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.6735562761333627\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.0733316, \"EndTime\": 1716353069.3458908, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.87418937683105, \"count\": 1, \"min\": 271.87418937683105, \"max\": 271.87418937683105}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 17.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.0739923, \"EndTime\": 1716353069.3461275, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 86, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6141895.0, \"count\": 1, \"min\": 6141895, \"max\": 6141895}, \"Total Batches Seen\": {\"sum\": 6178.0, \"count\": 1, \"min\": 6178, \"max\": 6178}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259269.5279455565 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.8074485398656994\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=0.65197314453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.6332049560546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:29.619] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.8814698756961228\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.7769891417597381\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.6727325035417584\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.3459642, \"EndTime\": 1716353069.6202044, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.5929489135742, \"count\": 1, \"min\": 273.5929489135742, \"max\": 273.5929489135742}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 17.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.3465865, \"EndTime\": 1716353069.6204576, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 87, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6212480.0, \"count\": 1, \"min\": 6212480, \"max\": 6212480}, \"Total Batches Seen\": {\"sum\": 6249.0, \"count\": 1, \"min\": 6249, \"max\": 6249}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257619.19449771842 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.8065094286467417\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=0.6504574584960937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.6324232788085937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:29.896] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.8805937702193944\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.7754453881492077\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.67192509696853\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.6202736, \"EndTime\": 1716353069.897289, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.3516902923584, \"count\": 1, \"min\": 276.3516902923584, \"max\": 276.3516902923584}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 17.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.6209114, \"EndTime\": 1716353069.897493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 88, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6283065.0, \"count\": 1, \"min\": 6283065, \"max\": 6283065}, \"Total Batches Seen\": {\"sum\": 6320.0, \"count\": 1, \"min\": 6320, \"max\": 6320}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 90.0, \"count\": 1, \"min\": 90, \"max\": 90}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255097.5117443708 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.8055873685087057\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=0.6489710083007812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.6316522827148437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:30.163] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.8797341606303615\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.7739321933800066\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.671132637131382\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.8973453, \"EndTime\": 1716353070.1639159, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.94090461730957, \"count\": 1, \"min\": 265.94090461730957, \"max\": 265.94090461730957}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353069.8979516, \"EndTime\": 1716353070.1640654, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 89, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6353650.0, \"count\": 1, \"min\": 6353650, \"max\": 6353650}, \"Total Batches Seen\": {\"sum\": 6391.0, \"count\": 1, \"min\": 6391, \"max\": 6391}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265146.07449759217 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.8046818112662996\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=0.6475128173828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.63088623046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:30.432] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.8788904634732482\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.772448446784221\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.670354795643981\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.1639733, \"EndTime\": 1716353070.432639, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.0494785308838, \"count\": 1, \"min\": 268.0494785308838, \"max\": 268.0494785308838}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 18.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.1645656, \"EndTime\": 1716353070.4327874, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 90, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6424235.0, \"count\": 1, \"min\": 6424235, \"max\": 6424235}, \"Total Batches Seen\": {\"sum\": 6462.0, \"count\": 1, \"min\": 6462, \"max\": 6462}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263065.71764958865 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, batch=0 train rmse <loss>=0.8037922431915125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, batch=0 train mse <loss>=0.6460819702148437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, batch=0 train absolute_loss <loss>=0.6301323852539062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:30.726] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 184, \"duration\": 291, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, train rmse <loss>=0.8780622649621257\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, train mse <loss>=0.7709933411504182\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=91, train absolute_loss <loss>=0.6695897251182878\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.4326952, \"EndTime\": 1716353070.7268622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 293.58625411987305, \"count\": 1, \"min\": 293.58625411987305, \"max\": 293.58625411987305}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 18.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.4332495, \"EndTime\": 1716353070.7270966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 91, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6494820.0, \"count\": 1, \"min\": 6494820, \"max\": 6494820}, \"Total Batches Seen\": {\"sum\": 6533.0, \"count\": 1, \"min\": 6533, \"max\": 6533}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 93.0, \"count\": 1, \"min\": 93, \"max\": 93}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=240095.23186380693 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, batch=0 train rmse <loss>=0.8029181473036534\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, batch=0 train mse <loss>=0.6446775512695313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, batch=0 train absolute_loss <loss>=0.6293902587890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:30.991] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 186, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, train rmse <loss>=0.8772489921220413\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, train mse <loss>=0.7695657941791373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=92, train absolute_loss <loss>=0.6688372063435299\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.7269344, \"EndTime\": 1716353070.992804, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.2089595794678, \"count\": 1, \"min\": 265.2089595794678, \"max\": 265.2089595794678}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 18.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.7275708, \"EndTime\": 1716353070.9929957, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 92, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6565405.0, \"count\": 1, \"min\": 6565405, \"max\": 6565405}, \"Total Batches Seen\": {\"sum\": 6604.0, \"count\": 1, \"min\": 6604, \"max\": 6604}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265842.72021565185 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, batch=0 train rmse <loss>=0.8020590415017386\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, batch=0 train mse <loss>=0.6432987060546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, batch=0 train absolute_loss <loss>=0.62865869140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:31.261] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 188, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, train rmse <loss>=0.876450261311931\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, train mse <loss>=0.7681650605537522\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=93, train absolute_loss <loss>=0.6680980697416924\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.9928663, \"EndTime\": 1716353071.2621768, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.80955696105957, \"count\": 1, \"min\": 268.80955696105957, \"max\": 268.80955696105957}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 18.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353070.9933453, \"EndTime\": 1716353071.2623742, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 93, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6635990.0, \"count\": 1, \"min\": 6635990, \"max\": 6635990}, \"Total Batches Seen\": {\"sum\": 6675.0, \"count\": 1, \"min\": 6675, \"max\": 6675}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 95.0, \"count\": 1, \"min\": 95, \"max\": 95}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262263.13029135036 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, batch=0 train rmse <loss>=0.8012144407573575\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, batch=0 train mse <loss>=0.641944580078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, batch=0 train absolute_loss <loss>=0.6279325561523438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:31.534] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 190, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, train rmse <loss>=0.8756655846557052\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, train mse <loss>=0.7667902161504181\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=94, train absolute_loss <loss>=0.667373027962698\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.262242, \"EndTime\": 1716353071.535048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.2907066345215, \"count\": 1, \"min\": 272.2907066345215, \"max\": 272.2907066345215}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.2627323, \"EndTime\": 1716353071.535274, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 94, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6706575.0, \"count\": 1, \"min\": 6706575, \"max\": 6706575}, \"Total Batches Seen\": {\"sum\": 6746.0, \"count\": 1, \"min\": 6746, \"max\": 6746}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 96.0, \"count\": 1, \"min\": 96, \"max\": 96}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258884.33501810106 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, batch=0 train rmse <loss>=0.8003839334456737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, batch=0 train mse <loss>=0.6406144409179687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, batch=0 train absolute_loss <loss>=0.6272132568359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:31.807] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 192, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, train rmse <loss>=0.8748945823735339\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, train mse <loss>=0.7654405302665603\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=95, train absolute_loss <loss>=0.6666625813228984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.5351174, \"EndTime\": 1716353071.8078718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.0921039581299, \"count\": 1, \"min\": 272.0921039581299, \"max\": 272.0921039581299}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 19.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.5357563, \"EndTime\": 1716353071.8080688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 95, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6777160.0, \"count\": 1, \"min\": 6777160, \"max\": 6777160}, \"Total Batches Seen\": {\"sum\": 6817.0, \"count\": 1, \"min\": 6817, \"max\": 6817}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 97.0, \"count\": 1, \"min\": 97, \"max\": 97}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259113.86189168776 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, batch=0 train rmse <loss>=0.7995671436392944\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, batch=0 train mse <loss>=0.6393076171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, batch=0 train absolute_loss <loss>=0.6265043334960938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:32.081] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 194, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, train rmse <loss>=0.8741368564653654\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, train mse <loss>=0.7641152438311509\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=96, train absolute_loss <loss>=0.6659656999614877\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.8079355, \"EndTime\": 1716353072.0822558, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.7770080566406, \"count\": 1, \"min\": 273.7770080566406, \"max\": 273.7770080566406}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 19.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353071.8084557, \"EndTime\": 1716353072.0824728, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 96, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6847745.0, \"count\": 1, \"min\": 6847745, \"max\": 6847745}, \"Total Batches Seen\": {\"sum\": 6888.0, \"count\": 1, \"min\": 6888, \"max\": 6888}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 98.0, \"count\": 1, \"min\": 98, \"max\": 98}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257486.552164399 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, batch=0 train rmse <loss>=0.798763578535308\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, batch=0 train mse <loss>=0.6380232543945312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, batch=0 train absolute_loss <loss>=0.6258023071289063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:32.350] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 196, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, train rmse <loss>=0.8733919783885454\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, train mse <loss>=0.7628135479134573\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=97, train absolute_loss <loss>=0.6652820632289833\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.0823233, \"EndTime\": 1716353072.3508356, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.911434173584, \"count\": 1, \"min\": 267.911434173584, \"max\": 267.911434173584}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 19.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.0829008, \"EndTime\": 1716353072.3510323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 97, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6918330.0, \"count\": 1, \"min\": 6918330, \"max\": 6918330}, \"Total Batches Seen\": {\"sum\": 6959.0, \"count\": 1, \"min\": 6959, \"max\": 6959}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 99.0, \"count\": 1, \"min\": 99, \"max\": 99}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263143.3463665849 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, batch=0 train rmse <loss>=0.7979729721349041\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, batch=0 train mse <loss>=0.6367608642578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, batch=0 train absolute_loss <loss>=0.62511181640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:32.625] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 198, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, train rmse <loss>=0.8726596421711151\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, train mse <loss>=0.7615348510742187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=98, train absolute_loss <loss>=0.6646120158450705\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.3509088, \"EndTime\": 1716353072.6263125, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.8262882232666, \"count\": 1, \"min\": 274.8262882232666, \"max\": 274.8262882232666}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 19.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.3514647, \"EndTime\": 1716353072.626504, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 98, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6988915.0, \"count\": 1, \"min\": 6988915, \"max\": 6988915}, \"Total Batches Seen\": {\"sum\": 7030.0, \"count\": 1, \"min\": 7030, \"max\": 7030}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 100.0, \"count\": 1, \"min\": 100, \"max\": 100}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256536.30037598123 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, batch=0 train rmse <loss>=0.7971949036185999\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, batch=0 train mse <loss>=0.6355197143554687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, batch=0 train absolute_loss <loss>=0.62443505859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:32.901] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 200, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, train rmse <loss>=0.8719394929395997\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, train mse <loss>=0.7602784793477663\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=99, train absolute_loss <loss>=0.6639542012819102\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.6263866, \"EndTime\": 1716353072.902439, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.45857429504395, \"count\": 1, \"min\": 275.45857429504395, \"max\": 275.45857429504395}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.626956, \"EndTime\": 1716353072.9026737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 99, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7059500.0, \"count\": 1, \"min\": 7059500, \"max\": 7059500}, \"Total Batches Seen\": {\"sum\": 7101.0, \"count\": 1, \"min\": 7101, \"max\": 7101}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 101.0, \"count\": 1, \"min\": 101, \"max\": 101}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255901.45114140253 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, batch=0 train rmse <loss>=0.7964290265528609\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, batch=0 train mse <loss>=0.6342991943359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, batch=0 train absolute_loss <loss>=0.6237763671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:33.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 202, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, train rmse <loss>=0.8712311553782541\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, train mse <loss>=0.7590437261017275\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=100, train absolute_loss <loss>=0.6633086840132593\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.9025145, \"EndTime\": 1716353073.172943, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.82831954956055, \"count\": 1, \"min\": 269.82831954956055, \"max\": 269.82831954956055}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 20.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353072.903091, \"EndTime\": 1716353073.1730945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 100, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7130085.0, \"count\": 1, \"min\": 7130085, \"max\": 7130085}, \"Total Batches Seen\": {\"sum\": 7172.0, \"count\": 1, \"min\": 7172, \"max\": 7172}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 102.0, \"count\": 1, \"min\": 102, \"max\": 102}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261312.87807426968 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, batch=0 train rmse <loss>=0.7956750309534745\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, batch=0 train mse <loss>=0.6330987548828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, batch=0 train absolute_loss <loss>=0.6231307373046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:33.440] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 204, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, train rmse <loss>=0.8705343600958261\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, train mse <loss>=0.7578300721074493\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=101, train absolute_loss <loss>=0.6626745055292693\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.1730013, \"EndTime\": 1716353073.4414585, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.9460048675537, \"count\": 1, \"min\": 267.9460048675537, \"max\": 267.9460048675537}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 20.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.1734872, \"EndTime\": 1716353073.4416895, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 101, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7200670.0, \"count\": 1, \"min\": 7200670, \"max\": 7200670}, \"Total Batches Seen\": {\"sum\": 7243.0, \"count\": 1, \"min\": 7243, \"max\": 7243}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 103.0, \"count\": 1, \"min\": 103, \"max\": 103}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263071.0940660044 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, batch=0 train rmse <loss>=0.7949326051179983\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, batch=0 train mse <loss>=0.6319178466796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, batch=0 train absolute_loss <loss>=0.6224960327148438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:33.714] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 206, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, train rmse <loss>=0.8698487494029425\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, train mse <loss>=0.7566368468378631\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=102, train absolute_loss <loss>=0.6620511792679907\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.4415433, \"EndTime\": 1716353073.7152493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.1301784515381, \"count\": 1, \"min\": 273.1301784515381, \"max\": 273.1301784515381}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 20.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.4420917, \"EndTime\": 1716353073.7154696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 102, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7271255.0, \"count\": 1, \"min\": 7271255, \"max\": 7271255}, \"Total Batches Seen\": {\"sum\": 7314.0, \"count\": 1, \"min\": 7314, \"max\": 7314}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 104.0, \"count\": 1, \"min\": 104, \"max\": 104}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258094.6454777744 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, batch=0 train rmse <loss>=0.7942014356636207\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, batch=0 train mse <loss>=0.6307559204101563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, batch=0 train absolute_loss <loss>=0.6218663940429687\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:44:33.985] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 208, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, train rmse <loss>=0.8691740916270012\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, train mse <loss>=0.7554636015556228\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=103, train absolute_loss <loss>=0.6614377647722272\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.7153227, \"EndTime\": 1716353073.9859629, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.0676918029785, \"count\": 1, \"min\": 270.0676918029785, \"max\": 270.0676918029785}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 20.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.7158709, \"EndTime\": 1716353073.986168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 103, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7341840.0, \"count\": 1, \"min\": 7341840, \"max\": 7341840}, \"Total Batches Seen\": {\"sum\": 7385.0, \"count\": 1, \"min\": 7385, \"max\": 7385}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 105.0, \"count\": 1, \"min\": 105, \"max\": 105}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261032.94121588796 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, batch=0 train rmse <loss>=0.793481207564371\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, batch=0 train mse <loss>=0.6296124267578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, batch=0 train absolute_loss <loss>=0.6212421264648438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:34.262] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 210, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, train rmse <loss>=0.8685100336947243\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, train mse <loss>=0.7543096786284111\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=104, train absolute_loss <loss>=0.6608338984099912\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.986029, \"EndTime\": 1716353074.263107, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.4933109283447, \"count\": 1, \"min\": 276.4933109283447, \"max\": 276.4933109283447}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353073.9865916, \"EndTime\": 1716353074.2633119, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 104, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7412425.0, \"count\": 1, \"min\": 7412425, \"max\": 7412425}, \"Total Batches Seen\": {\"sum\": 7456.0, \"count\": 1, \"min\": 7456, \"max\": 7456}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 106.0, \"count\": 1, \"min\": 106, \"max\": 106}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254981.50679881903 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, batch=0 train rmse <loss>=0.7927716811772242\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, batch=0 train mse <loss>=0.6284869384765625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, batch=0 train absolute_loss <loss>=0.6206301879882813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:34.539] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 212, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, train rmse <loss>=0.8678563750846611\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, train mse <loss>=0.753174687775088\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=105, train absolute_loss <loss>=0.6602393007950044\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.263172, \"EndTime\": 1716353074.540318, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.6249179840088, \"count\": 1, \"min\": 276.6249179840088, \"max\": 276.6249179840088}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 21.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.2636688, \"EndTime\": 1716353074.5405133, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 105, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7483010.0, \"count\": 1, \"min\": 7483010, \"max\": 7483010}, \"Total Batches Seen\": {\"sum\": 7527.0, \"count\": 1, \"min\": 7527, \"max\": 7527}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 107.0, \"count\": 1, \"min\": 107, \"max\": 107}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254853.54050687503 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, batch=0 train rmse <loss>=0.7920725385026298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, batch=0 train mse <loss>=0.62737890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, batch=0 train absolute_loss <loss>=0.6200265502929687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:34.809] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 214, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, train rmse <loss>=0.8672127690694124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, train mse <loss>=0.7520579868370378\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=106, train absolute_loss <loss>=0.6596536787865868\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.5403712, \"EndTime\": 1716353074.809569, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.57995986938477, \"count\": 1, \"min\": 268.57995986938477, \"max\": 268.57995986938477}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 21.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.5409672, \"EndTime\": 1716353074.8097634, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 106, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7553595.0, \"count\": 1, \"min\": 7553595, \"max\": 7553595}, \"Total Batches Seen\": {\"sum\": 7598.0, \"count\": 1, \"min\": 7598, \"max\": 7598}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 108.0, \"count\": 1, \"min\": 108, \"max\": 108}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262487.98439550307 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, batch=0 train rmse <loss>=0.791383575687029\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, batch=0 train mse <loss>=0.6262879638671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, batch=0 train absolute_loss <loss>=0.6194276733398437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:35.077] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 216, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, train rmse <loss>=0.8665790500622994\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, train mse <loss>=0.7509592500068772\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=107, train absolute_loss <loss>=0.6590771011567451\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.8096366, \"EndTime\": 1716353075.0778832, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.6551342010498, \"count\": 1, \"min\": 267.6551342010498, \"max\": 267.6551342010498}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 21.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353074.8102024, \"EndTime\": 1716353075.0781047, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 107, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7624180.0, \"count\": 1, \"min\": 7624180, \"max\": 7624180}, \"Total Batches Seen\": {\"sum\": 7669.0, \"count\": 1, \"min\": 7669, \"max\": 7669}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 109.0, \"count\": 1, \"min\": 109, \"max\": 109}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263358.46739586815 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, batch=0 train rmse <loss>=0.7907045105770392\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, batch=0 train mse <loss>=0.625213623046875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, batch=0 train absolute_loss <loss>=0.6188334350585938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:35.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 218, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, train rmse <loss>=0.865954901252511\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, train mse <loss>=0.7498778910032461\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=108, train absolute_loss <loss>=0.6585082466232944\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.0779521, \"EndTime\": 1716353075.3527853, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.2176055908203, \"count\": 1, \"min\": 274.2176055908203, \"max\": 274.2176055908203}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 21.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.0785463, \"EndTime\": 1716353075.3529346, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 108, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7694765.0, \"count\": 1, \"min\": 7694765, \"max\": 7694765}, \"Total Batches Seen\": {\"sum\": 7740.0, \"count\": 1, \"min\": 7740, \"max\": 7740}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 110.0, \"count\": 1, \"min\": 110, \"max\": 110}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257160.68068916694 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, batch=0 train rmse <loss>=0.7900351369262794\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, batch=0 train mse <loss>=0.624155517578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, batch=0 train absolute_loss <loss>=0.618242919921875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:35.621] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 220, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, train rmse <loss>=0.8653401228080814\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, train mse <loss>=0.7488135281415053\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=109, train absolute_loss <loss>=0.6579475235200264\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.3528435, \"EndTime\": 1716353075.6216648, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.5413360595703, \"count\": 1, \"min\": 268.5413360595703, \"max\": 268.5413360595703}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.3531013, \"EndTime\": 1716353075.6218085, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 109, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7765350.0, \"count\": 1, \"min\": 7765350, \"max\": 7765350}, \"Total Batches Seen\": {\"sum\": 7811.0, \"count\": 1, \"min\": 7811, \"max\": 7811}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 111.0, \"count\": 1, \"min\": 111, \"max\": 111}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262598.5762348047 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, batch=0 train rmse <loss>=0.7893752087663025\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, batch=0 train mse <loss>=0.6231132202148437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, batch=0 train absolute_loss <loss>=0.6176561889648438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:35.906] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 222, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, train rmse <loss>=0.8647345045756323\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, train mse <loss>=0.7477657634036642\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=110, train absolute_loss <loss>=0.6573946223729094\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.6217177, \"EndTime\": 1716353075.9066913, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.67297554016113, \"count\": 1, \"min\": 284.67297554016113, \"max\": 284.67297554016113}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 22.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.6219923, \"EndTime\": 1716353075.906905, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 110, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7835935.0, \"count\": 1, \"min\": 7835935, \"max\": 7835935}, \"Total Batches Seen\": {\"sum\": 7882.0, \"count\": 1, \"min\": 7882, \"max\": 7882}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 112.0, \"count\": 1, \"min\": 112, \"max\": 112}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247634.68938906645 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, batch=0 train rmse <loss>=0.7887244402678171\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, batch=0 train mse <loss>=0.6220862426757813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, batch=0 train absolute_loss <loss>=0.6170797119140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:36.169] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 224, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, train rmse <loss>=0.8641378151233045\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, train mse <loss>=0.7467341635260784\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=111, train absolute_loss <loss>=0.6568497529365647\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.9067643, \"EndTime\": 1716353076.1702414, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.0643844604492, \"count\": 1, \"min\": 263.0643844604492, \"max\": 263.0643844604492}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 22.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353075.9071534, \"EndTime\": 1716353076.1703897, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 111, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7906520.0, \"count\": 1, \"min\": 7906520, \"max\": 7906520}, \"Total Batches Seen\": {\"sum\": 7953.0, \"count\": 1, \"min\": 7953, \"max\": 7953}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 113.0, \"count\": 1, \"min\": 113, \"max\": 113}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268039.7058266992 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, batch=0 train rmse <loss>=0.7880826992266183\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, batch=0 train mse <loss>=0.6210743408203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, batch=0 train absolute_loss <loss>=0.6165072021484375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:36.434] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 226, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, train rmse <loss>=0.8635497857626085\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, train mse <loss>=0.7457182324906471\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=112, train absolute_loss <loss>=0.6563129753864987\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.1702971, \"EndTime\": 1716353076.4349022, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.3239498138428, \"count\": 1, \"min\": 264.3239498138428, \"max\": 264.3239498138428}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 22.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.1705563, \"EndTime\": 1716353076.4350855, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 112, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7977105.0, \"count\": 1, \"min\": 7977105, \"max\": 7977105}, \"Total Batches Seen\": {\"sum\": 8024.0, \"count\": 1, \"min\": 8024, \"max\": 8024}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 114.0, \"count\": 1, \"min\": 114, \"max\": 114}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266740.1998738625 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, batch=0 train rmse <loss>=0.7874497364291538\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, batch=0 train mse <loss>=0.6200770874023438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, batch=0 train absolute_loss <loss>=0.6159388427734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:36.705] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 228, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, train rmse <loss>=0.8629703086813288\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, train mse <loss>=0.7447177536655479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=113, train absolute_loss <loss>=0.6557834635989767\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.4349592, \"EndTime\": 1716353076.7059326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.40815353393555, \"count\": 1, \"min\": 270.40815353393555, \"max\": 270.40815353393555}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 22.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.435481, \"EndTime\": 1716353076.7062364, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 113, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8047690.0, \"count\": 1, \"min\": 8047690, \"max\": 8047690}, \"Total Batches Seen\": {\"sum\": 8095.0, \"count\": 1, \"min\": 8095, \"max\": 8095}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 115.0, \"count\": 1, \"min\": 115, \"max\": 115}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260578.2600475643 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, batch=0 train rmse <loss>=0.7868253791319226\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, batch=0 train mse <loss>=0.6190941772460937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, batch=0 train absolute_loss <loss>=0.6153783569335938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:36.974] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 230, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, train rmse <loss>=0.8623990776536545\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, train mse <loss>=0.7437321691378741\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=114, train absolute_loss <loss>=0.6552620075924296\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.7060125, \"EndTime\": 1716353076.9754992, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.8467502593994, \"count\": 1, \"min\": 268.8467502593994, \"max\": 268.8467502593994}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.7066271, \"EndTime\": 1716353076.9757178, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 114, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8118275.0, \"count\": 1, \"min\": 8118275, \"max\": 8118275}, \"Total Batches Seen\": {\"sum\": 8166.0, \"count\": 1, \"min\": 8166, \"max\": 8166}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 116.0, \"count\": 1, \"min\": 116, \"max\": 116}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262205.5255226531 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, batch=0 train rmse <loss>=0.7862093761241141\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, batch=0 train mse <loss>=0.6181251831054687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, batch=0 train absolute_loss <loss>=0.61483251953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:37.256] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 232, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, train rmse <loss>=0.8618360018488764\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, train mse <loss>=0.7427612940828565\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=115, train absolute_loss <loss>=0.6547477872606734\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.9755707, \"EndTime\": 1716353077.257427, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.45670890808105, \"count\": 1, \"min\": 281.45670890808105, \"max\": 281.45670890808105}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 23.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353076.9759421, \"EndTime\": 1716353077.2576404, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 115, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8188860.0, \"count\": 1, \"min\": 8188860, \"max\": 8188860}, \"Total Batches Seen\": {\"sum\": 8237.0, \"count\": 1, \"min\": 8237, \"max\": 8237}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 117.0, \"count\": 1, \"min\": 117, \"max\": 117}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250488.5717525023 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, batch=0 train rmse <loss>=0.7856016305195656\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, batch=0 train mse <loss>=0.617169921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, batch=0 train absolute_loss <loss>=0.6142955322265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:37.537] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 234, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, train rmse <loss>=0.8612808402493927\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, train mse <loss>=0.7418046857806998\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=116, train absolute_loss <loss>=0.6542405223577795\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.2575, \"EndTime\": 1716353077.5382917, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.4279327392578, \"count\": 1, \"min\": 280.4279327392578, \"max\": 280.4279327392578}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 23.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.2578382, \"EndTime\": 1716353077.538514, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 116, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8259445.0, \"count\": 1, \"min\": 8259445, \"max\": 8259445}, \"Total Batches Seen\": {\"sum\": 8308.0, \"count\": 1, \"min\": 8308, \"max\": 8308}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 118.0, \"count\": 1, \"min\": 118, \"max\": 118}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251386.7842983747 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, batch=0 train rmse <loss>=0.7850018893662574\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, batch=0 train mse <loss>=0.6162279663085938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, batch=0 train absolute_loss <loss>=0.6137620849609375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:37.814] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 236, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, train rmse <loss>=0.8607333809552259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, train mse <loss>=0.740861953090614\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=117, train absolute_loss <loss>=0.6537403401119608\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.5383568, \"EndTime\": 1716353077.8148737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.11470222473145, \"count\": 1, \"min\": 276.11470222473145, \"max\": 276.11470222473145}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 23.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.5387337, \"EndTime\": 1716353077.8151095, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 117, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8330030.0, \"count\": 1, \"min\": 8330030, \"max\": 8330030}, \"Total Batches Seen\": {\"sum\": 8379.0, \"count\": 1, \"min\": 8379, \"max\": 8379}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 119.0, \"count\": 1, \"min\": 119, \"max\": 119}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255292.6290519105 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, batch=0 train rmse <loss>=0.7844099764985583\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, batch=0 train mse <loss>=0.6152990112304687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, batch=0 train absolute_loss <loss>=0.6132333374023438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:38.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 238, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, train rmse <loss>=0.8601935207470341\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, train mse <loss>=0.7399328931351783\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=118, train absolute_loss <loss>=0.6532469224526849\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.8149433, \"EndTime\": 1716353078.085033, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.64831352233887, \"count\": 1, \"min\": 269.64831352233887, \"max\": 269.64831352233887}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 23.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353077.81536, \"EndTime\": 1716353078.0852625, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 118, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8400615.0, \"count\": 1, \"min\": 8400615, \"max\": 8400615}, \"Total Batches Seen\": {\"sum\": 8450.0, \"count\": 1, \"min\": 8450, \"max\": 8450}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 120.0, \"count\": 1, \"min\": 120, \"max\": 120}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261402.16927063788 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, batch=0 train rmse <loss>=0.7838257539147333\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, batch=0 train mse <loss>=0.6143828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, batch=0 train absolute_loss <loss>=0.6127088623046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:38.362] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 240, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, train rmse <loss>=0.8596610389443338\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, train mse <loss>=0.7390171018788513\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=119, train absolute_loss <loss>=0.6527600630639304\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.0851045, \"EndTime\": 1716353078.3633735, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.6777744293213, \"count\": 1, \"min\": 277.6777744293213, \"max\": 277.6777744293213}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.0856724, \"EndTime\": 1716353078.3635767, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 119, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8471200.0, \"count\": 1, \"min\": 8471200, \"max\": 8471200}, \"Total Batches Seen\": {\"sum\": 8521.0, \"count\": 1, \"min\": 8521, \"max\": 8521}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 121.0, \"count\": 1, \"min\": 121, \"max\": 121}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253886.00562218827 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, batch=0 train rmse <loss>=0.7832490440092514\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, batch=0 train mse <loss>=0.6134790649414062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, batch=0 train absolute_loss <loss>=0.6121878662109375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:38.629] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 242, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, train rmse <loss>=0.8591357661567237\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, train mse <loss>=0.7381142646897006\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=120, train absolute_loss <loss>=0.6522790011553697\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.3634315, \"EndTime\": 1716353078.630024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.01386070251465, \"count\": 1, \"min\": 266.01386070251465, \"max\": 266.01386070251465}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 24.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.3639877, \"EndTime\": 1716353078.6302242, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 120, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8541785.0, \"count\": 1, \"min\": 8541785, \"max\": 8541785}, \"Total Batches Seen\": {\"sum\": 8592.0, \"count\": 1, \"min\": 8592, \"max\": 8592}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 122.0, \"count\": 1, \"min\": 122, \"max\": 122}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265023.3623432311 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, batch=0 train rmse <loss>=0.7826796684333293\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, batch=0 train mse <loss>=0.6125874633789062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, batch=0 train absolute_loss <loss>=0.6116715087890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:38.907] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 244, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, train rmse <loss>=0.8586175749459429\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, train mse <loss>=0.737224140006052\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=121, train absolute_loss <loss>=0.6518039817272777\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.6300879, \"EndTime\": 1716353078.907852, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.2042751312256, \"count\": 1, \"min\": 277.2042751312256, \"max\": 277.2042751312256}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 24.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.6306238, \"EndTime\": 1716353078.9081948, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 121, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8612370.0, \"count\": 1, \"min\": 8612370, \"max\": 8612370}, \"Total Batches Seen\": {\"sum\": 8663.0, \"count\": 1, \"min\": 8663, \"max\": 8663}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 123.0, \"count\": 1, \"min\": 123, \"max\": 123}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254165.43428467427 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, batch=0 train rmse <loss>=0.7821175261474654\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, batch=0 train mse <loss>=0.6117078247070312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, batch=0 train absolute_loss <loss>=0.6111607055664062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:39.187] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 246, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, train rmse <loss>=0.8581062772805124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, train mse <loss>=0.7363463831082196\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=122, train absolute_loss <loss>=0.651335390762544\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.9079223, \"EndTime\": 1716353079.18773, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.0062427520752, \"count\": 1, \"min\": 279.0062427520752, \"max\": 279.0062427520752}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 24.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353078.9086974, \"EndTime\": 1716353079.1879442, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 122, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8682955.0, \"count\": 1, \"min\": 8682955, \"max\": 8682955}, \"Total Batches Seen\": {\"sum\": 8734.0, \"count\": 1, \"min\": 8734, \"max\": 8734}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 124.0, \"count\": 1, \"min\": 124, \"max\": 124}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252651.01872854785 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, batch=0 train rmse <loss>=0.7815623984781022\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, batch=0 train mse <loss>=0.6108397827148437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, batch=0 train absolute_loss <loss>=0.6106532592773437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:39.456] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 248, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, train rmse <loss>=0.8576017301199179\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, train mse <loss>=0.7354807275046765\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=123, train absolute_loss <loss>=0.650873291015625\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.1878002, \"EndTime\": 1716353079.4569356, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.48840713500977, \"count\": 1, \"min\": 268.48840713500977, \"max\": 268.48840713500977}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 24.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.1884253, \"EndTime\": 1716353079.457088, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 123, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8753540.0, \"count\": 1, \"min\": 8753540, \"max\": 8753540}, \"Total Batches Seen\": {\"sum\": 8805.0, \"count\": 1, \"min\": 8805, \"max\": 8805}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 125.0, \"count\": 1, \"min\": 125, \"max\": 125}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262637.24714989454 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, batch=0 train rmse <loss>=0.7810141440855721\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, batch=0 train mse <loss>=0.6099830932617187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, batch=0 train absolute_loss <loss>=0.6101527099609375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:39.737] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 250, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, train rmse <loss>=0.8571037623433585\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, train mse <loss>=0.7346268594231404\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=124, train absolute_loss <loss>=0.6504174349072953\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.4569926, \"EndTime\": 1716353079.7380204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.4841995239258, \"count\": 1, \"min\": 280.4841995239258, \"max\": 280.4841995239258}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.4575138, \"EndTime\": 1716353079.738218, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 124, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8824125.0, \"count\": 1, \"min\": 8824125, \"max\": 8824125}, \"Total Batches Seen\": {\"sum\": 8876.0, \"count\": 1, \"min\": 8876, \"max\": 8876}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 126.0, \"count\": 1, \"min\": 126, \"max\": 126}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251362.02560190458 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, batch=0 train rmse <loss>=0.78047269925177\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, batch=0 train mse <loss>=0.6091376342773438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, batch=0 train absolute_loss <loss>=0.6096599731445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:39.999] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 252, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, train rmse <loss>=0.8566122850704359\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, train mse <loss>=0.7337846069335937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=125, train absolute_loss <loss>=0.6499673410335057\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.7380874, \"EndTime\": 1716353080.0003264, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.7220878601074, \"count\": 1, \"min\": 261.7220878601074, \"max\": 261.7220878601074}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 25.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353079.7385802, \"EndTime\": 1716353080.0004797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 125, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8894710.0, \"count\": 1, \"min\": 8894710, \"max\": 8894710}, \"Total Batches Seen\": {\"sum\": 8947.0, \"count\": 1, \"min\": 8947, \"max\": 8947}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 127.0, \"count\": 1, \"min\": 127, \"max\": 127}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269423.0210547774 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, batch=0 train rmse <loss>=0.7799378825175358\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, batch=0 train mse <loss>=0.6083031005859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, batch=0 train absolute_loss <loss>=0.6091717529296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:40.272] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 254, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, train rmse <loss>=0.8561271141788188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, train mse <loss>=0.7329536356321523\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=126, train absolute_loss <loss>=0.6495225890253631\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.0003848, \"EndTime\": 1716353080.2733688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.4606990814209, \"count\": 1, \"min\": 272.4606990814209, \"max\": 272.4606990814209}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 25.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.0008826, \"EndTime\": 1716353080.2735934, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 126, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8965295.0, \"count\": 1, \"min\": 8965295, \"max\": 8965295}, \"Total Batches Seen\": {\"sum\": 9018.0, \"count\": 1, \"min\": 9018, \"max\": 9018}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 128.0, \"count\": 1, \"min\": 128, \"max\": 128}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258707.2002852242 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, batch=0 train rmse <loss>=0.7794094725986864\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, batch=0 train mse <loss>=0.6074791259765625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, batch=0 train absolute_loss <loss>=0.6086867065429687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:40.540] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 256, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, train rmse <loss>=0.8556480870892751\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, train mse <loss>=0.7321336489395357\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=127, train absolute_loss <loss>=0.6490832390583737\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.2734394, \"EndTime\": 1716353080.5405893, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.51930809020996, \"count\": 1, \"min\": 266.51930809020996, \"max\": 266.51930809020996}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 25.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.2740479, \"EndTime\": 1716353080.540741, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 127, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9035880.0, \"count\": 1, \"min\": 9035880, \"max\": 9035880}, \"Total Batches Seen\": {\"sum\": 9089.0, \"count\": 1, \"min\": 9089, \"max\": 9089}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 129.0, \"count\": 1, \"min\": 129, \"max\": 129}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264580.22025789996 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, batch=0 train rmse <loss>=0.7788874433536995\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, batch=0 train mse <loss>=0.6066656494140625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, batch=0 train absolute_loss <loss>=0.6082048950195312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:40.813] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 258, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, train rmse <loss>=0.8551751337075522\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, train mse <loss>=0.7313245093117298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=128, train absolute_loss <loss>=0.6486492782377861\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.5406494, \"EndTime\": 1716353080.8140626, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.9613780975342, \"count\": 1, \"min\": 272.9613780975342, \"max\": 272.9613780975342}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 25.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.5410745, \"EndTime\": 1716353080.8142767, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 128, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9106465.0, \"count\": 1, \"min\": 9106465, \"max\": 9106465}, \"Total Batches Seen\": {\"sum\": 9160.0, \"count\": 1, \"min\": 9160, \"max\": 9160}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 130.0, \"count\": 1, \"min\": 130, \"max\": 130}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258253.5944583482 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, batch=0 train rmse <loss>=0.7783716507927383\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, batch=0 train mse <loss>=0.6058624267578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, batch=0 train absolute_loss <loss>=0.607726318359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:41.096] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 260, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, train rmse <loss>=0.8547080735206327\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, train mse <loss>=0.7305258909413512\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=129, train absolute_loss <loss>=0.6482206369319432\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.814135, \"EndTime\": 1716353081.0972826, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.75084495544434, \"count\": 1, \"min\": 282.75084495544434, \"max\": 282.75084495544434}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353080.8145092, \"EndTime\": 1716353081.097512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 129, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9177050.0, \"count\": 1, \"min\": 9177050, \"max\": 9177050}, \"Total Batches Seen\": {\"sum\": 9231.0, \"count\": 1, \"min\": 9231, \"max\": 9231}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 131.0, \"count\": 1, \"min\": 131, \"max\": 131}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249304.60112351508 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, batch=0 train rmse <loss>=0.7778619503917051\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, batch=0 train mse <loss>=0.6050692138671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, batch=0 train absolute_loss <loss>=0.6072509765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:41.378] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 262, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, train rmse <loss>=0.8542468105307046\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, train mse <loss>=0.7297376133018816\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=130, train absolute_loss <loss>=0.6477971045265735\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.0973582, \"EndTime\": 1716353081.379547, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.7552089691162, \"count\": 1, \"min\": 281.7552089691162, \"max\": 281.7552089691162}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 26.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.0977666, \"EndTime\": 1716353081.3797626, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 130, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9247635.0, \"count\": 1, \"min\": 9247635, \"max\": 9247635}, \"Total Batches Seen\": {\"sum\": 9302.0, \"count\": 1, \"min\": 9302, \"max\": 9302}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 132.0, \"count\": 1, \"min\": 132, \"max\": 132}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250195.596225452 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, batch=0 train rmse <loss>=0.7773581971019297\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, batch=0 train mse <loss>=0.6042857666015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, batch=0 train absolute_loss <loss>=0.6067824096679687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:41.658] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 264, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, train rmse <loss>=0.853791175919024\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, train mse <loss>=0.7289593720771897\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=131, train absolute_loss <loss>=0.6473778901435959\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.3796244, \"EndTime\": 1716353081.659446, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.4067859649658, \"count\": 1, \"min\": 279.4067859649658, \"max\": 279.4067859649658}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 26.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.380017, \"EndTime\": 1716353081.659636, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 131, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9318220.0, \"count\": 1, \"min\": 9318220, \"max\": 9318220}, \"Total Batches Seen\": {\"sum\": 9373.0, \"count\": 1, \"min\": 9373, \"max\": 9373}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 133.0, \"count\": 1, \"min\": 133, \"max\": 133}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252342.42635056985 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, batch=0 train rmse <loss>=0.7768603239261386\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, batch=0 train mse <loss>=0.603511962890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, batch=0 train absolute_loss <loss>=0.606320068359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:41.924] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 266, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, train rmse <loss>=0.853341109191139\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, train mse <loss>=0.7281910486355634\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=132, train absolute_loss <loss>=0.6469640219245159\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.6595087, \"EndTime\": 1716353081.924987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.09761810302734, \"count\": 1, \"min\": 265.09761810302734, \"max\": 265.09761810302734}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 26.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.6598613, \"EndTime\": 1716353081.9251933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 132, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9388805.0, \"count\": 1, \"min\": 9388805, \"max\": 9388805}, \"Total Batches Seen\": {\"sum\": 9444.0, \"count\": 1, \"min\": 9444, \"max\": 9444}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 134.0, \"count\": 1, \"min\": 134, \"max\": 134}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265908.62151070934 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, batch=0 train rmse <loss>=0.7763682242524524\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, batch=0 train mse <loss>=0.6027476196289062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, batch=0 train absolute_loss <loss>=0.6058729858398437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:42.187] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 268, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, train rmse <loss>=0.8528964321925728\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, train mse <loss>=0.72743232404682\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=133, train absolute_loss <loss>=0.6465554706412302\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.925052, \"EndTime\": 1716353082.188124, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.6798152923584, \"count\": 1, \"min\": 262.6798152923584, \"max\": 262.6798152923584}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 26.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353081.92542, \"EndTime\": 1716353082.1883311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 133, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9459390.0, \"count\": 1, \"min\": 9459390, \"max\": 9459390}, \"Total Batches Seen\": {\"sum\": 9515.0, \"count\": 1, \"min\": 9515, \"max\": 9515}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 135.0, \"count\": 1, \"min\": 135, \"max\": 135}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268355.5557328146 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, batch=0 train rmse <loss>=0.775881712402493\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, batch=0 train mse <loss>=0.601992431640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, batch=0 train absolute_loss <loss>=0.6054324340820313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:42.477] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 270, \"duration\": 286, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, train rmse <loss>=0.852457064615306\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, train mse <loss>=0.726683047012544\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=134, train absolute_loss <loss>=0.6461522878727443\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.1881988, \"EndTime\": 1716353082.4778466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.2894744873047, \"count\": 1, \"min\": 289.2894744873047, \"max\": 289.2894744873047}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.188533, \"EndTime\": 1716353082.4780667, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 134, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9529975.0, \"count\": 1, \"min\": 9529975, \"max\": 9529975}, \"Total Batches Seen\": {\"sum\": 9586.0, \"count\": 1, \"min\": 9586, \"max\": 9586}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 136.0, \"count\": 1, \"min\": 136, \"max\": 136}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=243693.29962868363 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, batch=0 train rmse <loss>=0.7754007595370441\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, batch=0 train mse <loss>=0.601246337890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, batch=0 train absolute_loss <loss>=0.6049966430664062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:42.744] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 272, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, train rmse <loss>=0.8520228971302737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, train mse <loss>=0.725943017234265\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=135, train absolute_loss <loss>=0.6457545337945643\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.477915, \"EndTime\": 1716353082.7447307, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.406774520874, \"count\": 1, \"min\": 266.406774520874, \"max\": 266.406774520874}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 27.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.4782977, \"EndTime\": 1716353082.7449763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 135, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9600560.0, \"count\": 1, \"min\": 9600560, \"max\": 9600560}, \"Total Batches Seen\": {\"sum\": 9657.0, \"count\": 1, \"min\": 9657, \"max\": 9657}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 137.0, \"count\": 1, \"min\": 137, \"max\": 137}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264573.59977622656 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, batch=0 train rmse <loss>=0.774925218481294\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, batch=0 train mse <loss>=0.6005090942382812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, batch=0 train absolute_loss <loss>=0.6045650634765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:43.015] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 274, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, train rmse <loss>=0.8515938251361462\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, train mse <loss>=0.7252120430100132\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=136, train absolute_loss <loss>=0.6453618043711488\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.7447982, \"EndTime\": 1716353083.0158718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.6441879272461, \"count\": 1, \"min\": 270.6441879272461, \"max\": 270.6441879272461}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 27.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353082.7452042, \"EndTime\": 1716353083.0160916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 136, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9671145.0, \"count\": 1, \"min\": 9671145, \"max\": 9671145}, \"Total Batches Seen\": {\"sum\": 9728.0, \"count\": 1, \"min\": 9728, \"max\": 9728}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 138.0, \"count\": 1, \"min\": 138, \"max\": 138}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260460.65516570932 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, batch=0 train rmse <loss>=0.7744549415834137\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, batch=0 train mse <loss>=0.5997804565429687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, batch=0 train absolute_loss <loss>=0.6041463623046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:43.276] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 276, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, train rmse <loss>=0.8511697083791886\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, train mse <loss>=0.7244898724623129\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=137, train absolute_loss <loss>=0.6449736173387984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.0159426, \"EndTime\": 1716353083.277277, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.662317276001, \"count\": 1, \"min\": 260.662317276001, \"max\": 260.662317276001}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 27.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.0165906, \"EndTime\": 1716353083.2775135, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 137, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9741730.0, \"count\": 1, \"min\": 9741730, \"max\": 9741730}, \"Total Batches Seen\": {\"sum\": 9799.0, \"count\": 1, \"min\": 9799, \"max\": 9799}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 139.0, \"count\": 1, \"min\": 139, \"max\": 139}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270408.33930678706 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, batch=0 train rmse <loss>=0.7739898990100137\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, batch=0 train mse <loss>=0.5990603637695312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, batch=0 train absolute_loss <loss>=0.6037357177734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:43.550] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 278, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, train rmse <loss>=0.8507504476666442\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, train mse <loss>=0.7237763242049956\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=138, train absolute_loss <loss>=0.6445898979079555\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.2773468, \"EndTime\": 1716353083.551022, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.95947074890137, \"count\": 1, \"min\": 272.95947074890137, \"max\": 272.95947074890137}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 27.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.2780406, \"EndTime\": 1716353083.5511746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 138, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9812315.0, \"count\": 1, \"min\": 9812315, \"max\": 9812315}, \"Total Batches Seen\": {\"sum\": 9870.0, \"count\": 1, \"min\": 9870, \"max\": 9870}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 140.0, \"count\": 1, \"min\": 140, \"max\": 140}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258332.46613724157 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, batch=0 train rmse <loss>=0.7735299818445953\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, batch=0 train mse <loss>=0.5983486328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, batch=0 train absolute_loss <loss>=0.603328857421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:43.830] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 280, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, train rmse <loss>=0.8503359369545905\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, train mse <loss>=0.7230712056764415\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=139, train absolute_loss <loss>=0.6442106116926166\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.5510817, \"EndTime\": 1716353083.8310955, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.4623374938965, \"count\": 1, \"min\": 279.4623374938965, \"max\": 279.4623374938965}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.5516086, \"EndTime\": 1716353083.8313122, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 139, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9882900.0, \"count\": 1, \"min\": 9882900, \"max\": 9882900}, \"Total Batches Seen\": {\"sum\": 9941.0, \"count\": 1, \"min\": 9941, \"max\": 9941}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 141.0, \"count\": 1, \"min\": 141, \"max\": 141}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252257.49674085865 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, batch=0 train rmse <loss>=0.7730751202836387\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, batch=0 train mse <loss>=0.5976451416015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, batch=0 train absolute_loss <loss>=0.602925537109375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:44:44.111] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 282, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, train rmse <loss>=0.8499261316092955\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, train mse <loss>=0.7223744291923415\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=140, train absolute_loss <loss>=0.6438357165699273\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.831161, \"EndTime\": 1716353084.112464, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.6134223937988, \"count\": 1, \"min\": 280.6134223937988, \"max\": 280.6134223937988}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 28.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353083.8318255, \"EndTime\": 1716353084.1126945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 140, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9953485.0, \"count\": 1, \"min\": 9953485, \"max\": 9953485}, \"Total Batches Seen\": {\"sum\": 10012.0, \"count\": 1, \"min\": 10012, \"max\": 10012}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 142.0, \"count\": 1, \"min\": 142, \"max\": 142}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251198.22890602265 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, batch=0 train rmse <loss>=0.7726251652619748\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, batch=0 train mse <loss>=0.5969496459960938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, batch=0 train absolute_loss <loss>=0.60252490234375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:44.389] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 284, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, train rmse <loss>=0.8495208512344846\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, train mse <loss>=0.7216856766821633\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=141, train absolute_loss <loss>=0.643465000206316\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.112524, \"EndTime\": 1716353084.3903577, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.3556709289551, \"count\": 1, \"min\": 277.3556709289551, \"max\": 277.3556709289551}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 28.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.1129758, \"EndTime\": 1716353084.390586, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 141, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10024070.0, \"count\": 1, \"min\": 10024070, \"max\": 10024070}, \"Total Batches Seen\": {\"sum\": 10083.0, \"count\": 1, \"min\": 10083, \"max\": 10083}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 143.0, \"count\": 1, \"min\": 143, \"max\": 143}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254144.27035931562 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, batch=0 train rmse <loss>=0.7721800858355112\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, batch=0 train mse <loss>=0.5962620849609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, batch=0 train absolute_loss <loss>=0.6021268310546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:44.665] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 286, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, train rmse <loss>=0.8491200739621586\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, train mse <loss>=0.7210049000055018\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=142, train absolute_loss <loss>=0.643098477215834\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.3904328, \"EndTime\": 1716353084.6658733, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.7223377227783, \"count\": 1, \"min\": 274.7223377227783, \"max\": 274.7223377227783}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 28.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.391126, \"EndTime\": 1716353084.6661081, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 142, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10094655.0, \"count\": 1, \"min\": 10094655, \"max\": 10094655}, \"Total Batches Seen\": {\"sum\": 10154.0, \"count\": 1, \"min\": 10154, \"max\": 10154}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 144.0, \"count\": 1, \"min\": 144, \"max\": 144}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256581.43374667634 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, batch=0 train rmse <loss>=0.7717397322643618\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, batch=0 train mse <loss>=0.5955822143554688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, batch=0 train absolute_loss <loss>=0.6017315673828125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:44.942] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 288, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, train rmse <loss>=0.8487236628499184\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, train mse <loss>=0.720331855881382\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=143, train absolute_loss <loss>=0.6427359283877091\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.6659489, \"EndTime\": 1716353084.942754, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.0968208312988, \"count\": 1, \"min\": 276.0968208312988, \"max\": 276.0968208312988}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 28.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.6666367, \"EndTime\": 1716353084.9429038, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 143, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10165240.0, \"count\": 1, \"min\": 10165240, \"max\": 10165240}, \"Total Batches Seen\": {\"sum\": 10225.0, \"count\": 1, \"min\": 10225, \"max\": 10225}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 145.0, \"count\": 1, \"min\": 145, \"max\": 145}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255413.7649714999 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, batch=0 train rmse <loss>=0.7713039939441638\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, batch=0 train mse <loss>=0.5949098510742188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, batch=0 train absolute_loss <loss>=0.6013387451171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:45.221] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 290, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, train rmse <loss>=0.848331564737953\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, train mse <loss>=0.7196664437307438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=144, train absolute_loss <loss>=0.6423778351259903\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.9428134, \"EndTime\": 1716353085.221775, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.34534645080566, \"count\": 1, \"min\": 278.34534645080566, \"max\": 278.34534645080566}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353084.943403, \"EndTime\": 1716353085.2220118, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 144, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10235825.0, \"count\": 1, \"min\": 10235825, \"max\": 10235825}, \"Total Batches Seen\": {\"sum\": 10296.0, \"count\": 1, \"min\": 10296, \"max\": 10296}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 146.0, \"count\": 1, \"min\": 146, \"max\": 146}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253232.34531743967 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, batch=0 train rmse <loss>=0.770872878701273\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, batch=0 train mse <loss>=0.5942449951171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, batch=0 train absolute_loss <loss>=0.600948486328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:45.494] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 292, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, train rmse <loss>=0.847943647224928\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, train mse <loss>=0.7190084288691131\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=145, train absolute_loss <loss>=0.6420235312018596\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.2218533, \"EndTime\": 1716353085.495053, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.4494934082031, \"count\": 1, \"min\": 272.4494934082031, \"max\": 272.4494934082031}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 29.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.2225814, \"EndTime\": 1716353085.4952042, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 145, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10306410.0, \"count\": 1, \"min\": 10306410, \"max\": 10306410}, \"Total Batches Seen\": {\"sum\": 10367.0, \"count\": 1, \"min\": 10367, \"max\": 10367}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 147.0, \"count\": 1, \"min\": 147, \"max\": 147}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258825.94199528254 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, batch=0 train rmse <loss>=0.770446235855397\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, batch=0 train mse <loss>=0.59358740234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, batch=0 train absolute_loss <loss>=0.6005606689453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:45.766] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 294, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, train rmse <loss>=0.8475598683806245\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, train mse <loss>=0.7183577304893816\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=146, train absolute_loss <loss>=0.6416732633348922\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.4951105, \"EndTime\": 1716353085.7671819, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.4669704437256, \"count\": 1, \"min\": 271.4669704437256, \"max\": 271.4669704437256}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 29.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.495691, \"EndTime\": 1716353085.7673366, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 146, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10376995.0, \"count\": 1, \"min\": 10376995, \"max\": 10376995}, \"Total Batches Seen\": {\"sum\": 10438.0, \"count\": 1, \"min\": 10438, \"max\": 10438}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 148.0, \"count\": 1, \"min\": 148, \"max\": 148}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259756.56539210698 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, batch=0 train rmse <loss>=0.7700240728405224\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, batch=0 train mse <loss>=0.5929370727539063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, batch=0 train absolute_loss <loss>=0.6001817016601563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:46.040] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 296, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, train rmse <loss>=0.8471801272840569\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, train mse <loss>=0.7177141680650309\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=147, train absolute_loss <loss>=0.6413272644902619\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.7672415, \"EndTime\": 1716353086.0407434, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.83406257629395, \"count\": 1, \"min\": 272.83406257629395, \"max\": 272.83406257629395}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 29.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353085.7678862, \"EndTime\": 1716353086.040891, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 147, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10447580.0, \"count\": 1, \"min\": 10447580, \"max\": 10447580}, \"Total Batches Seen\": {\"sum\": 10509.0, \"count\": 1, \"min\": 10509, \"max\": 10509}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 149.0, \"count\": 1, \"min\": 149, \"max\": 149}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258462.3713187952 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, batch=0 train rmse <loss>=0.7696061987613373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, batch=0 train mse <loss>=0.592293701171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, batch=0 train absolute_loss <loss>=0.5998053588867187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:46.313] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 298, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, train rmse <loss>=0.8468043131303657\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, train mse <loss>=0.7170775447361906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=148, train absolute_loss <loss>=0.6409850111410651\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.0407987, \"EndTime\": 1716353086.3142223, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.72677421569824, \"count\": 1, \"min\": 272.72677421569824, \"max\": 272.72677421569824}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 29.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.0414681, \"EndTime\": 1716353086.3144596, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 148, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10518165.0, \"count\": 1, \"min\": 10518165, \"max\": 10518165}, \"Total Batches Seen\": {\"sum\": 10580.0, \"count\": 1, \"min\": 10580, \"max\": 10580}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 150.0, \"count\": 1, \"min\": 150, \"max\": 150}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258445.22357036915 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, batch=0 train rmse <loss>=0.7691926206079048\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, batch=0 train mse <loss>=0.5916572875976562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, batch=0 train absolute_loss <loss>=0.5994315185546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:46.586] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 300, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, train rmse <loss>=0.8464323839240809\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, train mse <loss>=0.7164477805554027\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=149, train absolute_loss <loss>=0.6406460562692562\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.3143127, \"EndTime\": 1716353086.5873175, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.28379249572754, \"count\": 1, \"min\": 272.28379249572754, \"max\": 272.28379249572754}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.3150105, \"EndTime\": 1716353086.5875182, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 149, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10588750.0, \"count\": 1, \"min\": 10588750, \"max\": 10588750}, \"Total Batches Seen\": {\"sum\": 10651.0, \"count\": 1, \"min\": 10651, \"max\": 10651}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 151.0, \"count\": 1, \"min\": 151, \"max\": 151}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258921.0138724421 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, batch=0 train rmse <loss>=0.7687831468336626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, batch=0 train mse <loss>=0.5910275268554688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, batch=0 train absolute_loss <loss>=0.5990598754882812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:46.870] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 302, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, train rmse <loss>=0.846064228450061\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, train mse <loss>=0.7158246786627971\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=150, train absolute_loss <loss>=0.640311239752971\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.587382, \"EndTime\": 1716353086.8709915, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.8695774078369, \"count\": 1, \"min\": 282.8695774078369, \"max\": 282.8695774078369}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 30.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.5880966, \"EndTime\": 1716353086.8712325, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 150, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10659335.0, \"count\": 1, \"min\": 10659335, \"max\": 10659335}, \"Total Batches Seen\": {\"sum\": 10722.0, \"count\": 1, \"min\": 10722, \"max\": 10722}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 152.0, \"count\": 1, \"min\": 152, \"max\": 152}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249193.80383502055 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, batch=0 train rmse <loss>=0.7683779031510349\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, batch=0 train mse <loss>=0.5904046020507813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, batch=0 train absolute_loss <loss>=0.5986907958984375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:47.135] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 304, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, train rmse <loss>=0.8456998216501045\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, train mse <loss>=0.7152081883390184\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=151, train absolute_loss <loss>=0.6399803999779929\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.8710632, \"EndTime\": 1716353087.135728, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.9327049255371, \"count\": 1, \"min\": 263.9327049255371, \"max\": 263.9327049255371}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 30.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353086.871772, \"EndTime\": 1716353087.1358771, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 151, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10729920.0, \"count\": 1, \"min\": 10729920, \"max\": 10729920}, \"Total Batches Seen\": {\"sum\": 10793.0, \"count\": 1, \"min\": 10793, \"max\": 10793}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 153.0, \"count\": 1, \"min\": 153, \"max\": 153}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267170.35883524513 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, batch=0 train rmse <loss>=0.7679766180929599\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, batch=0 train mse <loss>=0.5897880859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, batch=0 train absolute_loss <loss>=0.5983239135742188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:47.424] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 306, \"duration\": 286, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, train rmse <loss>=0.8453390458321417\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, train mse <loss>=0.7145981024083957\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=152, train absolute_loss <loss>=0.6396528208557989\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.135785, \"EndTime\": 1716353087.4253688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.8352870941162, \"count\": 1, \"min\": 288.8352870941162, \"max\": 288.8352870941162}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 30.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.1365075, \"EndTime\": 1716353087.425652, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 152, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10800505.0, \"count\": 1, \"min\": 10800505, \"max\": 10800505}, \"Total Batches Seen\": {\"sum\": 10864.0, \"count\": 1, \"min\": 10864, \"max\": 10864}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 154.0, \"count\": 1, \"min\": 154, \"max\": 154}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=244031.1641175913 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, batch=0 train rmse <loss>=0.7675793376262686\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, batch=0 train mse <loss>=0.5891780395507813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, batch=0 train absolute_loss <loss>=0.59795947265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:47.717] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 308, \"duration\": 288, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, train rmse <loss>=0.8449818288364345\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, train mse <loss>=0.7139942910637654\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=153, train absolute_loss <loss>=0.6393282823159661\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.4254444, \"EndTime\": 1716353087.71756, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 291.32938385009766, \"count\": 1, \"min\": 291.32938385009766, \"max\": 291.32938385009766}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 30.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.4262042, \"EndTime\": 1716353087.7177794, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 153, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10871090.0, \"count\": 1, \"min\": 10871090, \"max\": 10871090}, \"Total Batches Seen\": {\"sum\": 10935.0, \"count\": 1, \"min\": 10935, \"max\": 10935}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 155.0, \"count\": 1, \"min\": 155, \"max\": 155}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=241992.39487136732 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, batch=0 train rmse <loss>=0.7671859486364151\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, batch=0 train mse <loss>=0.5885742797851562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, batch=0 train absolute_loss <loss>=0.5975972290039062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:47.981] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 310, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, train rmse <loss>=0.8446281293780238\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, train mse <loss>=0.7133966769366197\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=154, train absolute_loss <loss>=0.6390073388328015\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.7176325, \"EndTime\": 1716353087.9822288, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.18304443359375, \"count\": 1, \"min\": 264.18304443359375, \"max\": 264.18304443359375}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.7180214, \"EndTime\": 1716353087.9823778, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 154, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10941675.0, \"count\": 1, \"min\": 10941675, \"max\": 10941675}, \"Total Batches Seen\": {\"sum\": 11006.0, \"count\": 1, \"min\": 11006, \"max\": 11006}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 156.0, \"count\": 1, \"min\": 156, \"max\": 156}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266910.701439157 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, batch=0 train rmse <loss>=0.7667964571127236\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, batch=0 train mse <loss>=0.587976806640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, batch=0 train absolute_loss <loss>=0.597239013671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:48.245] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 312, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, train rmse <loss>=0.8442778729667118\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, train mse <loss>=0.712805126781195\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=155, train absolute_loss <loss>=0.6386897608797315\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.9822874, \"EndTime\": 1716353088.2457995, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.23962211608887, \"count\": 1, \"min\": 263.23962211608887, \"max\": 263.23962211608887}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 31.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353087.9825385, \"EndTime\": 1716353088.2459614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 155, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11012260.0, \"count\": 1, \"min\": 11012260, \"max\": 11012260}, \"Total Batches Seen\": {\"sum\": 11077.0, \"count\": 1, \"min\": 11077, \"max\": 11077}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 157.0, \"count\": 1, \"min\": 157, \"max\": 157}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267860.730888834 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, batch=0 train rmse <loss>=0.7664106699031572\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, batch=0 train mse <loss>=0.5873853149414062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, batch=0 train absolute_loss <loss>=0.5968853759765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:48.512] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 314, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, train rmse <loss>=0.8439309686478657\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, train mse <loss>=0.7122194798429248\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=156, train absolute_loss <loss>=0.6383755261058539\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.2458577, \"EndTime\": 1716353088.5126283, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.47472381591797, \"count\": 1, \"min\": 266.47472381591797, \"max\": 266.47472381591797}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 31.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.2461321, \"EndTime\": 1716353088.5127752, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 156, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11082845.0, \"count\": 1, \"min\": 11082845, \"max\": 11082845}, \"Total Batches Seen\": {\"sum\": 11148.0, \"count\": 1, \"min\": 11148, \"max\": 11148}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 158.0, \"count\": 1, \"min\": 158, \"max\": 158}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264628.9382751362 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, batch=0 train rmse <loss>=0.7660286324431067\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, batch=0 train mse <loss>=0.5867998657226563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, batch=0 train absolute_loss <loss>=0.5965352172851562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:48.786] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 316, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, train rmse <loss>=0.8435873792857216\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, train mse <loss>=0.7116396664901519\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=157, train absolute_loss <loss>=0.6380643310546875\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.512685, \"EndTime\": 1716353088.7867866, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.4105587005615, \"count\": 1, \"min\": 273.4105587005615, \"max\": 273.4105587005615}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 31.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.5133529, \"EndTime\": 1716353088.7869906, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 157, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11153430.0, \"count\": 1, \"min\": 11153430, \"max\": 11153430}, \"Total Batches Seen\": {\"sum\": 11219.0, \"count\": 1, \"min\": 11219, \"max\": 11219}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 159.0, \"count\": 1, \"min\": 159, \"max\": 159}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257850.07567714452 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, batch=0 train rmse <loss>=0.7656501909121096\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, batch=0 train mse <loss>=0.58622021484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, batch=0 train absolute_loss <loss>=0.5961928100585937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:49.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 318, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, train rmse <loss>=0.8432469922051345\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, train mse <loss>=0.7110654898630062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=158, train absolute_loss <loss>=0.6377566906566351\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.7868528, \"EndTime\": 1716353089.0704496, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.217191696167, \"count\": 1, \"min\": 283.217191696167, \"max\": 283.217191696167}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 31.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353088.7871985, \"EndTime\": 1716353089.0708177, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 158, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11224015.0, \"count\": 1, \"min\": 11224015, \"max\": 11224015}, \"Total Batches Seen\": {\"sum\": 11290.0, \"count\": 1, \"min\": 11290, \"max\": 11290}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 160.0, \"count\": 1, \"min\": 160, \"max\": 160}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248752.8518002247 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, batch=0 train rmse <loss>=0.7652753905228129\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, batch=0 train mse <loss>=0.5856464233398437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, batch=0 train absolute_loss <loss>=0.5958584594726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:49.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 320, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, train rmse <loss>=0.8429098117955074\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, train mse <loss>=0.7104969508211377\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=159, train absolute_loss <loss>=0.6374523676482724\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.0705209, \"EndTime\": 1716353089.3527195, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.4481258392334, \"count\": 1, \"min\": 281.4481258392334, \"max\": 281.4481258392334}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.0712295, \"EndTime\": 1716353089.3529432, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 159, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11294600.0, \"count\": 1, \"min\": 11294600, \"max\": 11294600}, \"Total Batches Seen\": {\"sum\": 11361.0, \"count\": 1, \"min\": 11361, \"max\": 11361}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 161.0, \"count\": 1, \"min\": 161, \"max\": 161}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250457.42112267006 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, batch=0 train rmse <loss>=0.7649041169358868\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, batch=0 train mse <loss>=0.5850783081054688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, batch=0 train absolute_loss <loss>=0.5955301513671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:49.630] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 322, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, train rmse <loss>=0.8425757138633742\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, train mse <loss>=0.7099338335923746\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=160, train absolute_loss <loss>=0.6371510860819212\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.3527956, \"EndTime\": 1716353089.6306148, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.4395942687988, \"count\": 1, \"min\": 277.4395942687988, \"max\": 277.4395942687988}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 32.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.3531487, \"EndTime\": 1716353089.6308293, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 160, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11365185.0, \"count\": 1, \"min\": 11365185, \"max\": 11365185}, \"Total Batches Seen\": {\"sum\": 11432.0, \"count\": 1, \"min\": 11432, \"max\": 11432}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 162.0, \"count\": 1, \"min\": 162, \"max\": 162}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254081.89001840894 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, batch=0 train rmse <loss>=0.7645362954564764\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, batch=0 train mse <loss>=0.5845157470703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, batch=0 train absolute_loss <loss>=0.5952041625976563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:49.915] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 324, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, train rmse <loss>=0.8422446882979816\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, train mse <loss>=0.7093761149661642\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=161, train absolute_loss <loss>=0.6368528175891285\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.6306827, \"EndTime\": 1716353089.9155579, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.466028213501, \"count\": 1, \"min\": 284.466028213501, \"max\": 284.466028213501}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 32.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.6310685, \"EndTime\": 1716353089.9157186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 161, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11435770.0, \"count\": 1, \"min\": 11435770, \"max\": 11435770}, \"Total Batches Seen\": {\"sum\": 11503.0, \"count\": 1, \"min\": 11503, \"max\": 11503}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247882.25420463402 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, batch=0 train rmse <loss>=0.7641718911339377\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, batch=0 train mse <loss>=0.5839586791992187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, batch=0 train absolute_loss <loss>=0.5948843383789062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:50.178] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 326, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, train rmse <loss>=0.8419166498908257\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, train mse <loss>=0.7088236453633913\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=162, train absolute_loss <loss>=0.636557343818772\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.9156117, \"EndTime\": 1716353090.1788063, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.8774642944336, \"count\": 1, \"min\": 262.8774642944336, \"max\": 262.8774642944336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 32.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353089.9159083, \"EndTime\": 1716353090.178962, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 162, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11506355.0, \"count\": 1, \"min\": 11506355, \"max\": 11506355}, \"Total Batches Seen\": {\"sum\": 11574.0, \"count\": 1, \"min\": 11574, \"max\": 11574}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 164.0, \"count\": 1, \"min\": 164, \"max\": 164}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268232.7718161424 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, batch=0 train rmse <loss>=0.7638108289503855\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, batch=0 train mse <loss>=0.583406982421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, batch=0 train absolute_loss <loss>=0.5945693359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:50.448] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 328, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, train rmse <loss>=0.8415915280792655\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, train mse <loss>=0.7082763001347931\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=163, train absolute_loss <loss>=0.6362643338055678\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.1788647, \"EndTime\": 1716353090.4488237, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.6723937988281, \"count\": 1, \"min\": 269.6723937988281, \"max\": 269.6723937988281}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 32.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.179129, \"EndTime\": 1716353090.4490566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 163, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11576940.0, \"count\": 1, \"min\": 11576940, \"max\": 11576940}, \"Total Batches Seen\": {\"sum\": 11645.0, \"count\": 1, \"min\": 11645, \"max\": 11645}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 165.0, \"count\": 1, \"min\": 165, \"max\": 165}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261386.0138879692 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, batch=0 train rmse <loss>=0.7634530736745546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, batch=0 train mse <loss>=0.582860595703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, batch=0 train absolute_loss <loss>=0.59425634765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:50.725] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 330, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, train rmse <loss>=0.841269326244794\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, train mse <loss>=0.7077340792803697\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=164, train absolute_loss <loss>=0.6359744752695863\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.448891, \"EndTime\": 1716353090.7263622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.8537998199463, \"count\": 1, \"min\": 276.8537998199463, \"max\": 276.8537998199463}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.4494863, \"EndTime\": 1716353090.7265477, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 164, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11647525.0, \"count\": 1, \"min\": 11647525, \"max\": 11647525}, \"Total Batches Seen\": {\"sum\": 11716.0, \"count\": 1, \"min\": 11716, \"max\": 11716}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 166.0, \"count\": 1, \"min\": 166, \"max\": 166}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254672.67545927197 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, batch=0 train rmse <loss>=0.7630985899658134\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, batch=0 train mse <loss>=0.5823194580078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, batch=0 train absolute_loss <loss>=0.5939453735351562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:51.001] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 332, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, train rmse <loss>=0.8409499266086241\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, train mse <loss>=0.7071967790630502\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=165, train absolute_loss <loss>=0.6356872274909221\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.726419, \"EndTime\": 1716353091.0021954, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.25877952575684, \"count\": 1, \"min\": 275.25877952575684, \"max\": 275.25877952575684}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 33.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353090.7269115, \"EndTime\": 1716353091.0024204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 165, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11718110.0, \"count\": 1, \"min\": 11718110, \"max\": 11718110}, \"Total Batches Seen\": {\"sum\": 11787.0, \"count\": 1, \"min\": 11787, \"max\": 11787}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 167.0, \"count\": 1, \"min\": 167, \"max\": 167}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256091.37637407315 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, batch=0 train rmse <loss>=0.7627473023653542\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, batch=0 train mse <loss>=0.581783447265625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, batch=0 train absolute_loss <loss>=0.5936371459960937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:51.285] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 334, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, train rmse <loss>=0.8406333160029\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, train mse <loss>=0.7066643719740316\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=166, train absolute_loss <loss>=0.6354030486630722\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.0022666, \"EndTime\": 1716353091.286512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.59484672546387, \"count\": 1, \"min\": 283.59484672546387, \"max\": 283.59484672546387}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 33.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.0028923, \"EndTime\": 1716353091.2867289, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 166, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11788695.0, \"count\": 1, \"min\": 11788695, \"max\": 11788695}, \"Total Batches Seen\": {\"sum\": 11858.0, \"count\": 1, \"min\": 11858, \"max\": 11858}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 168.0, \"count\": 1, \"min\": 168, \"max\": 168}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248568.6428739949 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, batch=0 train rmse <loss>=0.762399095206109\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, batch=0 train mse <loss>=0.5812523803710937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, batch=0 train absolute_loss <loss>=0.5933306274414063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:51.551] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 336, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, train rmse <loss>=0.8403194264813542\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, train mse <loss>=0.706136738521952\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=167, train absolute_loss <loss>=0.635121807259573\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.2865815, \"EndTime\": 1716353091.5517585, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.53471183776855, \"count\": 1, \"min\": 264.53471183776855, \"max\": 264.53471183776855}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 33.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.287202, \"EndTime\": 1716353091.5519435, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 167, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11859280.0, \"count\": 1, \"min\": 11859280, \"max\": 11859280}, \"Total Batches Seen\": {\"sum\": 11929.0, \"count\": 1, \"min\": 11929, \"max\": 11929}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 169.0, \"count\": 1, \"min\": 169, \"max\": 169}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266520.0009002383 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, batch=0 train rmse <loss>=0.762054012757216\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, batch=0 train mse <loss>=0.580726318359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, batch=0 train absolute_loss <loss>=0.5930291137695313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:51.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 338, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, train rmse <loss>=0.8400081802471314\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, train mse <loss>=0.7056137428820972\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=168, train absolute_loss <loss>=0.6348431319115867\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.5518143, \"EndTime\": 1716353091.8260913, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.73552322387695, \"count\": 1, \"min\": 273.73552322387695, \"max\": 273.73552322387695}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 33.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.5523317, \"EndTime\": 1716353091.826282, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 168, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11929865.0, \"count\": 1, \"min\": 11929865, \"max\": 11929865}, \"Total Batches Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 170.0, \"count\": 1, \"min\": 170, \"max\": 170}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257546.35873550808 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, batch=0 train rmse <loss>=0.7617119791365738\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, batch=0 train mse <loss>=0.5802051391601563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, batch=0 train absolute_loss <loss>=0.592733154296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:52.101] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 340, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, train rmse <loss>=0.8396995705138331\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, train mse <loss>=0.7050953687211158\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=169, train absolute_loss <loss>=0.6345668051276409\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.826153, \"EndTime\": 1716353092.1022992, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.56562423706055, \"count\": 1, \"min\": 275.56562423706055, \"max\": 275.56562423706055}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353091.82671, \"EndTime\": 1716353092.1025255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 169, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000450.0, \"count\": 1, \"min\": 12000450, \"max\": 12000450}, \"Total Batches Seen\": {\"sum\": 12071.0, \"count\": 1, \"min\": 12071, \"max\": 12071}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 171.0, \"count\": 1, \"min\": 171, \"max\": 171}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255799.07932879028 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, batch=0 train rmse <loss>=0.7613729182884856\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, batch=0 train mse <loss>=0.579688720703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, batch=0 train absolute_loss <loss>=0.5924393920898438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:52.375] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 342, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, train rmse <loss>=0.8393935126261356\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, train mse <loss>=0.7045814690388424\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=170, train absolute_loss <loss>=0.6342926033987126\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.102375, \"EndTime\": 1716353092.3761663, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.1912136077881, \"count\": 1, \"min\": 273.1912136077881, \"max\": 273.1912136077881}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 34.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.10295, \"EndTime\": 1716353092.3765228, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 170, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12071035.0, \"count\": 1, \"min\": 12071035, \"max\": 12071035}, \"Total Batches Seen\": {\"sum\": 12142.0, \"count\": 1, \"min\": 12142, \"max\": 12142}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 172.0, \"count\": 1, \"min\": 172, \"max\": 172}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257904.20971386658 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, batch=0 train rmse <loss>=0.7610367940862813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, batch=0 train mse <loss>=0.579177001953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, batch=0 train absolute_loss <loss>=0.5921471557617187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:52.653] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 344, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, train rmse <loss>=0.8390900273051936\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, train mse <loss>=0.7040720739230304\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=171, train absolute_loss <loss>=0.6340209032515405\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.3763394, \"EndTime\": 1716353092.6542397, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.23240852355957, \"count\": 1, \"min\": 277.23240852355957, \"max\": 277.23240852355957}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 34.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.3769846, \"EndTime\": 1716353092.654441, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 171, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12141620.0, \"count\": 1, \"min\": 12141620, \"max\": 12141620}, \"Total Batches Seen\": {\"sum\": 12213.0, \"count\": 1, \"min\": 12213, \"max\": 12213}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 173.0, \"count\": 1, \"min\": 173, \"max\": 173}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254295.11297712283 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, batch=0 train rmse <loss>=0.7607036104227166\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, batch=0 train mse <loss>=0.5786699829101563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, batch=0 train absolute_loss <loss>=0.5918595581054688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:52.925] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 346, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, train rmse <loss>=0.8387889707869044\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, train mse <loss>=0.7035669375137544\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=172, train absolute_loss <loss>=0.6337513866155919\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.6543028, \"EndTime\": 1716353092.926382, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.66748046875, \"count\": 1, \"min\": 271.66748046875, \"max\": 271.66748046875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 34.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.6546886, \"EndTime\": 1716353092.9266078, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 172, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12212205.0, \"count\": 1, \"min\": 12212205, \"max\": 12212205}, \"Total Batches Seen\": {\"sum\": 12284.0, \"count\": 1, \"min\": 12284, \"max\": 12284}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 174.0, \"count\": 1, \"min\": 174, \"max\": 174}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259463.123058222 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, batch=0 train rmse <loss>=0.7603732507583035\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, batch=0 train mse <loss>=0.57816748046875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, batch=0 train absolute_loss <loss>=0.5915756225585938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:53.229] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 348, \"duration\": 301, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, train rmse <loss>=0.8384903692678399\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, train mse <loss>=0.7030660993549186\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=173, train absolute_loss <loss>=0.6334845134036642\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.9264534, \"EndTime\": 1716353093.230297, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 303.41553688049316, \"count\": 1, \"min\": 303.41553688049316, \"max\": 303.41553688049316}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 34.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353092.9268575, \"EndTime\": 1716353093.2304869, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 173, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12282790.0, \"count\": 1, \"min\": 12282790, \"max\": 12282790}, \"Total Batches Seen\": {\"sum\": 12355.0, \"count\": 1, \"min\": 12355, \"max\": 12355}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 175.0, \"count\": 1, \"min\": 175, \"max\": 175}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=232387.14465691187 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, batch=0 train rmse <loss>=0.7600456786231667\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, batch=0 train mse <loss>=0.57766943359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, batch=0 train absolute_loss <loss>=0.5912978515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:53.504] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 350, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, train rmse <loss>=0.8381941689638583\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, train mse <loss>=0.7025694648850132\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=174, train absolute_loss <loss>=0.6332199655452244\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.2303615, \"EndTime\": 1716353093.5048938, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.17445182800293, \"count\": 1, \"min\": 274.17445182800293, \"max\": 274.17445182800293}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.2306943, \"EndTime\": 1716353093.5051174, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 174, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12353375.0, \"count\": 1, \"min\": 12353375, \"max\": 12353375}, \"Total Batches Seen\": {\"sum\": 12426.0, \"count\": 1, \"min\": 12426, \"max\": 12426}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 176.0, \"count\": 1, \"min\": 176, \"max\": 176}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257101.0530849874 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, batch=0 train rmse <loss>=0.7597208574535782\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, batch=0 train mse <loss>=0.57717578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, batch=0 train absolute_loss <loss>=0.5910223388671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:53.771] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 352, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, train rmse <loss>=0.8379002831631716\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, train mse <loss>=0.702076884524923\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=175, train absolute_loss <loss>=0.6329574954610475\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.5049622, \"EndTime\": 1716353093.771519, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.1247253417969, \"count\": 1, \"min\": 266.1247253417969, \"max\": 266.1247253417969}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 35.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.5053716, \"EndTime\": 1716353093.771737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 175, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12423960.0, \"count\": 1, \"min\": 12423960, \"max\": 12423960}, \"Total Batches Seen\": {\"sum\": 12497.0, \"count\": 1, \"min\": 12497, \"max\": 12497}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 177.0, \"count\": 1, \"min\": 177, \"max\": 177}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264878.95921889524 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, batch=0 train rmse <loss>=0.7593987505930885\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, batch=0 train mse <loss>=0.5766864624023438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, batch=0 train absolute_loss <loss>=0.5907482299804687\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:44:54.063] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 354, \"duration\": 289, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, train rmse <loss>=0.8376087117362124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, train mse <loss>=0.7015883539763974\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=176, train absolute_loss <loss>=0.632697090256382\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.771583, \"EndTime\": 1716353094.063723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 291.5372848510742, \"count\": 1, \"min\": 291.5372848510742, \"max\": 291.5372848510742}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 35.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353093.7721603, \"EndTime\": 1716353094.0639775, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 176, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12494545.0, \"count\": 1, \"min\": 12494545, \"max\": 12494545}, \"Total Batches Seen\": {\"sum\": 12568.0, \"count\": 1, \"min\": 12568, \"max\": 12568}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 178.0, \"count\": 1, \"min\": 178, \"max\": 178}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=241792.38449614428 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, batch=0 train rmse <loss>=0.7590793212936479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, batch=0 train mse <loss>=0.576201416015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, batch=0 train absolute_loss <loss>=0.5904755249023438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:54.324] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 356, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, train rmse <loss>=0.837319396527231\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, train mse <loss>=0.7011037718007262\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=177, train absolute_loss <loss>=0.6324384851590009\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.0637972, \"EndTime\": 1716353094.325328, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.08622550964355, \"count\": 1, \"min\": 261.08622550964355, \"max\": 261.08622550964355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 35.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.0642202, \"EndTime\": 1716353094.325478, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 177, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12565130.0, \"count\": 1, \"min\": 12565130, \"max\": 12565130}, \"Total Batches Seen\": {\"sum\": 12639.0, \"count\": 1, \"min\": 12639, \"max\": 12639}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 179.0, \"count\": 1, \"min\": 179, \"max\": 179}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270069.1630413266 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, batch=0 train rmse <loss>=0.7587625327167173\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, batch=0 train mse <loss>=0.5757205810546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, batch=0 train absolute_loss <loss>=0.5902042846679687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:54.602] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 358, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, train rmse <loss>=0.8370322823625738\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, train mse <loss>=0.7006230417170994\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=178, train absolute_loss <loss>=0.6321820291868397\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.3253858, \"EndTime\": 1716353094.6031163, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.44555473327637, \"count\": 1, \"min\": 277.44555473327637, \"max\": 277.44555473327637}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 35.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.3256464, \"EndTime\": 1716353094.6033537, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 178, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12635715.0, \"count\": 1, \"min\": 12635715, \"max\": 12635715}, \"Total Batches Seen\": {\"sum\": 12710.0, \"count\": 1, \"min\": 12710, \"max\": 12710}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 180.0, \"count\": 1, \"min\": 180, \"max\": 180}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254072.94989169575 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, batch=0 train rmse <loss>=0.7584483076975113\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, batch=0 train mse <loss>=0.5752438354492188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, batch=0 train absolute_loss <loss>=0.589934326171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:54.884] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 360, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, train rmse <loss>=0.8367473807543222\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, train mse <loss>=0.7001461791992187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=179, train absolute_loss <loss>=0.6319278100242077\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.6031888, \"EndTime\": 1716353094.8845284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.9295654296875, \"count\": 1, \"min\": 280.9295654296875, \"max\": 280.9295654296875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.603574, \"EndTime\": 1716353094.8847258, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 179, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12706300.0, \"count\": 1, \"min\": 12706300, \"max\": 12706300}, \"Total Batches Seen\": {\"sum\": 12781.0, \"count\": 1, \"min\": 12781, \"max\": 12781}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 181.0, \"count\": 1, \"min\": 181, \"max\": 181}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250953.99734512824 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, batch=0 train rmse <loss>=0.7581366494235843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, batch=0 train mse <loss>=0.5747711791992187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, batch=0 train absolute_loss <loss>=0.589665771484375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:55.168] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 362, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, train rmse <loss>=0.8364645870805684\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, train mse <loss>=0.6996730054398658\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=180, train absolute_loss <loss>=0.6316751623019367\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.8845932, \"EndTime\": 1716353095.1687505, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.71667861938477, \"count\": 1, \"min\": 283.71667861938477, \"max\": 283.71667861938477}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 36.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353094.8850098, \"EndTime\": 1716353095.168953, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 180, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12776885.0, \"count\": 1, \"min\": 12776885, \"max\": 12776885}, \"Total Batches Seen\": {\"sum\": 12852.0, \"count\": 1, \"min\": 12852, \"max\": 12852}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 182.0, \"count\": 1, \"min\": 182, \"max\": 182}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248436.81506053265 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, batch=0 train rmse <loss>=0.7578274402522112\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, batch=0 train mse <loss>=0.5743024291992187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, batch=0 train absolute_loss <loss>=0.5893985595703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:55.449] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 364, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, train rmse <loss>=0.8361838808625986\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, train mse <loss>=0.6992034826144367\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=181, train absolute_loss <loss>=0.6314244573888644\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.1688116, \"EndTime\": 1716353095.4498997, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.6849479675293, \"count\": 1, \"min\": 280.6849479675293, \"max\": 280.6849479675293}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 36.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.1691928, \"EndTime\": 1716353095.4501154, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 181, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12847470.0, \"count\": 1, \"min\": 12847470, \"max\": 12847470}, \"Total Batches Seen\": {\"sum\": 12923.0, \"count\": 1, \"min\": 12923, \"max\": 12923}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251163.70530052183 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, batch=0 train rmse <loss>=0.757520763754718\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, batch=0 train mse <loss>=0.5738377075195312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, batch=0 train absolute_loss <loss>=0.5891326904296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:55.717] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 366, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, train rmse <loss>=0.835905271402228\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, train mse <loss>=0.6987376227580325\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=182, train absolute_loss <loss>=0.6311757752324494\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.4499676, \"EndTime\": 1716353095.7177513, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.37284660339355, \"count\": 1, \"min\": 267.37284660339355, \"max\": 267.37284660339355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 36.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.450355, \"EndTime\": 1716353095.717946, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 182, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12918055.0, \"count\": 1, \"min\": 12918055, \"max\": 12918055}, \"Total Batches Seen\": {\"sum\": 12994.0, \"count\": 1, \"min\": 12994, \"max\": 12994}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 184.0, \"count\": 1, \"min\": 184, \"max\": 184}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263679.5781909772 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, batch=0 train rmse <loss>=0.757216461799089\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, batch=0 train mse <loss>=0.5733767700195312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, batch=0 train absolute_loss <loss>=0.5888681030273437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:55.998] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 368, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, train rmse <loss>=0.8356286687239063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, train mse <loss>=0.6982752719932879\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=183, train absolute_loss <loss>=0.6309286542005942\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.7178247, \"EndTime\": 1716353095.9989219, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.7729244232178, \"count\": 1, \"min\": 280.7729244232178, \"max\": 280.7729244232178}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 36.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.7181249, \"EndTime\": 1716353095.9991202, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 183, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12988640.0, \"count\": 1, \"min\": 12988640, \"max\": 12988640}, \"Total Batches Seen\": {\"sum\": 13065.0, \"count\": 1, \"min\": 13065, \"max\": 13065}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 185.0, \"count\": 1, \"min\": 185, \"max\": 185}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251107.03897119506 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, batch=0 train rmse <loss>=0.7569145372492319\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, batch=0 train mse <loss>=0.5729196166992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, batch=0 train absolute_loss <loss>=0.5886051025390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:56.276] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 370, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, train rmse <loss>=0.8353540516666862\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, train mse <loss>=0.6978163916359486\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=184, train absolute_loss <loss>=0.6306830874160981\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.9989839, \"EndTime\": 1716353096.277115, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.7700424194336, \"count\": 1, \"min\": 277.7700424194336, \"max\": 277.7700424194336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353095.999322, \"EndTime\": 1716353096.2773366, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 184, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13059225.0, \"count\": 1, \"min\": 13059225, \"max\": 13059225}, \"Total Batches Seen\": {\"sum\": 13136.0, \"count\": 1, \"min\": 13136, \"max\": 13136}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 186.0, \"count\": 1, \"min\": 186, \"max\": 186}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253781.1062802595 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, batch=0 train rmse <loss>=0.756614952616876\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, batch=0 train mse <loss>=0.5724661865234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, batch=0 train absolute_loss <loss>=0.588344482421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:56.556] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 372, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, train rmse <loss>=0.8350813907921546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, train mse <loss>=0.6973609292473592\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=185, train absolute_loss <loss>=0.6304393121423856\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.2771845, \"EndTime\": 1716353096.5570447, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.2377471923828, \"count\": 1, \"min\": 279.2377471923828, \"max\": 279.2377471923828}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 37.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.277782, \"EndTime\": 1716353096.5572612, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 185, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13129810.0, \"count\": 1, \"min\": 13129810, \"max\": 13129810}, \"Total Batches Seen\": {\"sum\": 13207.0, \"count\": 1, \"min\": 13207, \"max\": 13207}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 187.0, \"count\": 1, \"min\": 187, \"max\": 187}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252465.94503233267 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, batch=0 train rmse <loss>=0.7563177106826122\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, batch=0 train mse <loss>=0.5720164794921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, batch=0 train absolute_loss <loss>=0.5880851440429687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:56.827] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 374, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, train rmse <loss>=0.8348106777195163\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, train mse <loss>=0.6969088676345181\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=186, train absolute_loss <loss>=0.6301975467305788\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.557118, \"EndTime\": 1716353096.8284578, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.68638801574707, \"count\": 1, \"min\": 270.68638801574707, \"max\": 270.68638801574707}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 37.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.557749, \"EndTime\": 1716353096.8286264, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 186, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13200395.0, \"count\": 1, \"min\": 13200395, \"max\": 13200395}, \"Total Batches Seen\": {\"sum\": 13278.0, \"count\": 1, \"min\": 13278, \"max\": 13278}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 188.0, \"count\": 1, \"min\": 188, \"max\": 188}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260489.07234709006 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, batch=0 train rmse <loss>=0.7560227334777416\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, batch=0 train mse <loss>=0.5715703735351563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, batch=0 train absolute_loss <loss>=0.5878273315429687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:57.097] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 376, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, train rmse <loss>=0.8345417979445399\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, train mse <loss>=0.6964600125165052\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=187, train absolute_loss <loss>=0.6299577198297205\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.8285189, \"EndTime\": 1716353097.0980213, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.94450187683105, \"count\": 1, \"min\": 268.94450187683105, \"max\": 268.94450187683105}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 37.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353096.829051, \"EndTime\": 1716353097.0982652, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 187, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13270980.0, \"count\": 1, \"min\": 13270980, \"max\": 13270980}, \"Total Batches Seen\": {\"sum\": 13349.0, \"count\": 1, \"min\": 13349, \"max\": 13349}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 189.0, \"count\": 1, \"min\": 189, \"max\": 189}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262082.5033440301 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, batch=0 train rmse <loss>=0.7557299832725889\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, batch=0 train mse <loss>=0.5711278076171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, batch=0 train absolute_loss <loss>=0.5875711059570312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:57.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 378, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, train rmse <loss>=0.8342747836370676\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, train mse <loss>=0.6960144146126761\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=188, train absolute_loss <loss>=0.629719600193937\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.0980954, \"EndTime\": 1716353097.3746405, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.81787109375, \"count\": 1, \"min\": 275.81787109375, \"max\": 275.81787109375}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 37.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.0988, \"EndTime\": 1716353097.3747923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 188, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13341565.0, \"count\": 1, \"min\": 13341565, \"max\": 13341565}, \"Total Batches Seen\": {\"sum\": 13420.0, \"count\": 1, \"min\": 13420, \"max\": 13420}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 190.0, \"count\": 1, \"min\": 190, \"max\": 190}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255668.08338068647 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, batch=0 train rmse <loss>=0.755439422259075\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, batch=0 train mse <loss>=0.570688720703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, batch=0 train absolute_loss <loss>=0.5873164672851563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:57.643] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 380, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, train rmse <loss>=0.8340095938129687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, train mse <loss>=0.6955720025720731\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=189, train absolute_loss <loss>=0.6294830021388094\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.3746984, \"EndTime\": 1716353097.6442437, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.26231384277344, \"count\": 1, \"min\": 269.26231384277344, \"max\": 269.26231384277344}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.3749576, \"EndTime\": 1716353097.6444426, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 189, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13412150.0, \"count\": 1, \"min\": 13412150, \"max\": 13412150}, \"Total Batches Seen\": {\"sum\": 13491.0, \"count\": 1, \"min\": 13491, \"max\": 13491}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261836.11026207052 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, batch=0 train rmse <loss>=0.75515101255167\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, batch=0 train mse <loss>=0.5702530517578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, batch=0 train absolute_loss <loss>=0.5870647583007812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:57.913] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 382, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, train rmse <loss>=0.8337461863927408\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, train mse <loss>=0.6951327033244388\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=190, train absolute_loss <loss>=0.6292480838399538\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.6443264, \"EndTime\": 1716353097.9136062, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.6007022857666, \"count\": 1, \"min\": 268.6007022857666, \"max\": 268.6007022857666}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 38.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.6449823, \"EndTime\": 1716353097.913758, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 190, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13482735.0, \"count\": 1, \"min\": 13482735, \"max\": 13482735}, \"Total Batches Seen\": {\"sum\": 13562.0, \"count\": 1, \"min\": 13562, \"max\": 13562}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 192.0, \"count\": 1, \"min\": 192, \"max\": 192}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262531.5115372712 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, batch=0 train rmse <loss>=0.75486475661621\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, batch=0 train mse <loss>=0.56982080078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, batch=0 train absolute_loss <loss>=0.5868154296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:58.199] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 384, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, train rmse <loss>=0.8334845310930898\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, train mse <loss>=0.6946964635714679\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=191, train absolute_loss <loss>=0.6290146742270026\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.913665, \"EndTime\": 1716353098.1999362, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.62140464782715, \"count\": 1, \"min\": 285.62140464782715, \"max\": 285.62140464782715}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 38.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353097.9142902, \"EndTime\": 1716353098.200164, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 191, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13553320.0, \"count\": 1, \"min\": 13553320, \"max\": 13553320}, \"Total Batches Seen\": {\"sum\": 13633.0, \"count\": 1, \"min\": 13633, \"max\": 13633}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 193.0, \"count\": 1, \"min\": 193, \"max\": 193}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246815.5020054206 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, batch=0 train rmse <loss>=0.7545805760176477\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, batch=0 train mse <loss>=0.569391845703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, batch=0 train absolute_loss <loss>=0.586567138671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:58.474] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 386, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, train rmse <loss>=0.8332245686934884\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, train mse <loss>=0.6942631818744498\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=192, train absolute_loss <loss>=0.6287827200016505\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.200009, \"EndTime\": 1716353098.4746115, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.8916873931885, \"count\": 1, \"min\": 273.8916873931885, \"max\": 273.8916873931885}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 38.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.200697, \"EndTime\": 1716353098.4748278, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 192, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13623905.0, \"count\": 1, \"min\": 13623905, \"max\": 13623905}, \"Total Batches Seen\": {\"sum\": 13704.0, \"count\": 1, \"min\": 13704, \"max\": 13704}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 194.0, \"count\": 1, \"min\": 194, \"max\": 194}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257400.586903524 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, batch=0 train rmse <loss>=0.7542984731016213\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, batch=0 train mse <loss>=0.5689661865234374\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, batch=0 train absolute_loss <loss>=0.5863199462890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:58.742] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 388, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, train rmse <loss>=0.8329663539287429\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, train mse <loss>=0.6938329467773438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=193, train absolute_loss <loss>=0.6285525521291814\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.4746988, \"EndTime\": 1716353098.7425206, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.1630382537842, \"count\": 1, \"min\": 267.1630382537842, \"max\": 267.1630382537842}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 38.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.475335, \"EndTime\": 1716353098.7427204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 193, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13694490.0, \"count\": 1, \"min\": 13694490, \"max\": 13694490}, \"Total Batches Seen\": {\"sum\": 13775.0, \"count\": 1, \"min\": 13775, \"max\": 13775}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 195.0, \"count\": 1, \"min\": 195, \"max\": 195}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263892.51926904643 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, batch=0 train rmse <loss>=0.7540184097268655\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, batch=0 train mse <loss>=0.5685437622070313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, batch=0 train absolute_loss <loss>=0.5860739135742188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:59.010] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 390, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, train rmse <loss>=0.8327097650584978\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, train mse <loss>=0.6934055528237786\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=194, train absolute_loss <loss>=0.6283241061358384\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.7426171, \"EndTime\": 1716353099.0110502, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.777681350708, \"count\": 1, \"min\": 267.777681350708, \"max\": 267.777681350708}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353098.7432482, \"EndTime\": 1716353099.0112762, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 194, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13765075.0, \"count\": 1, \"min\": 13765075, \"max\": 13765075}, \"Total Batches Seen\": {\"sum\": 13846.0, \"count\": 1, \"min\": 13846, \"max\": 13846}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 196.0, \"count\": 1, \"min\": 196, \"max\": 196}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263230.6164321444 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, batch=0 train rmse <loss>=0.7537403071904764\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, batch=0 train mse <loss>=0.5681244506835937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, batch=0 train absolute_loss <loss>=0.5858289794921875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:59.283] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 392, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, train rmse <loss>=0.8324548092658877\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, train mse <loss>=0.6929810094699054\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=195, train absolute_loss <loss>=0.6280972969162633\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.011134, \"EndTime\": 1716353099.284272, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.4118232727051, \"count\": 1, \"min\": 272.4118232727051, \"max\": 272.4118232727051}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 39.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.0118377, \"EndTime\": 1716353099.284454, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 195, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13835660.0, \"count\": 1, \"min\": 13835660, \"max\": 13835660}, \"Total Batches Seen\": {\"sum\": 13917.0, \"count\": 1, \"min\": 13917, \"max\": 13917}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 197.0, \"count\": 1, \"min\": 197, \"max\": 197}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258828.2048000224 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, batch=0 train rmse <loss>=0.753464167663682\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, batch=0 train mse <loss>=0.567708251953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, batch=0 train absolute_loss <loss>=0.5855850219726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:59.555] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 394, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, train rmse <loss>=0.8322014679086853\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, train mse <loss>=0.6925592831893705\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=196, train absolute_loss <loss>=0.6278718304701254\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.2843518, \"EndTime\": 1716353099.5561624, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.1620330810547, \"count\": 1, \"min\": 271.1620330810547, \"max\": 271.1620330810547}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 39.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.284978, \"EndTime\": 1716353099.5563326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 196, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13906245.0, \"count\": 1, \"min\": 13906245, \"max\": 13906245}, \"Total Batches Seen\": {\"sum\": 13988.0, \"count\": 1, \"min\": 13988, \"max\": 13988}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 198.0, \"count\": 1, \"min\": 198, \"max\": 198}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260032.8562908806 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, batch=0 train rmse <loss>=0.753189952787787\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, batch=0 train mse <loss>=0.5672951049804688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, batch=0 train absolute_loss <loss>=0.5853421630859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:44:59.838] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 396, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, train rmse <loss>=0.8319496737475847\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, train mse <loss>=0.6921402596487126\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=197, train absolute_loss <loss>=0.6276478778677927\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.5562167, \"EndTime\": 1716353099.8393295, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.4394702911377, \"count\": 1, \"min\": 282.4394702911377, \"max\": 282.4394702911377}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 39.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.5568664, \"EndTime\": 1716353099.8395543, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 197, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13976830.0, \"count\": 1, \"min\": 13976830, \"max\": 13976830}, \"Total Batches Seen\": {\"sum\": 14059.0, \"count\": 1, \"min\": 14059, \"max\": 14059}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 199.0, \"count\": 1, \"min\": 199, \"max\": 199}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249595.07161458881 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, batch=0 train rmse <loss>=0.7529176646656823\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, batch=0 train mse <loss>=0.566885009765625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:44:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, batch=0 train absolute_loss <loss>=0.5851004028320312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:00.107] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 398, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, train rmse <loss>=0.8316994566119941\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, train mse <loss>=0.6917239861286861\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=198, train absolute_loss <loss>=0.6274253505653059\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.8394005, \"EndTime\": 1716353100.1075988, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.50946044921875, \"count\": 1, \"min\": 267.50946044921875, \"max\": 267.50946044921875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 39.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353099.840066, \"EndTime\": 1716353100.1077666, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 198, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14047415.0, \"count\": 1, \"min\": 14047415, \"max\": 14047415}, \"Total Batches Seen\": {\"sum\": 14130.0, \"count\": 1, \"min\": 14130, \"max\": 14130}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263583.32703284296 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, batch=0 train rmse <loss>=0.7526472242945438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, batch=0 train mse <loss>=0.5664778442382813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, batch=0 train absolute_loss <loss>=0.5848596801757813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:00.386] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 400, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, train rmse <loss>=0.831450742449833\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, train mse <loss>=0.6913103371203785\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=199, train absolute_loss <loss>=0.6272042734925176\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.1076534, \"EndTime\": 1716353100.3871946, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.92398834228516, \"count\": 1, \"min\": 278.92398834228516, \"max\": 278.92398834228516}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.1082456, \"EndTime\": 1716353100.387405, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 199, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14118000.0, \"count\": 1, \"min\": 14118000, \"max\": 14118000}, \"Total Batches Seen\": {\"sum\": 14201.0, \"count\": 1, \"min\": 14201, \"max\": 14201}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 201.0, \"count\": 1, \"min\": 201, \"max\": 201}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252749.80692132743 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, batch=0 train rmse <loss>=0.7523786336668775\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, batch=0 train mse <loss>=0.5660736083984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, batch=0 train absolute_loss <loss>=0.5846213989257812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:00.655] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 402, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, train rmse <loss>=0.8312035414011667\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, train mse <loss>=0.6908993272378411\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=200, train absolute_loss <loss>=0.6269847403512874\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.3872633, \"EndTime\": 1716353100.6559858, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.85755157470703, \"count\": 1, \"min\": 267.85755157470703, \"max\": 267.85755157470703}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 40.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.3881035, \"EndTime\": 1716353100.6561375, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 200, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14188585.0, \"count\": 1, \"min\": 14188585, \"max\": 14188585}, \"Total Batches Seen\": {\"sum\": 14272.0, \"count\": 1, \"min\": 14272, \"max\": 14272}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 202.0, \"count\": 1, \"min\": 202, \"max\": 202}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263247.0006437684 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, batch=0 train rmse <loss>=0.7521118136126976\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, batch=0 train mse <loss>=0.5656721801757812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, batch=0 train absolute_loss <loss>=0.584384033203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:00.931] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 404, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, train rmse <loss>=0.8309577565361294\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, train mse <loss>=0.6904907931475572\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=201, train absolute_loss <loss>=0.6267666840889085\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.656045, \"EndTime\": 1716353100.9321933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.4507064819336, \"count\": 1, \"min\": 275.4507064819336, \"max\": 275.4507064819336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 40.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.656718, \"EndTime\": 1716353100.9324684, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 201, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14259170.0, \"count\": 1, \"min\": 14259170, \"max\": 14259170}, \"Total Batches Seen\": {\"sum\": 14343.0, \"count\": 1, \"min\": 14343, \"max\": 14343}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 203.0, \"count\": 1, \"min\": 203, \"max\": 203}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255855.00884955752 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, batch=0 train rmse <loss>=0.7518468471973697\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, batch=0 train mse <loss>=0.565273681640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, batch=0 train absolute_loss <loss>=0.5841477661132812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:01.207] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 406, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, train rmse <loss>=0.8307134656894276\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, train mse <loss>=0.6900848620777399\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=202, train absolute_loss <loss>=0.6265502370914943\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.932271, \"EndTime\": 1716353101.2083833, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.59471130371094, \"count\": 1, \"min\": 275.59471130371094, \"max\": 275.59471130371094}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 40.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353100.9327655, \"EndTime\": 1716353101.2085395, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 202, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14329755.0, \"count\": 1, \"min\": 14329755, \"max\": 14329755}, \"Total Batches Seen\": {\"sum\": 14414.0, \"count\": 1, \"min\": 14414, \"max\": 14414}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 204.0, \"count\": 1, \"min\": 204, \"max\": 204}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255862.5269340395 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, batch=0 train rmse <loss>=0.7515835739638964\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, batch=0 train mse <loss>=0.5648778686523438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, batch=0 train absolute_loss <loss>=0.583912353515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:01.579] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 408, \"duration\": 368, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, train rmse <loss>=0.8304705620077816\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, train mse <loss>=0.6896813543615207\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=203, train absolute_loss <loss>=0.6263348509022887\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.208444, \"EndTime\": 1716353101.580038, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 371.29902839660645, \"count\": 1, \"min\": 371.29902839660645, \"max\": 371.29902839660645}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 40.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.2087123, \"EndTime\": 1716353101.5802464, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 203, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14400340.0, \"count\": 1, \"min\": 14400340, \"max\": 14400340}, \"Total Batches Seen\": {\"sum\": 14485.0, \"count\": 1, \"min\": 14485, \"max\": 14485}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 205.0, \"count\": 1, \"min\": 205, \"max\": 205}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=189910.0454288284 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, batch=0 train rmse <loss>=0.7513220363107246\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, batch=0 train mse <loss>=0.5644848022460938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, batch=0 train absolute_loss <loss>=0.5836779174804687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:01.908] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 410, \"duration\": 325, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, train rmse <loss>=0.83022905343908\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, train mse <loss>=0.6892802811743508\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=204, train absolute_loss <loss>=0.6261206200828014\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.5800993, \"EndTime\": 1716353101.908501, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 327.9545307159424, \"count\": 1, \"min\": 327.9545307159424, \"max\": 327.9545307159424}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.5805223, \"EndTime\": 1716353101.9086497, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 204, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14470925.0, \"count\": 1, \"min\": 14470925, \"max\": 14470925}, \"Total Batches Seen\": {\"sum\": 14556.0, \"count\": 1, \"min\": 14556, \"max\": 14556}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 206.0, \"count\": 1, \"min\": 206, \"max\": 206}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=215053.21785569267 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, batch=0 train rmse <loss>=0.7510621954184079\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, batch=0 train mse <loss>=0.5640944213867187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, batch=0 train absolute_loss <loss>=0.5834443969726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:02.272] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 412, \"duration\": 361, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, train rmse <loss>=0.829988913754139\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, train mse <loss>=0.6888815969547756\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=205, train absolute_loss <loss>=0.625907695071798\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.9085593, \"EndTime\": 1716353102.273824, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 364.9911880493164, \"count\": 1, \"min\": 364.9911880493164, \"max\": 364.9911880493164}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #progress_metric: host=algo-1, completed 41.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353101.9088097, \"EndTime\": 1716353102.2740846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 205, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14541510.0, \"count\": 1, \"min\": 14541510, \"max\": 14541510}, \"Total Batches Seen\": {\"sum\": 14627.0, \"count\": 1, \"min\": 14627, \"max\": 14627}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 207.0, \"count\": 1, \"min\": 207, \"max\": 207}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=193176.2378863134 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, batch=0 train rmse <loss>=0.7508040530486092\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, batch=0 train mse <loss>=0.5637067260742188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, batch=0 train absolute_loss <loss>=0.5832118530273438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:02.615] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 414, \"duration\": 338, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, train rmse <loss>=0.8297501058081814\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, train mse <loss>=0.6884852380886883\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=206, train absolute_loss <loss>=0.6256961953606404\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353102.273905, \"EndTime\": 1716353102.616193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 341.85194969177246, \"count\": 1, \"min\": 341.85194969177246, \"max\": 341.85194969177246}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #progress_metric: host=algo-1, completed 41.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353102.274314, \"EndTime\": 1716353102.6164527, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 206, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14612095.0, \"count\": 1, \"min\": 14612095, \"max\": 14612095}, \"Total Batches Seen\": {\"sum\": 14698.0, \"count\": 1, \"min\": 14698, \"max\": 14698}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 208.0, \"count\": 1, \"min\": 208, \"max\": 208}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=206225.85330311107 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, batch=0 train rmse <loss>=0.7505474889726332\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, batch=0 train mse <loss>=0.563321533203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, batch=0 train absolute_loss <loss>=0.5829801025390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:03.016] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 416, \"duration\": 397, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, train rmse <loss>=0.8295126188335759\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, train mse <loss>=0.6880911848041373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=207, train absolute_loss <loss>=0.6254858982999559\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353102.616266, \"EndTime\": 1716353103.0171447, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 400.4015922546387, \"count\": 1, \"min\": 400.4015922546387, \"max\": 400.4015922546387}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 41.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353102.6167178, \"EndTime\": 1716353103.017333, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 207, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14682680.0, \"count\": 1, \"min\": 14682680, \"max\": 14682680}, \"Total Batches Seen\": {\"sum\": 14769.0, \"count\": 1, \"min\": 14769, \"max\": 14769}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 209.0, \"count\": 1, \"min\": 209, \"max\": 209}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=176145.5952973095 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, batch=0 train rmse <loss>=0.75029258615806\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, batch=0 train mse <loss>=0.56293896484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, batch=0 train absolute_loss <loss>=0.582749267578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:03.408] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 418, \"duration\": 389, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, train rmse <loss>=0.8292764342693086\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, train mse <loss>=0.687699404434419\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=208, train absolute_loss <loss>=0.6252769276793574\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.0172026, \"EndTime\": 1716353103.409438, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 391.8623924255371, \"count\": 1, \"min\": 391.8623924255371, \"max\": 391.8623924255371}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 41.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.0175521, \"EndTime\": 1716353103.4098096, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 208, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14753265.0, \"count\": 1, \"min\": 14753265, \"max\": 14753265}, \"Total Batches Seen\": {\"sum\": 14840.0, \"count\": 1, \"min\": 14840, \"max\": 14840}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 210.0, \"count\": 1, \"min\": 210, \"max\": 210}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=179883.38176321046 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, batch=0 train rmse <loss>=0.7500392649226981\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, batch=0 train mse <loss>=0.5625588989257813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, batch=0 train absolute_loss <loss>=0.5825193481445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:03.797] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 420, \"duration\": 385, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, train rmse <loss>=0.8290414863471381\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, train mse <loss>=0.6873097860846721\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=209, train absolute_loss <loss>=0.6250693282006492\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.4095721, \"EndTime\": 1716353103.799586, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 389.35327529907227, \"count\": 1, \"min\": 389.35327529907227, \"max\": 389.35327529907227}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.4102044, \"EndTime\": 1716353103.7999353, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 209, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14823850.0, \"count\": 1, \"min\": 14823850, \"max\": 14823850}, \"Total Batches Seen\": {\"sum\": 14911.0, \"count\": 1, \"min\": 14911, \"max\": 14911}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 211.0, \"count\": 1, \"min\": 211, \"max\": 211}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=181053.76227772285 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, batch=0 train rmse <loss>=0.7497874861679558\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, batch=0 train mse <loss>=0.5621812744140625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, batch=0 train absolute_loss <loss>=0.5822902221679688\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:04.136] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 422, \"duration\": 333, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, train rmse <loss>=0.8288078160514374\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, train mse <loss>=0.6869223959479533\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=210, train absolute_loss <loss>=0.6248632735131492\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.7996507, \"EndTime\": 1716353104.1369464, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 336.58361434936523, \"count\": 1, \"min\": 336.58361434936523, \"max\": 336.58361434936523}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 42.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353103.8003318, \"EndTime\": 1716353104.1373003, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 210, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14894435.0, \"count\": 1, \"min\": 14894435, \"max\": 14894435}, \"Total Batches Seen\": {\"sum\": 14982.0, \"count\": 1, \"min\": 14982, \"max\": 14982}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 212.0, \"count\": 1, \"min\": 212, \"max\": 212}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=209357.7924206745 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, batch=0 train rmse <loss>=0.7495372514482477\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, batch=0 train mse <loss>=0.5618060913085937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, batch=0 train absolute_loss <loss>=0.58206201171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:04.419] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 424, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, train rmse <loss>=0.8285753668816753\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, train mse <loss>=0.686537138603103\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=211, train absolute_loss <loss>=0.6246585581604863\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.1370232, \"EndTime\": 1716353104.4204965, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.8190326690674, \"count\": 1, \"min\": 282.8190326690674, \"max\": 282.8190326690674}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 42.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.1376522, \"EndTime\": 1716353104.420656, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 211, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14965020.0, \"count\": 1, \"min\": 14965020, \"max\": 14965020}, \"Total Batches Seen\": {\"sum\": 15053.0, \"count\": 1, \"min\": 15053, \"max\": 15053}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 213.0, \"count\": 1, \"min\": 213, \"max\": 213}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249294.31465208004 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, batch=0 train rmse <loss>=0.749288521581786\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, batch=0 train mse <loss>=0.5614332885742187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, batch=0 train absolute_loss <loss>=0.5818345947265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:04.693] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 426, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, train rmse <loss>=0.8283441274123448\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, train mse <loss>=0.6861539934185189\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=212, train absolute_loss <loss>=0.624455087581151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.42056, \"EndTime\": 1716353104.6942697, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.252010345459, \"count\": 1, \"min\": 273.252010345459, \"max\": 273.252010345459}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 42.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.4209952, \"EndTime\": 1716353104.6944242, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 212, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15035605.0, \"count\": 1, \"min\": 15035605, \"max\": 15035605}, \"Total Batches Seen\": {\"sum\": 15124.0, \"count\": 1, \"min\": 15124, \"max\": 15124}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 214.0, \"count\": 1, \"min\": 214, \"max\": 214}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258061.3495323942 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, batch=0 train rmse <loss>=0.749041298067695\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, batch=0 train mse <loss>=0.5610628662109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, batch=0 train absolute_loss <loss>=0.5816080322265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:04.962] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 428, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, train rmse <loss>=0.8281140638810847\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, train mse <loss>=0.6857729027976452\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=213, train absolute_loss <loss>=0.6242527525995819\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.694329, \"EndTime\": 1716353104.9625807, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.9638862609863, \"count\": 1, \"min\": 267.9638862609863, \"max\": 267.9638862609863}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 42.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.6945915, \"EndTime\": 1716353104.9628015, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 213, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15106190.0, \"count\": 1, \"min\": 15106190, \"max\": 15106190}, \"Total Batches Seen\": {\"sum\": 15195.0, \"count\": 1, \"min\": 15195, \"max\": 15195}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 215.0, \"count\": 1, \"min\": 215, \"max\": 215}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263064.31514231715 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, batch=0 train rmse <loss>=0.7487955008868827\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, batch=0 train mse <loss>=0.5606947021484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, batch=0 train absolute_loss <loss>=0.5813822631835938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:05.238] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 430, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, train rmse <loss>=0.8278851637694564\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, train mse <loss>=0.6853938443895796\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=214, train absolute_loss <loss>=0.6240515343034772\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.96265, \"EndTime\": 1716353105.239447, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.3681411743164, \"count\": 1, \"min\": 276.3681411743164, \"max\": 276.3681411743164}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353104.9630523, \"EndTime\": 1716353105.2396421, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 214, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15176775.0, \"count\": 1, \"min\": 15176775, \"max\": 15176775}, \"Total Batches Seen\": {\"sum\": 15266.0, \"count\": 1, \"min\": 15266, \"max\": 15266}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 216.0, \"count\": 1, \"min\": 216, \"max\": 216}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255104.10610361164 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, batch=0 train rmse <loss>=0.7485511722132796\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, batch=0 train mse <loss>=0.560328857421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, batch=0 train absolute_loss <loss>=0.5811572875976563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:05.517] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 432, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, train rmse <loss>=0.8276573875352139\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, train mse <loss>=0.6850167511416153\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=215, train absolute_loss <loss>=0.6238513888506823\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.2395086, \"EndTime\": 1716353105.5180979, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.05018424987793, \"count\": 1, \"min\": 278.05018424987793, \"max\": 278.05018424987793}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 43.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.2400236, \"EndTime\": 1716353105.5183089, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 215, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15247360.0, \"count\": 1, \"min\": 15247360, \"max\": 15247360}, \"Total Batches Seen\": {\"sum\": 15337.0, \"count\": 1, \"min\": 15337, \"max\": 15337}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 217.0, \"count\": 1, \"min\": 217, \"max\": 217}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253530.96043852717 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, batch=0 train rmse <loss>=0.7483082727032314\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, batch=0 train mse <loss>=0.5599652709960937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, batch=0 train absolute_loss <loss>=0.58093310546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:05.797] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 434, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, train rmse <loss>=0.827430760002102\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, train mse <loss>=0.6846416625976562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=216, train absolute_loss <loss>=0.6236525552239216\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.5181649, \"EndTime\": 1716353105.7982352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.6363830566406, \"count\": 1, \"min\": 279.6363830566406, \"max\": 279.6363830566406}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 43.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.5185714, \"EndTime\": 1716353105.7984455, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 216, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15317945.0, \"count\": 1, \"min\": 15317945, \"max\": 15317945}, \"Total Batches Seen\": {\"sum\": 15408.0, \"count\": 1, \"min\": 15408, \"max\": 15408}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 218.0, \"count\": 1, \"min\": 218, \"max\": 218}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252087.16496298157 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, batch=0 train rmse <loss>=0.74806676295364\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, batch=0 train mse <loss>=0.5596038818359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, batch=0 train absolute_loss <loss>=0.580709716796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:06.063] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 436, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, train rmse <loss>=0.8272052265158526\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, train mse <loss>=0.6842684867751431\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=217, train absolute_loss <loss>=0.6234545743700484\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.7983048, \"EndTime\": 1716353106.0636723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.7662162780762, \"count\": 1, \"min\": 264.7662162780762, \"max\": 264.7662162780762}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 43.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353105.7988837, \"EndTime\": 1716353106.063833, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 217, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15388530.0, \"count\": 1, \"min\": 15388530, \"max\": 15388530}, \"Total Batches Seen\": {\"sum\": 15479.0, \"count\": 1, \"min\": 15479, \"max\": 15479}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 219.0, \"count\": 1, \"min\": 219, \"max\": 219}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266320.0481446065 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, batch=0 train rmse <loss>=0.7478265626942479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, batch=0 train mse <loss>=0.5592445678710938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, batch=0 train absolute_loss <loss>=0.580487060546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:06.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 438, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, train rmse <loss>=0.8269807692604905\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, train mse <loss>=0.6838971927266725\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=218, train absolute_loss <loss>=0.6232576706577355\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.0637333, \"EndTime\": 1716353106.3395607, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.51984786987305, \"count\": 1, \"min\": 275.51984786987305, \"max\": 275.51984786987305}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 43.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.0640173, \"EndTime\": 1716353106.3397603, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 218, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15459115.0, \"count\": 1, \"min\": 15459115, \"max\": 15459115}, \"Total Batches Seen\": {\"sum\": 15550.0, \"count\": 1, \"min\": 15550, \"max\": 15550}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 220.0, \"count\": 1, \"min\": 220, \"max\": 220}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255891.71897931985 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, batch=0 train rmse <loss>=0.7475877140086765\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, batch=0 train mse <loss>=0.5588873901367187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, batch=0 train absolute_loss <loss>=0.5802673950195313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:06.622] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 440, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, train rmse <loss>=0.8267573766351545\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, train mse <loss>=0.6835277598206426\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=219, train absolute_loss <loss>=0.6230617435079225\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.3396285, \"EndTime\": 1716353106.6227856, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.76515007019043, \"count\": 1, \"min\": 282.76515007019043, \"max\": 282.76515007019043}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.3399956, \"EndTime\": 1716353106.6230056, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 219, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15529700.0, \"count\": 1, \"min\": 15529700, \"max\": 15529700}, \"Total Batches Seen\": {\"sum\": 15621.0, \"count\": 1, \"min\": 15621, \"max\": 15621}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 221.0, \"count\": 1, \"min\": 221, \"max\": 221}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249299.35281773875 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, batch=0 train rmse <loss>=0.7473502181927911\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, batch=0 train mse <loss>=0.5585323486328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, batch=0 train absolute_loss <loss>=0.5800486450195312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:06.899] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 442, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, train rmse <loss>=0.8265350261016162\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, train mse <loss>=0.6831601493727993\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=220, train absolute_loss <loss>=0.6228666442011443\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.6228569, \"EndTime\": 1716353106.9002428, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.95727348327637, \"count\": 1, \"min\": 276.95727348327637, \"max\": 276.95727348327637}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 44.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.6232588, \"EndTime\": 1716353106.9004862, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 220, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15600285.0, \"count\": 1, \"min\": 15600285, \"max\": 15600285}, \"Total Batches Seen\": {\"sum\": 15692.0, \"count\": 1, \"min\": 15692, \"max\": 15692}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 222.0, \"count\": 1, \"min\": 222, \"max\": 222}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254508.25652077855 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, batch=0 train rmse <loss>=0.7471140356894781\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, batch=0 train mse <loss>=0.5581793823242187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, batch=0 train absolute_loss <loss>=0.5798322143554687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:07.176] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 444, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, train rmse <loss>=0.8263137018556208\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, train mse <loss>=0.6827943338743397\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=221, train absolute_loss <loss>=0.622672519737566\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.9003463, \"EndTime\": 1716353107.177616, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.72529220581055, \"count\": 1, \"min\": 276.72529220581055, \"max\": 276.72529220581055}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 44.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353106.9008658, \"EndTime\": 1716353107.1778371, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 221, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15670870.0, \"count\": 1, \"min\": 15670870, \"max\": 15670870}, \"Total Batches Seen\": {\"sum\": 15763.0, \"count\": 1, \"min\": 15763, \"max\": 15763}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 223.0, \"count\": 1, \"min\": 223, \"max\": 223}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254744.7714649322 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, batch=0 train rmse <loss>=0.7468791268845189\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, batch=0 train mse <loss>=0.5578284301757812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, batch=0 train absolute_loss <loss>=0.5796183471679688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:07.454] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 446, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, train rmse <loss>=0.826093358934725\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, train mse <loss>=0.6824302376760564\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=222, train absolute_loss <loss>=0.6224793271346831\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.1776896, \"EndTime\": 1716353107.4553971, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.2815227508545, \"count\": 1, \"min\": 277.2815227508545, \"max\": 277.2815227508545}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 44.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.178091, \"EndTime\": 1716353107.455552, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 222, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15741455.0, \"count\": 1, \"min\": 15741455, \"max\": 15741455}, \"Total Batches Seen\": {\"sum\": 15834.0, \"count\": 1, \"min\": 15834, \"max\": 15834}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 224.0, \"count\": 1, \"min\": 224, \"max\": 224}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254307.78229796592 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, batch=0 train rmse <loss>=0.7466454929801023\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, batch=0 train mse <loss>=0.5574794921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, batch=0 train absolute_loss <loss>=0.579406494140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:07.741] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 448, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, train rmse <loss>=0.8258740465261074\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, train mse <loss>=0.6820679407254071\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=223, train absolute_loss <loss>=0.6222869666730854\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.4554572, \"EndTime\": 1716353107.741995, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.24987602233887, \"count\": 1, \"min\": 286.24987602233887, \"max\": 286.24987602233887}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 44.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.455723, \"EndTime\": 1716353107.7421536, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 223, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15812040.0, \"count\": 1, \"min\": 15812040, \"max\": 15812040}, \"Total Batches Seen\": {\"sum\": 15905.0, \"count\": 1, \"min\": 15905, \"max\": 15905}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 225.0, \"count\": 1, \"min\": 225, \"max\": 225}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246351.55151037063 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, batch=0 train rmse <loss>=0.746413053402111\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, batch=0 train mse <loss>=0.5571324462890626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, batch=0 train absolute_loss <loss>=0.5791952514648437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:08.007] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 450, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, train rmse <loss>=0.8256556691424858\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, train mse <loss>=0.6817072839871259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=224, train absolute_loss <loss>=0.622095428896622\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.7420554, \"EndTime\": 1716353108.0074704, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.12646675109863, \"count\": 1, \"min\": 265.12646675109863, \"max\": 265.12646675109863}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353107.7423215, \"EndTime\": 1716353108.0076213, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 224, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15882625.0, \"count\": 1, \"min\": 15882625, \"max\": 15882625}, \"Total Batches Seen\": {\"sum\": 15976.0, \"count\": 1, \"min\": 15976, \"max\": 15976}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 226.0, \"count\": 1, \"min\": 226, \"max\": 226}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265966.67035596987 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, batch=0 train rmse <loss>=0.7461818501649748\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, batch=0 train mse <loss>=0.556787353515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, batch=0 train absolute_loss <loss>=0.5789905395507813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:08.289] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 452, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, train rmse <loss>=0.8254382467927361\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, train mse <loss>=0.6813482992682659\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=225, train absolute_loss <loss>=0.6219048032089018\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.0075288, \"EndTime\": 1716353108.2899306, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.1023464202881, \"count\": 1, \"min\": 282.1023464202881, \"max\": 282.1023464202881}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 45.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.007806, \"EndTime\": 1716353108.29009, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 225, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15953210.0, \"count\": 1, \"min\": 15953210, \"max\": 15953210}, \"Total Batches Seen\": {\"sum\": 16047.0, \"count\": 1, \"min\": 16047, \"max\": 16047}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 227.0, \"count\": 1, \"min\": 227, \"max\": 227}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249971.2483746441 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, batch=0 train rmse <loss>=0.7459518435073617\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, batch=0 train mse <loss>=0.5564441528320313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, batch=0 train absolute_loss <loss>=0.5787869262695312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:08.560] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 454, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, train rmse <loss>=0.8252217953366716\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, train mse <loss>=0.6809910114986796\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=226, train absolute_loss <loss>=0.6217150621011224\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.2899983, \"EndTime\": 1716353108.5613985, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.1210250854492, \"count\": 1, \"min\": 271.1210250854492, \"max\": 271.1210250854492}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 45.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.290252, \"EndTime\": 1716353108.5616016, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 226, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16023795.0, \"count\": 1, \"min\": 16023795, \"max\": 16023795}, \"Total Batches Seen\": {\"sum\": 16118.0, \"count\": 1, \"min\": 16118, \"max\": 16118}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 228.0, \"count\": 1, \"min\": 228, \"max\": 228}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260025.31951707506 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, batch=0 train rmse <loss>=0.7457229936129937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, batch=0 train mse <loss>=0.556102783203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, batch=0 train absolute_loss <loss>=0.5785838623046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:08.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 456, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, train rmse <loss>=0.8250062259271453\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, train mse <loss>=0.680635272818552\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=227, train absolute_loss <loss>=0.6215261187486245\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.5614698, \"EndTime\": 1716353108.8259077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.0705108642578, \"count\": 1, \"min\": 264.0705108642578, \"max\": 264.0705108642578}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 45.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.561811, \"EndTime\": 1716353108.826153, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 227, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16094380.0, \"count\": 1, \"min\": 16094380, \"max\": 16094380}, \"Total Batches Seen\": {\"sum\": 16189.0, \"count\": 1, \"min\": 16189, \"max\": 16189}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 229.0, \"count\": 1, \"min\": 229, \"max\": 229}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266896.2640917159 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, batch=0 train rmse <loss>=0.7454953424831455\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, batch=0 train mse <loss>=0.5557633056640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, batch=0 train absolute_loss <loss>=0.57838134765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:09.087] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 458, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, train rmse <loss>=0.8247915720870568\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, train mse <loss>=0.6802811373858385\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=228, train absolute_loss <loss>=0.6213380453620159\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.825974, \"EndTime\": 1716353109.0875723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.1067295074463, \"count\": 1, \"min\": 261.1067295074463, \"max\": 261.1067295074463}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 45.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353108.8263986, \"EndTime\": 1716353109.0877228, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 228, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16164965.0, \"count\": 1, \"min\": 16164965, \"max\": 16164965}, \"Total Batches Seen\": {\"sum\": 16260.0, \"count\": 1, \"min\": 16260, \"max\": 16260}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 230.0, \"count\": 1, \"min\": 230, \"max\": 230}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270012.0186310195 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, batch=0 train rmse <loss>=0.7452688093195174\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, batch=0 train mse <loss>=0.5554255981445313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, batch=0 train absolute_loss <loss>=0.5781814575195312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:09.362] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 460, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, train rmse <loss>=0.8245778235848253\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, train mse <loss>=0.6799285871478873\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=229, train absolute_loss <loss>=0.6211507963798415\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.0876288, \"EndTime\": 1716353109.36268, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.7378349304199, \"count\": 1, \"min\": 274.7378349304199, \"max\": 274.7378349304199}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.0878897, \"EndTime\": 1716353109.3628883, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 229, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16235550.0, \"count\": 1, \"min\": 16235550, \"max\": 16235550}, \"Total Batches Seen\": {\"sum\": 16331.0, \"count\": 1, \"min\": 16331, \"max\": 16331}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 231.0, \"count\": 1, \"min\": 231, \"max\": 231}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256576.09695389768 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, batch=0 train rmse <loss>=0.745043354181067\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, batch=0 train mse <loss>=0.555089599609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, batch=0 train absolute_loss <loss>=0.5779824829101563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:09.631] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 462, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, train rmse <loss>=0.8243649065642811\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, train mse <loss>=0.6795774991747359\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=230, train absolute_loss <loss>=0.6209643546090999\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.3627458, \"EndTime\": 1716353109.6324418, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.3145275115967, \"count\": 1, \"min\": 269.3145275115967, \"max\": 269.3145275115967}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 46.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.3631024, \"EndTime\": 1716353109.6326354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 230, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16306135.0, \"count\": 1, \"min\": 16306135, \"max\": 16306135}, \"Total Batches Seen\": {\"sum\": 16402.0, \"count\": 1, \"min\": 16402, \"max\": 16402}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 232.0, \"count\": 1, \"min\": 232, \"max\": 232}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261777.76702566008 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, batch=0 train rmse <loss>=0.7448190599930337\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, batch=0 train mse <loss>=0.5547554321289062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, batch=0 train absolute_loss <loss>=0.5777850952148438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:09.905] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 464, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, train rmse <loss>=0.8241528649573097\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, train mse <loss>=0.6792279448173415\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=231, train absolute_loss <loss>=0.6207787157515405\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.632507, \"EndTime\": 1716353109.9062989, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.4332084655762, \"count\": 1, \"min\": 273.4332084655762, \"max\": 273.4332084655762}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 46.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.632841, \"EndTime\": 1716353109.9065092, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 231, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16376720.0, \"count\": 1, \"min\": 16376720, \"max\": 16376720}, \"Total Batches Seen\": {\"sum\": 16473.0, \"count\": 1, \"min\": 16473, \"max\": 16473}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 233.0, \"count\": 1, \"min\": 233, \"max\": 233}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257813.2505697399 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, batch=0 train rmse <loss>=0.7445958458337063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, batch=0 train mse <loss>=0.5544229736328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, batch=0 train absolute_loss <loss>=0.5775882568359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:10.176] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 466, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, train rmse <loss>=0.8239416566628956\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, train mse <loss>=0.678879853584397\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=232, train absolute_loss <loss>=0.6205939038773658\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.9063644, \"EndTime\": 1716353110.1773756, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.6007957458496, \"count\": 1, \"min\": 270.6007957458496, \"max\": 270.6007957458496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 46.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353109.9067488, \"EndTime\": 1716353110.1775947, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 232, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16447305.0, \"count\": 1, \"min\": 16447305, \"max\": 16447305}, \"Total Batches Seen\": {\"sum\": 16544.0, \"count\": 1, \"min\": 16544, \"max\": 16544}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 234.0, \"count\": 1, \"min\": 234, \"max\": 234}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260495.94840321864 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, batch=0 train rmse <loss>=0.7443736716770264\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, batch=0 train mse <loss>=0.5540921630859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, batch=0 train absolute_loss <loss>=0.577391845703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:10.455] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 468, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, train rmse <loss>=0.823731264058946\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, train mse <loss>=0.6785331953881492\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=233, train absolute_loss <loss>=0.6204097281442562\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.1774464, \"EndTime\": 1716353110.4557245, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.8635025024414, \"count\": 1, \"min\": 277.8635025024414, \"max\": 277.8635025024414}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 46.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.1778336, \"EndTime\": 1716353110.4559433, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 233, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16517890.0, \"count\": 1, \"min\": 16517890, \"max\": 16517890}, \"Total Batches Seen\": {\"sum\": 16615.0, \"count\": 1, \"min\": 16615, \"max\": 16615}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 235.0, \"count\": 1, \"min\": 235, \"max\": 235}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253696.94483886808 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, batch=0 train rmse <loss>=0.7441525384545035\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, batch=0 train mse <loss>=0.5537630004882812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, batch=0 train absolute_loss <loss>=0.5771959228515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:10.728] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 470, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, train rmse <loss>=0.8235217029067605\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, train mse <loss>=0.6781879951584507\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=234, train absolute_loss <loss>=0.6202262452891175\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.4557946, \"EndTime\": 1716353110.729179, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.9649543762207, \"count\": 1, \"min\": 272.9649543762207, \"max\": 272.9649543762207}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.4561894, \"EndTime\": 1716353110.7294462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 234, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16588475.0, \"count\": 1, \"min\": 16588475, \"max\": 16588475}, \"Total Batches Seen\": {\"sum\": 16686.0, \"count\": 1, \"min\": 16686, \"max\": 16686}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 236.0, \"count\": 1, \"min\": 236, \"max\": 236}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258182.65111346767 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, batch=0 train rmse <loss>=0.7439324060724116\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, batch=0 train mse <loss>=0.5534354248046875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, batch=0 train absolute_loss <loss>=0.5770004272460938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:10.994] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 472, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, train rmse <loss>=0.8233129258110147\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, train mse <loss>=0.6778441738074934\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=235, train absolute_loss <loss>=0.6200433641890405\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.7292523, \"EndTime\": 1716353110.9953167, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.34581184387207, \"count\": 1, \"min\": 265.34581184387207, \"max\": 265.34581184387207}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 47.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.729948, \"EndTime\": 1716353110.9954987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 235, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16659060.0, \"count\": 1, \"min\": 16659060, \"max\": 16659060}, \"Total Batches Seen\": {\"sum\": 16757.0, \"count\": 1, \"min\": 16757, \"max\": 16757}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 237.0, \"count\": 1, \"min\": 237, \"max\": 237}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265688.3621737172 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, batch=0 train rmse <loss>=0.7437133164535328\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, batch=0 train mse <loss>=0.5531094970703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, batch=0 train absolute_loss <loss>=0.5768063354492188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:11.274] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 474, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, train rmse <loss>=0.8231049072583475\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, train mse <loss>=0.6775016883527729\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=236, train absolute_loss <loss>=0.6198611123528279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.9953744, \"EndTime\": 1716353111.2746878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.63597869873047, \"count\": 1, \"min\": 278.63597869873047, \"max\": 278.63597869873047}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 47.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353110.9960263, \"EndTime\": 1716353111.2749043, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 236, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16729645.0, \"count\": 1, \"min\": 16729645, \"max\": 16729645}, \"Total Batches Seen\": {\"sum\": 16828.0, \"count\": 1, \"min\": 16828, \"max\": 16828}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 238.0, \"count\": 1, \"min\": 238, \"max\": 238}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253000.57499092017 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, batch=0 train rmse <loss>=0.7434952294735993\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, batch=0 train mse <loss>=0.55278515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, batch=0 train absolute_loss <loss>=0.57661328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:11.549] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 476, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, train rmse <loss>=0.8228976567036393\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, train mse <loss>=0.6771605534083407\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=237, train absolute_loss <loss>=0.6196797150088028\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.274754, \"EndTime\": 1716353111.550273, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.8749256134033, \"count\": 1, \"min\": 274.8749256134033, \"max\": 274.8749256134033}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 47.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.2753756, \"EndTime\": 1716353111.5504618, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 237, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16800230.0, \"count\": 1, \"min\": 16800230, \"max\": 16800230}, \"Total Batches Seen\": {\"sum\": 16899.0, \"count\": 1, \"min\": 16899, \"max\": 16899}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 239.0, \"count\": 1, \"min\": 239, \"max\": 239}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256492.29395838839 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, batch=0 train rmse <loss>=0.7432781460151711\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, batch=0 train mse <loss>=0.55246240234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, batch=0 train absolute_loss <loss>=0.576420654296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:11.821] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 478, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, train rmse <loss>=0.8226911778620805\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, train mse <loss>=0.6768207741320973\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=238, train absolute_loss <loss>=0.6194989297356404\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.5503476, \"EndTime\": 1716353111.822037, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.9345817565918, \"count\": 1, \"min\": 270.9345817565918, \"max\": 270.9345817565918}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 47.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.5510788, \"EndTime\": 1716353111.8221886, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 238, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16870815.0, \"count\": 1, \"min\": 16870815, \"max\": 16870815}, \"Total Batches Seen\": {\"sum\": 16970.0, \"count\": 1, \"min\": 16970, \"max\": 16970}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 240.0, \"count\": 1, \"min\": 240, \"max\": 240}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260266.9419826726 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, batch=0 train rmse <loss>=0.7430619437476891\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, batch=0 train mse <loss>=0.5521410522460938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, batch=0 train absolute_loss <loss>=0.5762301025390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:12.088] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 480, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, train rmse <loss>=0.8224854279396598\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, train mse <loss>=0.6764822791730853\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=239, train absolute_loss <loss>=0.6193187900596941\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.822096, \"EndTime\": 1716353112.0893693, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.9963836669922, \"count\": 1, \"min\": 266.9963836669922, \"max\": 266.9963836669922}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353111.8223517, \"EndTime\": 1716353112.0895176, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 239, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16941400.0, \"count\": 1, \"min\": 16941400, \"max\": 16941400}, \"Total Batches Seen\": {\"sum\": 17041.0, \"count\": 1, \"min\": 17041, \"max\": 17041}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 241.0, \"count\": 1, \"min\": 241, \"max\": 241}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264110.0455059222 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, batch=0 train rmse <loss>=0.7428467466863539\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, batch=0 train mse <loss>=0.5518212890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, batch=0 train absolute_loss <loss>=0.5760405883789063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:12.369] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 482, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, train rmse <loss>=0.8222804038244828\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, train mse <loss>=0.6761450625137544\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=240, train absolute_loss <loss>=0.6191392934020137\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.0894263, \"EndTime\": 1716353112.3700988, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.0939083099365, \"count\": 1, \"min\": 280.0939083099365, \"max\": 280.0939083099365}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 48.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.0899806, \"EndTime\": 1716353112.3702707, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 240, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17011985.0, \"count\": 1, \"min\": 17011985, \"max\": 17011985}, \"Total Batches Seen\": {\"sum\": 17112.0, \"count\": 1, \"min\": 17112, \"max\": 17112}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 242.0, \"count\": 1, \"min\": 242, \"max\": 242}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251730.28011699885 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, batch=0 train rmse <loss>=0.7426324324236722\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, batch=0 train mse <loss>=0.5515029296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, batch=0 train absolute_loss <loss>=0.5758513793945312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:12.651] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 484, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, train rmse <loss>=0.8220760579571067\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, train mse <loss>=0.6758090450662962\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=241, train absolute_loss <loss>=0.6189604380432988\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.370162, \"EndTime\": 1716353112.6524074, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.91304206848145, \"count\": 1, \"min\": 281.91304206848145, \"max\": 281.91304206848145}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 48.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.3704677, \"EndTime\": 1716353112.652681, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 241, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17082570.0, \"count\": 1, \"min\": 17082570, \"max\": 17082570}, \"Total Batches Seen\": {\"sum\": 17183.0, \"count\": 1, \"min\": 17183, \"max\": 17183}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 243.0, \"count\": 1, \"min\": 243, \"max\": 243}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250001.64484061976 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, batch=0 train rmse <loss>=0.7424190839353513\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, batch=0 train mse <loss>=0.5511860961914062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, batch=0 train absolute_loss <loss>=0.5756626586914062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:12.928] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 486, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, train rmse <loss>=0.8218724441876731\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, train mse <loss>=0.6754743145150198\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=242, train absolute_loss <loss>=0.6187823469135123\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.6524782, \"EndTime\": 1716353112.9292974, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.33142471313477, \"count\": 1, \"min\": 276.33142471313477, \"max\": 276.33142471313477}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 48.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.6529427, \"EndTime\": 1716353112.9294448, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 242, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17153155.0, \"count\": 1, \"min\": 17153155, \"max\": 17153155}, \"Total Batches Seen\": {\"sum\": 17254.0, \"count\": 1, \"min\": 17254, \"max\": 17254}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 244.0, \"count\": 1, \"min\": 244, \"max\": 244}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255185.46457545363 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, batch=0 train rmse <loss>=0.7422065375847843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, batch=0 train mse <loss>=0.5508705444335937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, batch=0 train absolute_loss <loss>=0.5754741821289062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:13.195] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 488, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, train rmse <loss>=0.8216695070874699\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, train mse <loss>=0.6751407788773658\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=243, train absolute_loss <loss>=0.6186049787494499\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.9293563, \"EndTime\": 1716353113.1959255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.27564430236816, \"count\": 1, \"min\": 266.27564430236816, \"max\": 266.27564430236816}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 48.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353112.929614, \"EndTime\": 1716353113.1960778, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 243, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17223740.0, \"count\": 1, \"min\": 17223740, \"max\": 17223740}, \"Total Batches Seen\": {\"sum\": 17325.0, \"count\": 1, \"min\": 17325, \"max\": 17325}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 245.0, \"count\": 1, \"min\": 245, \"max\": 245}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264810.0142577304 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, batch=0 train rmse <loss>=0.7419949585776763\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, batch=0 train mse <loss>=0.5505565185546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, batch=0 train absolute_loss <loss>=0.5752861938476562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:13.474] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 490, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, train rmse <loss>=0.8214672487277167\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, train mse <loss>=0.6748084407322843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=244, train absolute_loss <loss>=0.6184280103226782\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.1959846, \"EndTime\": 1716353113.474817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.55443954467773, \"count\": 1, \"min\": 278.55443954467773, \"max\": 278.55443954467773}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.19624, \"EndTime\": 1716353113.4750056, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 244, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17294325.0, \"count\": 1, \"min\": 17294325, \"max\": 17294325}, \"Total Batches Seen\": {\"sum\": 17396.0, \"count\": 1, \"min\": 17396, \"max\": 17396}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 246.0, \"count\": 1, \"min\": 246, \"max\": 246}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253113.48565771215 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, batch=0 train rmse <loss>=0.7417842243194571\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, batch=0 train mse <loss>=0.5502438354492187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, batch=0 train absolute_loss <loss>=0.5751001586914063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:13.743] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 492, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, train rmse <loss>=0.8212656219833006\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, train mse <loss>=0.6744772218516175\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=245, train absolute_loss <loss>=0.6182515129841549\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.4748769, \"EndTime\": 1716353113.743494, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.25976371765137, \"count\": 1, \"min\": 268.25976371765137, \"max\": 268.25976371765137}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 49.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.4752128, \"EndTime\": 1716353113.7436478, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 245, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17364910.0, \"count\": 1, \"min\": 17364910, \"max\": 17364910}, \"Total Batches Seen\": {\"sum\": 17467.0, \"count\": 1, \"min\": 17467, \"max\": 17467}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 247.0, \"count\": 1, \"min\": 247, \"max\": 247}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262862.2767106406 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, batch=0 train rmse <loss>=0.7415743355302875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, batch=0 train mse <loss>=0.5499324951171874\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, batch=0 train absolute_loss <loss>=0.57491455078125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:14.013] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 494, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, train rmse <loss>=0.8210646540178914\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, train mse <loss>=0.6741471660775198\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=246, train absolute_loss <loss>=0.6180756792954996\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.7435539, \"EndTime\": 1716353114.0139146, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.078182220459, \"count\": 1, \"min\": 270.078182220459, \"max\": 270.078182220459}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 49.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353113.7438154, \"EndTime\": 1716353114.0141125, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 246, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17435495.0, \"count\": 1, \"min\": 17435495, \"max\": 17435495}, \"Total Batches Seen\": {\"sum\": 17538.0, \"count\": 1, \"min\": 17538, \"max\": 17538}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 248.0, \"count\": 1, \"min\": 248, \"max\": 248}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261039.15551871902 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, batch=0 train rmse <loss>=0.7413652517642282\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, batch=0 train mse <loss>=0.5496224365234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, batch=0 train absolute_loss <loss>=0.574732666015625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:14.288] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 496, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, train rmse <loss>=0.8208643264648476\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, train mse <loss>=0.673818242462588\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=247, train absolute_loss <loss>=0.6179005806076695\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.0139904, \"EndTime\": 1716353114.2892551, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.6102809906006, \"count\": 1, \"min\": 274.6102809906006, \"max\": 274.6102809906006}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 49.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.0146255, \"EndTime\": 1716353114.289393, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 247, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17506080.0, \"count\": 1, \"min\": 17506080, \"max\": 17506080}, \"Total Batches Seen\": {\"sum\": 17609.0, \"count\": 1, \"min\": 17609, \"max\": 17609}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 249.0, \"count\": 1, \"min\": 249, \"max\": 249}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256814.69040489383 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, batch=0 train rmse <loss>=0.7411570148781734\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, batch=0 train mse <loss>=0.549313720703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, batch=0 train absolute_loss <loss>=0.5745516967773437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:14.568] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 498, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, train rmse <loss>=0.8206646067967515\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, train mse <loss>=0.6734903968488667\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=248, train absolute_loss <loss>=0.6177259848151408\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.289309, \"EndTime\": 1716353114.569134, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.27160263061523, \"count\": 1, \"min\": 279.27160263061523, \"max\": 279.27160263061523}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 49.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.2898388, \"EndTime\": 1716353114.5693514, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 248, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17576665.0, \"count\": 1, \"min\": 17576665, \"max\": 17576665}, \"Total Batches Seen\": {\"sum\": 17680.0, \"count\": 1, \"min\": 17680, \"max\": 17680}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252433.00924449568 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, batch=0 train rmse <loss>=0.7409496255861461\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, batch=0 train mse <loss>=0.54900634765625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, batch=0 train absolute_loss <loss>=0.5743720703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:14.836] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 500, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, train rmse <loss>=0.8204655179843389\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, train mse <loss>=0.6731636662013094\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=249, train absolute_loss <loss>=0.6175518326020577\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.5692048, \"EndTime\": 1716353114.8366082, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.71791076660156, \"count\": 1, \"min\": 266.71791076660156, \"max\": 266.71791076660156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.5698674, \"EndTime\": 1716353114.8367596, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 249, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17647250.0, \"count\": 1, \"min\": 17647250, \"max\": 17647250}, \"Total Batches Seen\": {\"sum\": 17751.0, \"count\": 1, \"min\": 17751, \"max\": 17751}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 251.0, \"count\": 1, \"min\": 251, \"max\": 251}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264378.4445109237 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, batch=0 train rmse <loss>=0.7407430022028558\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, batch=0 train mse <loss>=0.5487001953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, batch=0 train absolute_loss <loss>=0.574194580078125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:15.105] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 502, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, train rmse <loss>=0.8202670337626411\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, train mse <loss>=0.6728380066777618\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=250, train absolute_loss <loss>=0.6173783010563381\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.836667, \"EndTime\": 1716353115.1058774, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.45741271972656, \"count\": 1, \"min\": 268.45741271972656, \"max\": 268.45741271972656}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 50.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353114.8373938, \"EndTime\": 1716353115.1061044, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 250, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17717835.0, \"count\": 1, \"min\": 17717835, \"max\": 17717835}, \"Total Batches Seen\": {\"sum\": 17822.0, \"count\": 1, \"min\": 17822, \"max\": 17822}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 252.0, \"count\": 1, \"min\": 252, \"max\": 252}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262572.2585714818 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, batch=0 train rmse <loss>=0.7405371041593518\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, batch=0 train mse <loss>=0.5483952026367187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, batch=0 train absolute_loss <loss>=0.5740184326171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:15.381] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 504, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, train rmse <loss>=0.8200691210261598\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, train mse <loss>=0.6725133632606184\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=251, train absolute_loss <loss>=0.6172054039323833\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.1059513, \"EndTime\": 1716353115.3815458, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.8880386352539, \"count\": 1, \"min\": 274.8880386352539, \"max\": 274.8880386352539}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 50.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.1066337, \"EndTime\": 1716353115.3816948, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 251, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17788420.0, \"count\": 1, \"min\": 17788420, \"max\": 17788420}, \"Total Batches Seen\": {\"sum\": 17893.0, \"count\": 1, \"min\": 17893, \"max\": 17893}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 253.0, \"count\": 1, \"min\": 253, \"max\": 253}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256530.52089425887 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, batch=0 train rmse <loss>=0.7403320145037757\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, batch=0 train mse <loss>=0.5480914916992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, batch=0 train absolute_loss <loss>=0.5738430786132812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:15.652] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 506, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, train rmse <loss>=0.8198717723248725\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, train mse <loss>=0.6721897230551276\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=252, train absolute_loss <loss>=0.6170330036861795\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.3816035, \"EndTime\": 1716353115.6535027, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.18444442749023, \"count\": 1, \"min\": 271.18444442749023, \"max\": 271.18444442749023}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 50.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.3822677, \"EndTime\": 1716353115.6538255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 252, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17859005.0, \"count\": 1, \"min\": 17859005, \"max\": 17859005}, \"Total Batches Seen\": {\"sum\": 17964.0, \"count\": 1, \"min\": 17964, \"max\": 17964}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 254.0, \"count\": 1, \"min\": 254, \"max\": 254}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259794.17575850646 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, batch=0 train rmse <loss>=0.7401276514424302\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, batch=0 train mse <loss>=0.5477889404296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, batch=0 train absolute_loss <loss>=0.573668701171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:15.921] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 508, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, train rmse <loss>=0.8196750095659519\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, train mse <loss>=0.6718671213069433\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=253, train absolute_loss <loss>=0.6168612137915382\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.6535654, \"EndTime\": 1716353115.9215758, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.3623561859131, \"count\": 1, \"min\": 267.3623561859131, \"max\": 267.3623561859131}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 50.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.6541874, \"EndTime\": 1716353115.921776, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 253, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17929590.0, \"count\": 1, \"min\": 17929590, \"max\": 17929590}, \"Total Batches Seen\": {\"sum\": 18035.0, \"count\": 1, \"min\": 18035, \"max\": 18035}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 255.0, \"count\": 1, \"min\": 255, \"max\": 255}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263660.5571467248 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, batch=0 train rmse <loss>=0.7399240568215641\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, batch=0 train mse <loss>=0.5474876098632813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, batch=0 train absolute_loss <loss>=0.5734952392578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:16.181] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 510, \"duration\": 257, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, train rmse <loss>=0.8194788017008493\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, train mse <loss>=0.6715455064370599\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=254, train absolute_loss <loss>=0.6166900703537632\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.9216409, \"EndTime\": 1716353116.1821108, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.04862785339355, \"count\": 1, \"min\": 260.04862785339355, \"max\": 260.04862785339355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353115.9220366, \"EndTime\": 1716353116.1823614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 254, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18000175.0, \"count\": 1, \"min\": 18000175, \"max\": 18000175}, \"Total Batches Seen\": {\"sum\": 18106.0, \"count\": 1, \"min\": 18106, \"max\": 18106}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 256.0, \"count\": 1, \"min\": 256, \"max\": 256}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=271031.67720991716 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, batch=0 train rmse <loss>=0.739721148764646\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, batch=0 train mse <loss>=0.5471873779296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, batch=0 train absolute_loss <loss>=0.5733224487304688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:16.448] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 512, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, train rmse <loss>=0.8192831092559341\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, train mse <loss>=0.6712248131120708\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=255, train absolute_loss <loss>=0.616519472793794\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.1821754, \"EndTime\": 1716353116.4489243, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.27421379089355, \"count\": 1, \"min\": 266.27421379089355, \"max\": 266.27421379089355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 51.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.1826236, \"EndTime\": 1716353116.449158, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 255, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18070760.0, \"count\": 1, \"min\": 18070760, \"max\": 18070760}, \"Total Batches Seen\": {\"sum\": 18177.0, \"count\": 1, \"min\": 18177, \"max\": 18177}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 257.0, \"count\": 1, \"min\": 257, \"max\": 257}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264718.143454181 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, batch=0 train rmse <loss>=0.7395190516371941\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, batch=0 train mse <loss>=0.546888427734375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, batch=0 train absolute_loss <loss>=0.5731500854492187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:16.710] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 514, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, train rmse <loss>=0.8190879761557567\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, train mse <loss>=0.6709051126829335\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=256, train absolute_loss <loss>=0.6163493936028279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.4489992, \"EndTime\": 1716353116.7112455, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.7785930633545, \"count\": 1, \"min\": 261.7785930633545, \"max\": 261.7785930633545}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 51.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.449442, \"EndTime\": 1716353116.7114723, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 256, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18141345.0, \"count\": 1, \"min\": 18141345, \"max\": 18141345}, \"Total Batches Seen\": {\"sum\": 18248.0, \"count\": 1, \"min\": 18248, \"max\": 18248}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 258.0, \"count\": 1, \"min\": 258, \"max\": 258}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269252.7239407645 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, batch=0 train rmse <loss>=0.7393175597140667\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, batch=0 train mse <loss>=0.5465904541015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, batch=0 train absolute_loss <loss>=0.5729778442382812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:16.977] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 516, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, train rmse <loss>=0.8188933650084372\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, train mse <loss>=0.6705863432548416\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=257, train absolute_loss <loss>=0.6161797528334066\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.7113144, \"EndTime\": 1716353116.9774342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.70606231689453, \"count\": 1, \"min\": 265.70606231689453, \"max\": 265.70606231689453}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 51.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.7117043, \"EndTime\": 1716353116.977594, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 257, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18211930.0, \"count\": 1, \"min\": 18211930, \"max\": 18211930}, \"Total Batches Seen\": {\"sum\": 18319.0, \"count\": 1, \"min\": 18319, \"max\": 18319}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 259.0, \"count\": 1, \"min\": 259, \"max\": 259}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265378.7559273356 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, batch=0 train rmse <loss>=0.739116797357981\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, batch=0 train mse <loss>=0.5462936401367188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, batch=0 train absolute_loss <loss>=0.5728059692382812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:17.251] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 518, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, train rmse <loss>=0.8186992693610663\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, train mse <loss>=0.6702684936523438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=258, train absolute_loss <loss>=0.616010565959232\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.9774947, \"EndTime\": 1716353117.251797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.01185035705566, \"count\": 1, \"min\": 274.01185035705566, \"max\": 274.01185035705566}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 51.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353116.9777598, \"EndTime\": 1716353117.2520335, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 258, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18282515.0, \"count\": 1, \"min\": 18282515, \"max\": 18282515}, \"Total Batches Seen\": {\"sum\": 18390.0, \"count\": 1, \"min\": 18390, \"max\": 18390}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 260.0, \"count\": 1, \"min\": 260, \"max\": 260}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257256.5447821372 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, batch=0 train rmse <loss>=0.7389166825627442\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, batch=0 train mse <loss>=0.5459978637695313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, batch=0 train absolute_loss <loss>=0.5726347045898438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:17.520] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 520, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, train rmse <loss>=0.8185056769771594\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, train mse <loss>=0.669951543243838\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=259, train absolute_loss <loss>=0.6158418123487016\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.2518718, \"EndTime\": 1716353117.5211513, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.86582374572754, \"count\": 1, \"min\": 268.86582374572754, \"max\": 268.86582374572754}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.2522593, \"EndTime\": 1716353117.521385, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 259, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18353100.0, \"count\": 1, \"min\": 18353100, \"max\": 18353100}, \"Total Batches Seen\": {\"sum\": 18461.0, \"count\": 1, \"min\": 18461, \"max\": 18461}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 261.0, \"count\": 1, \"min\": 261, \"max\": 261}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262167.9102631199 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, batch=0 train rmse <loss>=0.7387172158546191\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, batch=0 train mse <loss>=0.545703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, batch=0 train absolute_loss <loss>=0.572463623046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:17.807] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 522, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, train rmse <loss>=0.8183125756077089\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, train mse <loss>=0.6696354713977223\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=260, train absolute_loss <loss>=0.6156736123528279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.521222, \"EndTime\": 1716353117.8077865, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.12351417541504, \"count\": 1, \"min\": 286.12351417541504, \"max\": 286.12351417541504}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 52.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.5216396, \"EndTime\": 1716353117.8079603, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 260, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18423685.0, \"count\": 1, \"min\": 18423685, \"max\": 18423685}, \"Total Batches Seen\": {\"sum\": 18532.0, \"count\": 1, \"min\": 18532, \"max\": 18532}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 262.0, \"count\": 1, \"min\": 262, \"max\": 262}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246439.93503850326 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, batch=0 train rmse <loss>=0.7385184804041383\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, batch=0 train mse <loss>=0.5454095458984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, batch=0 train absolute_loss <loss>=0.5722928466796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:18.075] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 524, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, train rmse <loss>=0.8181199677019237\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, train mse <loss>=0.6693202815525968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=261, train absolute_loss <loss>=0.6155058576556999\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.807861, \"EndTime\": 1716353118.0756392, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.49110221862793, \"count\": 1, \"min\": 267.49110221862793, \"max\": 267.49110221862793}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 52.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353117.808125, \"EndTime\": 1716353118.0757928, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 261, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18494270.0, \"count\": 1, \"min\": 18494270, \"max\": 18494270}, \"Total Batches Seen\": {\"sum\": 18603.0, \"count\": 1, \"min\": 18603, \"max\": 18603}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 263.0, \"count\": 1, \"min\": 263, \"max\": 263}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263616.18538038724 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, batch=0 train rmse <loss>=0.7383203114666552\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, batch=0 train mse <loss>=0.5451168823242187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, batch=0 train absolute_loss <loss>=0.5721221313476562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:18.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 526, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, train rmse <loss>=0.8179278147210518\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, train mse <loss>=0.6690059100943552\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=262, train absolute_loss <loss>=0.6153386978364327\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.0756989, \"EndTime\": 1716353118.340408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.4221782684326, \"count\": 1, \"min\": 264.4221782684326, \"max\": 264.4221782684326}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 52.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.0759606, \"EndTime\": 1716353118.3406286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 262, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18564855.0, \"count\": 1, \"min\": 18564855, \"max\": 18564855}, \"Total Batches Seen\": {\"sum\": 18674.0, \"count\": 1, \"min\": 18674, \"max\": 18674}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 264.0, \"count\": 1, \"min\": 264, \"max\": 264}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266594.8805633473 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, batch=0 train rmse <loss>=0.7381228335330188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, batch=0 train mse <loss>=0.5448253173828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, batch=0 train absolute_loss <loss>=0.5719517822265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:18.625] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 528, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, train rmse <loss>=0.8177361753305017\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, train mse <loss>=0.6686924524441571\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=263, train absolute_loss <loss>=0.6151720486493177\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.340472, \"EndTime\": 1716353118.6259632, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.0935459136963, \"count\": 1, \"min\": 285.0935459136963, \"max\": 285.0935459136963}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 52.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.3408358, \"EndTime\": 1716353118.6261768, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 263, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18635440.0, \"count\": 1, \"min\": 18635440, \"max\": 18635440}, \"Total Batches Seen\": {\"sum\": 18745.0, \"count\": 1, \"min\": 18745, \"max\": 18745}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 265.0, \"count\": 1, \"min\": 265, \"max\": 265}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247269.01788108065 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, batch=0 train rmse <loss>=0.7379259230903533\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, batch=0 train mse <loss>=0.54453466796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, batch=0 train absolute_loss <loss>=0.5717814331054687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:18.898] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 530, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, train rmse <loss>=0.8175449657712953\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, train mse <loss>=0.6683797710579885\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=264, train absolute_loss <loss>=0.6150058215503962\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.6260333, \"EndTime\": 1716353118.8991973, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.59087562561035, \"count\": 1, \"min\": 272.59087562561035, \"max\": 272.59087562561035}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.6265838, \"EndTime\": 1716353118.8993487, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 264, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18706025.0, \"count\": 1, \"min\": 18706025, \"max\": 18706025}, \"Total Batches Seen\": {\"sum\": 18816.0, \"count\": 1, \"min\": 18816, \"max\": 18816}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 266.0, \"count\": 1, \"min\": 266, \"max\": 266}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258689.11587558314 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, batch=0 train rmse <loss>=0.7377295805930729\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, batch=0 train mse <loss>=0.5442449340820312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, batch=0 train absolute_loss <loss>=0.5716112670898438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:19.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 532, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, train rmse <loss>=0.8173541695171357\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, train mse <loss>=0.6680678384270466\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=265, train absolute_loss <loss>=0.614840087890625\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.899255, \"EndTime\": 1716353119.173156, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.4243869781494, \"count\": 1, \"min\": 273.4243869781494, \"max\": 273.4243869781494}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 53.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353118.8997054, \"EndTime\": 1716353119.1733568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 265, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18776610.0, \"count\": 1, \"min\": 18776610, \"max\": 18776610}, \"Total Batches Seen\": {\"sum\": 18887.0, \"count\": 1, \"min\": 18887, \"max\": 18887}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 267.0, \"count\": 1, \"min\": 267, \"max\": 267}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257837.94917528942 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, batch=0 train rmse <loss>=0.7375339306283644\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, batch=0 train mse <loss>=0.543956298828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, batch=0 train absolute_loss <loss>=0.5714414672851562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:19.438] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 534, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, train rmse <loss>=0.8171638662829473\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, train mse <loss>=0.6677567843584947\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=266, train absolute_loss <loss>=0.6146747642839459\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.1732218, \"EndTime\": 1716353119.4387338, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.91308212280273, \"count\": 1, \"min\": 264.91308212280273, \"max\": 264.91308212280273}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 53.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.1737971, \"EndTime\": 1716353119.4389024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 266, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18847195.0, \"count\": 1, \"min\": 18847195, \"max\": 18847195}, \"Total Batches Seen\": {\"sum\": 18958.0, \"count\": 1, \"min\": 18958, \"max\": 18958}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 268.0, \"count\": 1, \"min\": 268, \"max\": 268}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266162.5032612341 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, batch=0 train rmse <loss>=0.7373388081922762\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, batch=0 train mse <loss>=0.5436685180664063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, batch=0 train absolute_loss <loss>=0.571271728515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:19.705] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 536, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, train rmse <loss>=0.8169739706559619\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, train mse <loss>=0.6674464687293684\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=267, train absolute_loss <loss>=0.6145098275198063\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.4387932, \"EndTime\": 1716353119.7056658, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.33667945861816, \"count\": 1, \"min\": 266.33667945861816, \"max\": 266.33667945861816}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 53.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.4393058, \"EndTime\": 1716353119.7058213, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 267, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18917780.0, \"count\": 1, \"min\": 18917780, \"max\": 18917780}, \"Total Batches Seen\": {\"sum\": 19029.0, \"count\": 1, \"min\": 19029, \"max\": 19029}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 269.0, \"count\": 1, \"min\": 269, \"max\": 269}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264753.65295807295 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, batch=0 train rmse <loss>=0.7371442551034575\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, batch=0 train mse <loss>=0.5433816528320312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, batch=0 train absolute_loss <loss>=0.5711021118164062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:19.990] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 538, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, train rmse <loss>=0.81678450028641\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, train mse <loss>=0.6671369199081206\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=268, train absolute_loss <loss>=0.6143454254580216\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.7057233, \"EndTime\": 1716353119.990975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.95240211486816, \"count\": 1, \"min\": 284.95240211486816, \"max\": 284.95240211486816}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 53.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.7059965, \"EndTime\": 1716353119.9912066, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 268, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18988365.0, \"count\": 1, \"min\": 18988365, \"max\": 18988365}, \"Total Batches Seen\": {\"sum\": 19100.0, \"count\": 1, \"min\": 19100, \"max\": 19100}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 270.0, \"count\": 1, \"min\": 270, \"max\": 270}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247396.3011424078 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, batch=0 train rmse <loss>=0.7369503132234603\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, batch=0 train mse <loss>=0.5430957641601563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, batch=0 train absolute_loss <loss>=0.5709327392578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:20.264] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 540, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, train rmse <loss>=0.8165954381003475\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, train mse <loss>=0.6668281095262985\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=269, train absolute_loss <loss>=0.6141813560808209\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.9910498, \"EndTime\": 1716353120.264682, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.2250690460205, \"count\": 1, \"min\": 273.2250690460205, \"max\": 273.2250690460205}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353119.9914308, \"EndTime\": 1716353120.2648869, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 269, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19058950.0, \"count\": 1, \"min\": 19058950, \"max\": 19058950}, \"Total Batches Seen\": {\"sum\": 19171.0, \"count\": 1, \"min\": 19171, \"max\": 19171}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 271.0, \"count\": 1, \"min\": 271, \"max\": 271}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258022.21528480452 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, batch=0 train rmse <loss>=0.736756900191962\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, batch=0 train mse <loss>=0.5428107299804688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, batch=0 train absolute_loss <loss>=0.5707634887695312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:20.534] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 542, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, train rmse <loss>=0.8164068038612583\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, train mse <loss>=0.6665200693909551\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=270, train absolute_loss <loss>=0.6140178205463248\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.2647467, \"EndTime\": 1716353120.5345664, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.2863941192627, \"count\": 1, \"min\": 269.2863941192627, \"max\": 269.2863941192627}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 54.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.2652557, \"EndTime\": 1716353120.5348, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 270, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19129535.0, \"count\": 1, \"min\": 19129535, \"max\": 19129535}, \"Total Batches Seen\": {\"sum\": 19242.0, \"count\": 1, \"min\": 19242, \"max\": 19242}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 272.0, \"count\": 1, \"min\": 272, \"max\": 272}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261762.95383570704 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, batch=0 train rmse <loss>=0.7365640164255709\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, batch=0 train mse <loss>=0.5425265502929687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, batch=0 train absolute_loss <loss>=0.5705944213867188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:20.813] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 544, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, train rmse <loss>=0.8162185562640277\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, train mse <loss>=0.6662127315897337\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=271, train absolute_loss <loss>=0.613854541187555\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.5346415, \"EndTime\": 1716353120.8142235, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.9723873138428, \"count\": 1, \"min\": 278.9723873138428, \"max\": 278.9723873138428}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 54.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.5352283, \"EndTime\": 1716353120.814372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 271, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19200120.0, \"count\": 1, \"min\": 19200120, \"max\": 19200120}, \"Total Batches Seen\": {\"sum\": 19313.0, \"count\": 1, \"min\": 19313, \"max\": 19313}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 273.0, \"count\": 1, \"min\": 273, \"max\": 273}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252781.96209486615 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, batch=0 train rmse <loss>=0.7363716623401909\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, batch=0 train mse <loss>=0.5422432250976562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, batch=0 train absolute_loss <loss>=0.5704259033203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:21.085] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 546, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, train rmse <loss>=0.8160306997900477\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, train mse <loss>=0.665906102999835\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=272, train absolute_loss <loss>=0.6136917268994828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.8142784, \"EndTime\": 1716353121.085622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.85208892822266, \"count\": 1, \"min\": 270.85208892822266, \"max\": 270.85208892822266}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 54.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353120.8147485, \"EndTime\": 1716353121.0857747, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 272, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19270705.0, \"count\": 1, \"min\": 19270705, \"max\": 19270705}, \"Total Batches Seen\": {\"sum\": 19384.0, \"count\": 1, \"min\": 19384, \"max\": 19384}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 274.0, \"count\": 1, \"min\": 274, \"max\": 274}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260350.2536976505 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, batch=0 train rmse <loss>=0.7361798798049887\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, batch=0 train mse <loss>=0.5419608154296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, batch=0 train absolute_loss <loss>=0.57025830078125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:21.355] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 548, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, train rmse <loss>=0.8158432457732985\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, train mse <loss>=0.6656002016739107\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=273, train absolute_loss <loss>=0.6135293493136553\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.0856795, \"EndTime\": 1716353121.355797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.5965766906738, \"count\": 1, \"min\": 269.5965766906738, \"max\": 269.5965766906738}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 54.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.0861804, \"EndTime\": 1716353121.3559916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 273, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19341290.0, \"count\": 1, \"min\": 19341290, \"max\": 19341290}, \"Total Batches Seen\": {\"sum\": 19455.0, \"count\": 1, \"min\": 19455, \"max\": 19455}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 275.0, \"count\": 1, \"min\": 275, \"max\": 275}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261513.2338589716 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, batch=0 train rmse <loss>=0.7359885448725365\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, batch=0 train mse <loss>=0.5416791381835937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, batch=0 train absolute_loss <loss>=0.5700907592773438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:21.618] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 550, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, train rmse <loss>=0.8156561618192162\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, train mse <loss>=0.6652949743136554\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=274, train absolute_loss <loss>=0.6133673302019146\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.3558614, \"EndTime\": 1716353121.6189451, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.7224922180176, \"count\": 1, \"min\": 262.7224922180176, \"max\": 262.7224922180176}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.3562016, \"EndTime\": 1716353121.6190956, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 274, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19411875.0, \"count\": 1, \"min\": 19411875, \"max\": 19411875}, \"Total Batches Seen\": {\"sum\": 19526.0, \"count\": 1, \"min\": 19526, \"max\": 19526}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 276.0, \"count\": 1, \"min\": 276, \"max\": 276}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268403.48410095175 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, batch=0 train rmse <loss>=0.7357977823185143\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, batch=0 train mse <loss>=0.5413983764648438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, batch=0 train absolute_loss <loss>=0.5699234619140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:21.889] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 552, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, train rmse <loss>=0.8154694281531134\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, train mse <loss>=0.6649903882523658\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=275, train absolute_loss <loss>=0.6132054623885893\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.619003, \"EndTime\": 1716353121.8898478, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.3707218170166, \"count\": 1, \"min\": 270.3707218170166, \"max\": 270.3707218170166}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 55.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.6194525, \"EndTime\": 1716353121.8900588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 275, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19482460.0, \"count\": 1, \"min\": 19482460, \"max\": 19482460}, \"Total Batches Seen\": {\"sum\": 19597.0, \"count\": 1, \"min\": 19597, \"max\": 19597}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 277.0, \"count\": 1, \"min\": 277, \"max\": 277}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260740.97271799317 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, batch=0 train rmse <loss>=0.7356074681295512\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, batch=0 train mse <loss>=0.5411183471679688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, batch=0 train absolute_loss <loss>=0.5697561645507813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:22.165] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 554, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, train rmse <loss>=0.8152830634680172\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, train mse <loss>=0.6646864735777949\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=276, train absolute_loss <loss>=0.6130439848564041\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.8899164, \"EndTime\": 1716353122.165812, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.51841735839844, \"count\": 1, \"min\": 275.51841735839844, \"max\": 275.51841735839844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 55.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353121.8902683, \"EndTime\": 1716353122.1660497, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 276, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19553045.0, \"count\": 1, \"min\": 19553045, \"max\": 19553045}, \"Total Batches Seen\": {\"sum\": 19668.0, \"count\": 1, \"min\": 19668, \"max\": 19668}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 278.0, \"count\": 1, \"min\": 278, \"max\": 278}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255834.66801242987 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, batch=0 train rmse <loss>=0.7354176441506723\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, batch=0 train mse <loss>=0.540839111328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, batch=0 train absolute_loss <loss>=0.5695889892578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:22.443] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 556, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, train rmse <loss>=0.8150970532517833\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, train mse <loss>=0.6643832062197403\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=277, train absolute_loss <loss>=0.6128828185175507\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.1658828, \"EndTime\": 1716353122.443765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.27460861206055, \"count\": 1, \"min\": 277.27460861206055, \"max\": 277.27460861206055}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 55.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.1664655, \"EndTime\": 1716353122.4439828, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 277, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19623630.0, \"count\": 1, \"min\": 19623630, \"max\": 19623630}, \"Total Batches Seen\": {\"sum\": 19739.0, \"count\": 1, \"min\": 19739, \"max\": 19739}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 279.0, \"count\": 1, \"min\": 279, \"max\": 279}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254246.6317199684 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, batch=0 train rmse <loss>=0.7352283522691905\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, batch=0 train mse <loss>=0.5405607299804688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, batch=0 train absolute_loss <loss>=0.5694219970703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:22.724] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 558, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, train rmse <loss>=0.8149114199000439\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, train mse <loss>=0.6640806222835057\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=278, train absolute_loss <loss>=0.6127220080738336\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.4438348, \"EndTime\": 1716353122.7247622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.32875061035156, \"count\": 1, \"min\": 280.32875061035156, \"max\": 280.32875061035156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 55.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.4444122, \"EndTime\": 1716353122.7249706, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 278, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19694215.0, \"count\": 1, \"min\": 19694215, \"max\": 19694215}, \"Total Batches Seen\": {\"sum\": 19810.0, \"count\": 1, \"min\": 19810, \"max\": 19810}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 280.0, \"count\": 1, \"min\": 280, \"max\": 280}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251488.2177891493 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, batch=0 train rmse <loss>=0.7350395098596316\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, batch=0 train mse <loss>=0.5402830810546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, batch=0 train absolute_loss <loss>=0.5692549438476563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:22.997] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 560, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, train rmse <loss>=0.8147261077479854\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, train mse <loss>=0.6637786306461818\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=279, train absolute_loss <loss>=0.6125614314549406\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.7248318, \"EndTime\": 1716353122.997809, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.40467071533203, \"count\": 1, \"min\": 272.40467071533203, \"max\": 272.40467071533203}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.7253819, \"EndTime\": 1716353122.998013, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 279, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19764800.0, \"count\": 1, \"min\": 19764800, \"max\": 19764800}, \"Total Batches Seen\": {\"sum\": 19881.0, \"count\": 1, \"min\": 19881, \"max\": 19881}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 281.0, \"count\": 1, \"min\": 281, \"max\": 281}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258811.2347288188 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, batch=0 train rmse <loss>=0.7348511172685126\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, batch=0 train mse <loss>=0.5400061645507812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, batch=0 train absolute_loss <loss>=0.569088134765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:23.268] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 562, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, train rmse <loss>=0.8145411317901454\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, train mse <loss>=0.663477255377971\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=280, train absolute_loss <loss>=0.6124012760645907\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.9978824, \"EndTime\": 1716353123.2694714, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.026611328125, \"count\": 1, \"min\": 271.026611328125, \"max\": 271.026611328125}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 56.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353122.9984238, \"EndTime\": 1716353123.2696614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 280, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19835385.0, \"count\": 1, \"min\": 19835385, \"max\": 19835385}, \"Total Batches Seen\": {\"sum\": 19952.0, \"count\": 1, \"min\": 19952, \"max\": 19952}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 282.0, \"count\": 1, \"min\": 282, \"max\": 282}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260121.73180803767 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, batch=0 train rmse <loss>=0.7346631748418795\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, batch=0 train mse <loss>=0.53972998046875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, batch=0 train absolute_loss <loss>=0.5689212646484375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:23.548] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 564, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, train rmse <loss>=0.8143564743100962\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, train mse <loss>=0.6631764672507703\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=281, train absolute_loss <loss>=0.6122414679728764\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.269536, \"EndTime\": 1716353123.5486133, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.48362922668457, \"count\": 1, \"min\": 278.48362922668457, \"max\": 278.48362922668457}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 56.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.2701051, \"EndTime\": 1716353123.5488048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 281, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19905970.0, \"count\": 1, \"min\": 19905970, \"max\": 19905970}, \"Total Batches Seen\": {\"sum\": 20023.0, \"count\": 1, \"min\": 20023, \"max\": 20023}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 283.0, \"count\": 1, \"min\": 283, \"max\": 283}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253167.59734668033 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, batch=0 train rmse <loss>=0.7344756829253054\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, batch=0 train mse <loss>=0.5394545288085938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, batch=0 train absolute_loss <loss>=0.568754638671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:23.822] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 566, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, train rmse <loss>=0.8141721719516307\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, train mse <loss>=0.6628763255804357\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=282, train absolute_loss <loss>=0.6120820071797975\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.5486717, \"EndTime\": 1716353123.8234694, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.20854568481445, \"count\": 1, \"min\": 274.20854568481445, \"max\": 274.20854568481445}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 56.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.5492337, \"EndTime\": 1716353123.8237069, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 282, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19976555.0, \"count\": 1, \"min\": 19976555, \"max\": 19976555}, \"Total Batches Seen\": {\"sum\": 20094.0, \"count\": 1, \"min\": 20094, \"max\": 20094}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 284.0, \"count\": 1, \"min\": 284, \"max\": 284}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257047.25565290474 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, batch=0 train rmse <loss>=0.734288600303148\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, batch=0 train mse <loss>=0.5391797485351563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, batch=0 train absolute_loss <loss>=0.5685880126953125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:24.093] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 568, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, train rmse <loss>=0.813988149445067\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, train mse <loss>=0.6625767074370048\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=283, train absolute_loss <loss>=0.6119228825099031\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.823544, \"EndTime\": 1716353124.0944753, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.3213691711426, \"count\": 1, \"min\": 270.3213691711426, \"max\": 270.3213691711426}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 56.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353123.8241346, \"EndTime\": 1716353124.0947025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 283, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20047140.0, \"count\": 1, \"min\": 20047140, \"max\": 20047140}, \"Total Batches Seen\": {\"sum\": 20165.0, \"count\": 1, \"min\": 20165, \"max\": 20165}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 285.0, \"count\": 1, \"min\": 285, \"max\": 285}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260747.17312688808 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, batch=0 train rmse <loss>=0.7341020104309415\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, batch=0 train mse <loss>=0.53890576171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, batch=0 train absolute_loss <loss>=0.5684215087890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:24.377] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 570, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, train rmse <loss>=0.8138044656068418\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, train mse <loss>=0.6622777082416373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=284, train absolute_loss <loss>=0.611764112015845\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.0945554, \"EndTime\": 1716353124.3781729, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.02836418151855, \"count\": 1, \"min\": 283.02836418151855, \"max\": 283.02836418151855}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.09512, \"EndTime\": 1716353124.3783958, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 284, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20117725.0, \"count\": 1, \"min\": 20117725, \"max\": 20117725}, \"Total Batches Seen\": {\"sum\": 20236.0, \"count\": 1, \"min\": 20236, \"max\": 20236}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 286.0, \"count\": 1, \"min\": 286, \"max\": 286}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249071.99860007135 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, batch=0 train rmse <loss>=0.7339157889389669\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, batch=0 train mse <loss>=0.5386323852539062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, batch=0 train absolute_loss <loss>=0.568255126953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:24.650] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 572, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, train rmse <loss>=0.8136210578002346\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, train mse <loss>=0.6619792256959727\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=285, train absolute_loss <loss>=0.6116056991362236\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.3782377, \"EndTime\": 1716353124.651082, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.2146511077881, \"count\": 1, \"min\": 272.2146511077881, \"max\": 272.2146511077881}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 57.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.3788419, \"EndTime\": 1716353124.651302, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 285, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20188310.0, \"count\": 1, \"min\": 20188310, \"max\": 20188310}, \"Total Batches Seen\": {\"sum\": 20307.0, \"count\": 1, \"min\": 20307, \"max\": 20307}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 287.0, \"count\": 1, \"min\": 287, \"max\": 287}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258958.60916053504 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, batch=0 train rmse <loss>=0.7337300192924763\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, batch=0 train mse <loss>=0.5383597412109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, batch=0 train absolute_loss <loss>=0.5680911865234375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:24.940] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 574, \"duration\": 287, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, train rmse <loss>=0.8134379690127995\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, train mse <loss>=0.6616813294316681\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=286, train absolute_loss <loss>=0.6114476516078895\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.6511471, \"EndTime\": 1716353124.941015, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.4477844238281, \"count\": 1, \"min\": 289.4477844238281, \"max\": 289.4477844238281}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #progress_metric: host=algo-1, completed 57.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.6515434, \"EndTime\": 1716353124.9412568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 286, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20258895.0, \"count\": 1, \"min\": 20258895, \"max\": 20258895}, \"Total Batches Seen\": {\"sum\": 20378.0, \"count\": 1, \"min\": 20378, \"max\": 20378}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 288.0, \"count\": 1, \"min\": 288, \"max\": 288}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=243493.47282261832 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, batch=0 train rmse <loss>=0.7335446602318686\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, batch=0 train mse <loss>=0.5380877685546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:24 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, batch=0 train absolute_loss <loss>=0.56792724609375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:25.213] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 576, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, train rmse <loss>=0.8132552015740963\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, train mse <loss>=0.6613840228873239\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=287, train absolute_loss <loss>=0.6112901000976563\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.9410853, \"EndTime\": 1716353125.2142718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.66979217529297, \"count\": 1, \"min\": 272.66979217529297, \"max\": 272.66979217529297}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 57.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353124.9415772, \"EndTime\": 1716353125.2144253, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 287, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20329480.0, \"count\": 1, \"min\": 20329480, \"max\": 20329480}, \"Total Batches Seen\": {\"sum\": 20449.0, \"count\": 1, \"min\": 20449, \"max\": 20449}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 289.0, \"count\": 1, \"min\": 289, \"max\": 289}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258601.894116938 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, batch=0 train rmse <loss>=0.7333596704550912\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, batch=0 train mse <loss>=0.53781640625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, batch=0 train absolute_loss <loss>=0.5677633056640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:25.479] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 578, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, train rmse <loss>=0.8130726531441228\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, train mse <loss>=0.6610871392908231\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=288, train absolute_loss <loss>=0.6111328700965559\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.214331, \"EndTime\": 1716353125.4800115, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.3968334197998, \"count\": 1, \"min\": 265.3968334197998, \"max\": 265.3968334197998}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 57.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.2145925, \"EndTime\": 1716353125.4801633, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 288, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20400065.0, \"count\": 1, \"min\": 20400065, \"max\": 20400065}, \"Total Batches Seen\": {\"sum\": 20520.0, \"count\": 1, \"min\": 20520, \"max\": 20520}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 290.0, \"count\": 1, \"min\": 290, \"max\": 290}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265697.66152272146 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, batch=0 train rmse <loss>=0.733175091865532\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, batch=0 train mse <loss>=0.5375457153320312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, batch=0 train absolute_loss <loss>=0.5675994873046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:25.749] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 580, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, train rmse <loss>=0.8128904465430664\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, train mse <loss>=0.6607908780809859\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=289, train absolute_loss <loss>=0.6109760234993948\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.48007, \"EndTime\": 1716353125.7496915, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.3057060241699, \"count\": 1, \"min\": 269.3057060241699, \"max\": 269.3057060241699}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.480364, \"EndTime\": 1716353125.749839, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 289, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20470650.0, \"count\": 1, \"min\": 20470650, \"max\": 20470650}, \"Total Batches Seen\": {\"sum\": 20591.0, \"count\": 1, \"min\": 20591, \"max\": 20591}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 291.0, \"count\": 1, \"min\": 291, \"max\": 291}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261851.62653090648 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, batch=0 train rmse <loss>=0.732990924773821\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, batch=0 train mse <loss>=0.5372756958007813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:25 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, batch=0 train absolute_loss <loss>=0.5674356689453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:26.019] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 582, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, train rmse <loss>=0.8127084878602516\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, train mse <loss>=0.6604950862400968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=290, train absolute_loss <loss>=0.6108193857972051\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.7497468, \"EndTime\": 1716353126.0199955, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.9601650238037, \"count\": 1, \"min\": 269.9601650238037, \"max\": 269.9601650238037}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 58.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353125.7500114, \"EndTime\": 1716353126.020193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 290, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20541235.0, \"count\": 1, \"min\": 20541235, \"max\": 20541235}, \"Total Batches Seen\": {\"sum\": 20662.0, \"count\": 1, \"min\": 20662, \"max\": 20662}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 292.0, \"count\": 1, \"min\": 292, \"max\": 292}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261147.8385559088 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, batch=0 train rmse <loss>=0.7328070862006845\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, batch=0 train mse <loss>=0.5370062255859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, batch=0 train absolute_loss <loss>=0.5672734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:26.283] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 584, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, train rmse <loss>=0.8125268216980676\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, train mse <loss>=0.6601998359787632\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=291, train absolute_loss <loss>=0.61066318307796\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.0200589, \"EndTime\": 1716353126.28347, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.8166675567627, \"count\": 1, \"min\": 262.8166675567627, \"max\": 262.8166675567627}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 58.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.020632, \"EndTime\": 1716353126.2836225, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 291, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20611820.0, \"count\": 1, \"min\": 20611820, \"max\": 20611820}, \"Total Batches Seen\": {\"sum\": 20733.0, \"count\": 1, \"min\": 20733, \"max\": 20733}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 293.0, \"count\": 1, \"min\": 293, \"max\": 293}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268302.2950451226 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, batch=0 train rmse <loss>=0.7326236180486241\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, batch=0 train mse <loss>=0.5367373657226563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, batch=0 train absolute_loss <loss>=0.567111328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:26.553] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 586, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, train rmse <loss>=0.8123454196804955\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, train mse <loss>=0.6599050808758803\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=292, train absolute_loss <loss>=0.6105072812362456\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.2835279, \"EndTime\": 1716353126.5540445, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.0464725494385, \"count\": 1, \"min\": 270.0464725494385, \"max\": 270.0464725494385}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 58.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.283975, \"EndTime\": 1716353126.554198, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 292, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20682405.0, \"count\": 1, \"min\": 20682405, \"max\": 20682405}, \"Total Batches Seen\": {\"sum\": 20804.0, \"count\": 1, \"min\": 20804, \"max\": 20804}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 294.0, \"count\": 1, \"min\": 294, \"max\": 294}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261123.65335918212 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, batch=0 train rmse <loss>=0.7324405205959986\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, batch=0 train mse <loss>=0.5364691162109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, batch=0 train absolute_loss <loss>=0.5669495849609375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:26.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 588, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, train rmse <loss>=0.8121642454673759\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, train mse <loss>=0.659610761615592\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=293, train absolute_loss <loss>=0.6103514679384903\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.5541039, \"EndTime\": 1716353126.825798, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.17037773132324, \"count\": 1, \"min\": 271.17037773132324, \"max\": 271.17037773132324}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #progress_metric: host=algo-1, completed 58.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.554603, \"EndTime\": 1716353126.8259983, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 293, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20752990.0, \"count\": 1, \"min\": 20752990, \"max\": 20752990}, \"Total Batches Seen\": {\"sum\": 20875.0, \"count\": 1, \"min\": 20875, \"max\": 20875}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 295.0, \"count\": 1, \"min\": 295, \"max\": 295}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259974.40064630285 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, batch=0 train rmse <loss>=0.7322578357968849\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, batch=0 train mse <loss>=0.5362015380859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:26 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, batch=0 train absolute_loss <loss>=0.56678857421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:27.086] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 590, \"duration\": 257, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, train rmse <loss>=0.8119833839075233\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, train mse <loss>=0.6593170157419124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=294, train absolute_loss <loss>=0.6101960629745269\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.8258572, \"EndTime\": 1716353127.0864773, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.0431442260742, \"count\": 1, \"min\": 260.0431442260742, \"max\": 260.0431442260742}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353126.8264112, \"EndTime\": 1716353127.0866275, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 294, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20823575.0, \"count\": 1, \"min\": 20823575, \"max\": 20823575}, \"Total Batches Seen\": {\"sum\": 20946.0, \"count\": 1, \"min\": 20946, \"max\": 20946}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 296.0, \"count\": 1, \"min\": 296, \"max\": 296}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=271163.24646728876 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, batch=0 train rmse <loss>=0.7320754805874485\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, batch=0 train mse <loss>=0.5359345092773438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, batch=0 train absolute_loss <loss>=0.5666275024414062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:27.361] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 592, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, train rmse <loss>=0.8118027637314865\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, train mse <loss>=0.6590237272020797\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=295, train absolute_loss <loss>=0.6100409958530479\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.0865362, \"EndTime\": 1716353127.361738, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.66392517089844, \"count\": 1, \"min\": 274.66392517089844, \"max\": 274.66392517089844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 59.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.0870502, \"EndTime\": 1716353127.3619256, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 295, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20894160.0, \"count\": 1, \"min\": 20894160, \"max\": 20894160}, \"Total Batches Seen\": {\"sum\": 21017.0, \"count\": 1, \"min\": 21017, \"max\": 21017}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 297.0, \"count\": 1, \"min\": 297, \"max\": 297}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256688.43880027364 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, batch=0 train rmse <loss>=0.7318934135172962\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, batch=0 train mse <loss>=0.53566796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, batch=0 train absolute_loss <loss>=0.5664678955078125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:27.635] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 594, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, train rmse <loss>=0.8116223596802207\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, train mse <loss>=0.6587308547328895\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=296, train absolute_loss <loss>=0.6098861255914393\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.361805, \"EndTime\": 1716353127.6363597, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.9388942718506, \"count\": 1, \"min\": 273.9388942718506, \"max\": 273.9388942718506}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 59.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.3623946, \"EndTime\": 1716353127.6365929, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 296, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20964745.0, \"count\": 1, \"min\": 20964745, \"max\": 20964745}, \"Total Batches Seen\": {\"sum\": 21088.0, \"count\": 1, \"min\": 21088, \"max\": 21088}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 298.0, \"count\": 1, \"min\": 298, \"max\": 298}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257308.64078471521 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, batch=0 train rmse <loss>=0.7317117599228367\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, batch=0 train mse <loss>=0.535402099609375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, batch=0 train absolute_loss <loss>=0.566308349609375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:27.917] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 596, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, train rmse <loss>=0.8114422068584107\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, train mse <loss>=0.6584384550712478\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=297, train absolute_loss <loss>=0.6097314736809529\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.6364334, \"EndTime\": 1716353127.918245, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.11863136291504, \"count\": 1, \"min\": 281.11863136291504, \"max\": 281.11863136291504}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #progress_metric: host=algo-1, completed 59.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.6371002, \"EndTime\": 1716353127.9185214, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 297, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21035330.0, \"count\": 1, \"min\": 21035330, \"max\": 21035330}, \"Total Batches Seen\": {\"sum\": 21159.0, \"count\": 1, \"min\": 21159, \"max\": 21159}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 299.0, \"count\": 1, \"min\": 299, \"max\": 299}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250691.7705715389 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, batch=0 train rmse <loss>=0.731530394959772\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, batch=0 train mse <loss>=0.53513671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:27 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, batch=0 train absolute_loss <loss>=0.56614892578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:28.200] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 598, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, train rmse <loss>=0.8112623239772124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, train mse <loss>=0.6581465583049075\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=298, train absolute_loss <loss>=0.6095770427005391\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.9183514, \"EndTime\": 1716353128.201428, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.29427337646484, \"count\": 1, \"min\": 282.29427337646484, \"max\": 282.29427337646484}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 59.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353127.9191084, \"EndTime\": 1716353128.2016623, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 298, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21105915.0, \"count\": 1, \"min\": 21105915, \"max\": 21105915}, \"Total Batches Seen\": {\"sum\": 21230.0, \"count\": 1, \"min\": 21230, \"max\": 21230}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 300.0, \"count\": 1, \"min\": 300, \"max\": 300}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249701.17147153808 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, batch=0 train rmse <loss>=0.7313494022983731\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, batch=0 train mse <loss>=0.5348719482421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, batch=0 train absolute_loss <loss>=0.5659899291992188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:28.471] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 600, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, train rmse <loss>=0.8110826825994771\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, train mse <loss>=0.6578551180127641\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=299, train absolute_loss <loss>=0.6094227604395906\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.2015026, \"EndTime\": 1716353128.471579, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.38652992248535, \"count\": 1, \"min\": 269.38652992248535, \"max\": 269.38652992248535}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.2021673, \"EndTime\": 1716353128.4717846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 299, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21176500.0, \"count\": 1, \"min\": 21176500, \"max\": 21176500}, \"Total Batches Seen\": {\"sum\": 21301.0, \"count\": 1, \"min\": 21301, \"max\": 21301}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 301.0, \"count\": 1, \"min\": 301, \"max\": 301}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261684.05556218483 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, batch=0 train rmse <loss>=0.7311686987389607\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, batch=0 train mse <loss>=0.534607666015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, batch=0 train absolute_loss <loss>=0.5658314208984375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:28.742] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 602, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, train rmse <loss>=0.8109032166285668\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, train mse <loss>=0.6575640267385563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=300, train absolute_loss <loss>=0.6092686698806118\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.471643, \"EndTime\": 1716353128.7431602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.88451385498047, \"count\": 1, \"min\": 270.88451385498047, \"max\": 270.88451385498047}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #progress_metric: host=algo-1, completed 60.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.4722512, \"EndTime\": 1716353128.7433755, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 300, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21247085.0, \"count\": 1, \"min\": 21247085, \"max\": 21247085}, \"Total Batches Seen\": {\"sum\": 21372.0, \"count\": 1, \"min\": 21372, \"max\": 21372}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 302.0, \"count\": 1, \"min\": 302, \"max\": 302}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260231.25328195305 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, batch=0 train rmse <loss>=0.7309883679926958\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, batch=0 train mse <loss>=0.534343994140625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:28 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, batch=0 train absolute_loss <loss>=0.5656737670898437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:29.011] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 604, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, train rmse <loss>=0.8107240104786884\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, train mse <loss>=0.6572734211666483\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=301, train absolute_loss <loss>=0.6091148458131602\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.74323, \"EndTime\": 1716353129.0116186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.7285671234131, \"count\": 1, \"min\": 267.7285671234131, \"max\": 267.7285671234131}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 60.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353128.743868, \"EndTime\": 1716353129.0118186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 301, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21317670.0, \"count\": 1, \"min\": 21317670, \"max\": 21317670}, \"Total Batches Seen\": {\"sum\": 21443.0, \"count\": 1, \"min\": 21443, \"max\": 21443}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 303.0, \"count\": 1, \"min\": 303, \"max\": 303}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263320.7548431798 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, batch=0 train rmse <loss>=0.7308082850595762\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, batch=0 train mse <loss>=0.5340807495117188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, batch=0 train absolute_loss <loss>=0.5655174560546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:29.278] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 606, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, train rmse <loss>=0.8105450224291573\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, train mse <loss>=0.6569832333846831\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=302, train absolute_loss <loss>=0.6089611506932219\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.0116916, \"EndTime\": 1716353129.278558, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.18170738220215, \"count\": 1, \"min\": 266.18170738220215, \"max\": 266.18170738220215}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 60.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.0123527, \"EndTime\": 1716353129.2787073, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 302, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21388255.0, \"count\": 1, \"min\": 21388255, \"max\": 21388255}, \"Total Batches Seen\": {\"sum\": 21514.0, \"count\": 1, \"min\": 21514, \"max\": 21514}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 304.0, \"count\": 1, \"min\": 304, \"max\": 304}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264911.43027411454 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, batch=0 train rmse <loss>=0.7306285754296604\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, batch=0 train mse <loss>=0.533818115234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, batch=0 train absolute_loss <loss>=0.5653629150390626\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:29.555] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 608, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, train rmse <loss>=0.8103662807361344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, train mse <loss>=0.6566935089541153\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=303, train absolute_loss <loss>=0.6088075767839458\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.2786152, \"EndTime\": 1716353129.5557556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.5483856201172, \"count\": 1, \"min\": 276.5483856201172, \"max\": 276.5483856201172}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 60.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.279185, \"EndTime\": 1716353129.5559618, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 303, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21458840.0, \"count\": 1, \"min\": 21458840, \"max\": 21458840}, \"Total Batches Seen\": {\"sum\": 21585.0, \"count\": 1, \"min\": 21585, \"max\": 21585}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 305.0, \"count\": 1, \"min\": 305, \"max\": 305}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254926.61701112686 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, batch=0 train rmse <loss>=0.7304490722616935\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, batch=0 train mse <loss>=0.5335558471679688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, batch=0 train absolute_loss <loss>=0.565208251953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:29.829] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 610, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, train rmse <loss>=0.8101877240217447\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, train mse <loss>=0.6564041481555347\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=304, train absolute_loss <loss>=0.6086541773836378\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.5558255, \"EndTime\": 1716353129.8304167, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.21045303344727, \"count\": 1, \"min\": 274.21045303344727, \"max\": 274.21045303344727}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.5561829, \"EndTime\": 1716353129.830604, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 304, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21529425.0, \"count\": 1, \"min\": 21529425, \"max\": 21529425}, \"Total Batches Seen\": {\"sum\": 21656.0, \"count\": 1, \"min\": 21656, \"max\": 21656}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 306.0, \"count\": 1, \"min\": 306, \"max\": 306}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257116.9064155263 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, batch=0 train rmse <loss>=0.7302699428657358\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, batch=0 train mse <loss>=0.533294189453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:29 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, batch=0 train absolute_loss <loss>=0.5650536499023437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:30.102] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 612, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, train rmse <loss>=0.8100094097176593\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, train mse <loss>=0.6561152438311509\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=305, train absolute_loss <loss>=0.6085011003521127\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.830477, \"EndTime\": 1716353130.103162, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.33147621154785, \"count\": 1, \"min\": 272.33147621154785, \"max\": 272.33147621154785}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 61.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353129.830808, \"EndTime\": 1716353130.103388, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 305, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21600010.0, \"count\": 1, \"min\": 21600010, \"max\": 21600010}, \"Total Batches Seen\": {\"sum\": 21727.0, \"count\": 1, \"min\": 21727, \"max\": 21727}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 307.0, \"count\": 1, \"min\": 307, \"max\": 307}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258836.80381888285 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, batch=0 train rmse <loss>=0.7300910621178532\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, batch=0 train mse <loss>=0.533032958984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, batch=0 train absolute_loss <loss>=0.5648990478515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:30.365] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 614, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, train rmse <loss>=0.8098312711084037\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, train mse <loss>=0.6558266876650528\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=306, train absolute_loss <loss>=0.608348349987621\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.1032412, \"EndTime\": 1716353130.36572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.04943656921387, \"count\": 1, \"min\": 262.04943656921387, \"max\": 262.04943656921387}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 61.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.1036477, \"EndTime\": 1716353130.3658748, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 306, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21670595.0, \"count\": 1, \"min\": 21670595, \"max\": 21670595}, \"Total Batches Seen\": {\"sum\": 21798.0, \"count\": 1, \"min\": 21798, \"max\": 21798}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 308.0, \"count\": 1, \"min\": 308, \"max\": 308}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269055.4977011839 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, batch=0 train rmse <loss>=0.7299125138206848\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, batch=0 train mse <loss>=0.5327722778320313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, batch=0 train absolute_loss <loss>=0.5647445068359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:30.641] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 616, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, train rmse <loss>=0.8096533741384959\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, train mse <loss>=0.6555385862538512\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=307, train absolute_loss <loss>=0.6081959873253191\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.3657796, \"EndTime\": 1716353130.6421309, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.7277488708496, \"count\": 1, \"min\": 275.7277488708496, \"max\": 275.7277488708496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 61.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.366376, \"EndTime\": 1716353130.6423464, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 307, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21741180.0, \"count\": 1, \"min\": 21741180, \"max\": 21741180}, \"Total Batches Seen\": {\"sum\": 21869.0, \"count\": 1, \"min\": 21869, \"max\": 21869}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 309.0, \"count\": 1, \"min\": 309, \"max\": 309}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255670.51210107474 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, batch=0 train rmse <loss>=0.7297342145780074\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, batch=0 train mse <loss>=0.5325120239257812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, batch=0 train absolute_loss <loss>=0.5645905151367188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:30.921] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 618, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, train rmse <loss>=0.8094756451593735\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, train mse <loss>=0.655250820106184\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=308, train absolute_loss <loss>=0.608043808628136\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.6421907, \"EndTime\": 1716353130.9220748, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.2630195617676, \"count\": 1, \"min\": 279.2630195617676, \"max\": 279.2630195617676}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #progress_metric: host=algo-1, completed 61.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.6427884, \"EndTime\": 1716353130.9222953, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 308, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21811765.0, \"count\": 1, \"min\": 21811765, \"max\": 21811765}, \"Total Batches Seen\": {\"sum\": 21940.0, \"count\": 1, \"min\": 21940, \"max\": 21940}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 310.0, \"count\": 1, \"min\": 310, \"max\": 310}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252439.4665648001 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, batch=0 train rmse <loss>=0.729556248233087\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, batch=0 train mse <loss>=0.5322523193359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:30 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, batch=0 train absolute_loss <loss>=0.5644376831054687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:31.195] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 620, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, train rmse <loss>=0.8092981384547725\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, train mse <loss>=0.65496347690636\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=309, train absolute_loss <loss>=0.6078918104574714\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.922146, \"EndTime\": 1716353131.1960528, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.23222160339355, \"count\": 1, \"min\": 273.23222160339355, \"max\": 273.23222160339355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353130.9227998, \"EndTime\": 1716353131.1962035, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 309, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21882350.0, \"count\": 1, \"min\": 21882350, \"max\": 21882350}, \"Total Batches Seen\": {\"sum\": 22011.0, \"count\": 1, \"min\": 22011, \"max\": 22011}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 311.0, \"count\": 1, \"min\": 311, \"max\": 311}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258087.22063756635 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, batch=0 train rmse <loss>=0.7293784895080409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, batch=0 train mse <loss>=0.5319929809570313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, batch=0 train absolute_loss <loss>=0.564285400390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:31.458] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 622, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, train rmse <loss>=0.8091208180476964\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, train mse <loss>=0.6546764981981734\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=310, train absolute_loss <loss>=0.6077400435326804\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.196107, \"EndTime\": 1716353131.4586077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.16936111450195, \"count\": 1, \"min\": 262.16936111450195, \"max\": 262.16936111450195}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 62.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.196414, \"EndTime\": 1716353131.4588332, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 310, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21952935.0, \"count\": 1, \"min\": 21952935, \"max\": 21952935}, \"Total Batches Seen\": {\"sum\": 22082.0, \"count\": 1, \"min\": 22082, \"max\": 22082}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 312.0, \"count\": 1, \"min\": 312, \"max\": 312}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268865.641025641 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, batch=0 train rmse <loss>=0.7292010222561232\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, batch=0 train mse <loss>=0.531734130859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, batch=0 train absolute_loss <loss>=0.5641331787109375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:31.729] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 624, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, train rmse <loss>=0.808943695218818\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, train mse <loss>=0.6543899020342759\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=311, train absolute_loss <loss>=0.6075885112923636\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.4586773, \"EndTime\": 1716353131.7296176, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.3530788421631, \"count\": 1, \"min\": 270.3530788421631, \"max\": 270.3530788421631}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 62.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.4592433, \"EndTime\": 1716353131.7298443, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 311, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22023520.0, \"count\": 1, \"min\": 22023520, \"max\": 22023520}, \"Total Batches Seen\": {\"sum\": 22153.0, \"count\": 1, \"min\": 22153, \"max\": 22153}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 313.0, \"count\": 1, \"min\": 313, \"max\": 313}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260731.55784612295 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, batch=0 train rmse <loss>=0.729023804829316\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, batch=0 train mse <loss>=0.5314757080078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, batch=0 train absolute_loss <loss>=0.5639814453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:31.990] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 626, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, train rmse <loss>=0.8087667626575454\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, train mse <loss>=0.6541036763795665\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=312, train absolute_loss <loss>=0.60743720685932\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.7296975, \"EndTime\": 1716353131.9905717, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.4522705078125, \"count\": 1, \"min\": 260.4522705078125, \"max\": 260.4522705078125}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #progress_metric: host=algo-1, completed 62.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.7300966, \"EndTime\": 1716353131.9907393, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 312, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22094105.0, \"count\": 1, \"min\": 22094105, \"max\": 22094105}, \"Total Batches Seen\": {\"sum\": 22224.0, \"count\": 1, \"min\": 22224, \"max\": 22224}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 314.0, \"count\": 1, \"min\": 314, \"max\": 314}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270718.90679122304 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, batch=0 train rmse <loss>=0.7288469211519358\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, batch=0 train mse <loss>=0.5312178344726562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:31 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, batch=0 train absolute_loss <loss>=0.5638313598632813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:32.277] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 628, \"duration\": 284, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, train rmse <loss>=0.8085900178309119\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, train mse <loss>=0.6538178169357944\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=313, train absolute_loss <loss>=0.6072861267949494\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.990645, \"EndTime\": 1716353132.2774472, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.2880229949951, \"count\": 1, \"min\": 286.2880229949951, \"max\": 286.2880229949951}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 62.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353131.9911377, \"EndTime\": 1716353132.277594, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 313, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22164690.0, \"count\": 1, \"min\": 22164690, \"max\": 22164690}, \"Total Batches Seen\": {\"sum\": 22295.0, \"count\": 1, \"min\": 22295, \"max\": 22295}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 315.0, \"count\": 1, \"min\": 315, \"max\": 315}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246331.05395146515 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, batch=0 train rmse <loss>=0.728670245823471\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, batch=0 train mse <loss>=0.5309603271484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, batch=0 train absolute_loss <loss>=0.5636819458007812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:32.563] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 630, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, train rmse <loss>=0.8084134635204998\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, train mse <loss>=0.6535323280012104\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=314, train absolute_loss <loss>=0.6071352779764525\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.2775035, \"EndTime\": 1716353132.5641491, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.1311435699463, \"count\": 1, \"min\": 286.1311435699463, \"max\": 286.1311435699463}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.2779806, \"EndTime\": 1716353132.5644639, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 314, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22235275.0, \"count\": 1, \"min\": 22235275, \"max\": 22235275}, \"Total Batches Seen\": {\"sum\": 22366.0, \"count\": 1, \"min\": 22366, \"max\": 22366}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 316.0, \"count\": 1, \"min\": 316, \"max\": 316}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246288.22506565772 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, batch=0 train rmse <loss>=0.7284937789955082\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, batch=0 train mse <loss>=0.5307031860351562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, batch=0 train absolute_loss <loss>=0.5635330200195312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:32.848] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 632, \"duration\": 282, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, train rmse <loss>=0.8082371083600502\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, train mse <loss>=0.6532472233302157\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=315, train absolute_loss <loss>=0.6069846509476783\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.5642376, \"EndTime\": 1716353132.849411, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.5010757446289, \"count\": 1, \"min\": 284.5010757446289, \"max\": 284.5010757446289}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #progress_metric: host=algo-1, completed 63.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.5648832, \"EndTime\": 1716353132.849627, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 315, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22305860.0, \"count\": 1, \"min\": 22305860, \"max\": 22305860}, \"Total Batches Seen\": {\"sum\": 22437.0, \"count\": 1, \"min\": 22437, \"max\": 22437}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 317.0, \"count\": 1, \"min\": 317, \"max\": 317}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247782.2564254502 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, batch=0 train rmse <loss>=0.7283176046225471\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, batch=0 train mse <loss>=0.530446533203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:32 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, batch=0 train absolute_loss <loss>=0.5633840942382813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:33.120] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 634, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, train rmse <loss>=0.8080609157773653\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, train mse <loss>=0.6529624436069542\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=316, train absolute_loss <loss>=0.6068340608838578\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.8494887, \"EndTime\": 1716353133.1213706, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.46124839782715, \"count\": 1, \"min\": 271.46124839782715, \"max\": 271.46124839782715}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 63.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353132.8498816, \"EndTime\": 1716353133.1215801, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 316, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22376445.0, \"count\": 1, \"min\": 22376445, \"max\": 22376445}, \"Total Batches Seen\": {\"sum\": 22508.0, \"count\": 1, \"min\": 22508, \"max\": 22508}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 318.0, \"count\": 1, \"min\": 318, \"max\": 318}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259679.09957195987 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, batch=0 train rmse <loss>=0.7281416810052749\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, batch=0 train mse <loss>=0.5301903076171876\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, batch=0 train absolute_loss <loss>=0.563235107421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:33.422] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 636, \"duration\": 299, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, train rmse <loss>=0.8078848816225151\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, train mse <loss>=0.6526779819542253\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=317, train absolute_loss <loss>=0.6066836264167034\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.1214414, \"EndTime\": 1716353133.423904, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.02579498291016, \"count\": 1, \"min\": 302.02579498291016, \"max\": 302.02579498291016}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 63.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.1218224, \"EndTime\": 1716353133.4243708, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 317, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22447030.0, \"count\": 1, \"min\": 22447030, \"max\": 22447030}, \"Total Batches Seen\": {\"sum\": 22579.0, \"count\": 1, \"min\": 22579, \"max\": 22579}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 319.0, \"count\": 1, \"min\": 319, \"max\": 319}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=233195.65882875587 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, batch=0 train rmse <loss>=0.7279660083254875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, batch=0 train mse <loss>=0.5299345092773438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, batch=0 train absolute_loss <loss>=0.5630860595703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:33.712] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 638, \"duration\": 284, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, train rmse <loss>=0.807709039524744\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, train mse <loss>=0.6523938925299846\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=318, train absolute_loss <loss>=0.606533418037522\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.42398, \"EndTime\": 1716353133.7129173, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.81938552856445, \"count\": 1, \"min\": 287.81938552856445, \"max\": 287.81938552856445}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 63.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.4250755, \"EndTime\": 1716353133.7130678, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 318, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22517615.0, \"count\": 1, \"min\": 22517615, \"max\": 22517615}, \"Total Batches Seen\": {\"sum\": 22650.0, \"count\": 1, \"min\": 22650, \"max\": 22650}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 320.0, \"count\": 1, \"min\": 320, \"max\": 320}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=245005.78705500602 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, batch=0 train rmse <loss>=0.7277905448330843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, batch=0 train mse <loss>=0.5296790771484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, batch=0 train absolute_loss <loss>=0.56293701171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:33.979] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 640, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, train rmse <loss>=0.807533401319434\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, train mse <loss>=0.6521101942465339\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=319, train absolute_loss <loss>=0.6063833979217099\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.7129724, \"EndTime\": 1716353133.9797742, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.30353927612305, \"count\": 1, \"min\": 266.30353927612305, \"max\": 266.30353927612305}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.713445, \"EndTime\": 1716353133.9799902, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 319, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22588200.0, \"count\": 1, \"min\": 22588200, \"max\": 22588200}, \"Total Batches Seen\": {\"sum\": 22721.0, \"count\": 1, \"min\": 22721, \"max\": 22721}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 321.0, \"count\": 1, \"min\": 321, \"max\": 321}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264670.1024244109 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, batch=0 train rmse <loss>=0.7276152906794007\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, batch=0 train mse <loss>=0.5294240112304688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:33 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, batch=0 train absolute_loss <loss>=0.5627877807617188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:34.249] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 642, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, train rmse <loss>=0.8073578867495567\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, train mse <loss>=0.6518267572967099\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=320, train absolute_loss <loss>=0.6062335849815691\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.979847, \"EndTime\": 1716353134.2498703, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.39868927001953, \"count\": 1, \"min\": 269.39868927001953, \"max\": 269.39868927001953}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 64.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353133.9804494, \"EndTime\": 1716353134.2500734, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 320, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22658785.0, \"count\": 1, \"min\": 22658785, \"max\": 22658785}, \"Total Batches Seen\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261677.81051678848 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, batch=0 train rmse <loss>=0.7274403299197467\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, batch=0 train mse <loss>=0.52916943359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, batch=0 train absolute_loss <loss>=0.5626386108398438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:34.521] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 644, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, train rmse <loss>=0.807182572575824\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, train mse <loss>=0.6515437054701254\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=321, train absolute_loss <loss>=0.6060839284977443\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.24993, \"EndTime\": 1716353134.5216486, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.1360454559326, \"count\": 1, \"min\": 271.1360454559326, \"max\": 271.1360454559326}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 64.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.2504883, \"EndTime\": 1716353134.5218754, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 321, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22729370.0, \"count\": 1, \"min\": 22729370, \"max\": 22729370}, \"Total Batches Seen\": {\"sum\": 22863.0, \"count\": 1, \"min\": 22863, \"max\": 22863}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 323.0, \"count\": 1, \"min\": 323, \"max\": 323}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259984.9024578942 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, batch=0 train rmse <loss>=0.7272655788417108\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, batch=0 train mse <loss>=0.5289152221679687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, batch=0 train absolute_loss <loss>=0.5624893188476563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:34.795] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 646, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, train rmse <loss>=0.8070073950149217\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, train mse <loss>=0.6512609356087699\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=322, train absolute_loss <loss>=0.6059343682947294\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.5217242, \"EndTime\": 1716353134.7955248, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.3895778656006, \"count\": 1, \"min\": 273.3895778656006, \"max\": 273.3895778656006}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #progress_metric: host=algo-1, completed 64.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.5221086, \"EndTime\": 1716353134.7958043, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 322, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22799955.0, \"count\": 1, \"min\": 22799955, \"max\": 22799955}, \"Total Batches Seen\": {\"sum\": 22934.0, \"count\": 1, \"min\": 22934, \"max\": 22934}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 324.0, \"count\": 1, \"min\": 324, \"max\": 324}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257787.8832925245 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, batch=0 train rmse <loss>=0.7270910375964794\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, batch=0 train mse <loss>=0.528661376953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:34 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, batch=0 train absolute_loss <loss>=0.5623399658203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:35.063] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 648, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, train rmse <loss>=0.8068324186163467\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, train mse <loss>=0.6509785517303037\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=323, train absolute_loss <loss>=0.6057852894957636\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.7956386, \"EndTime\": 1716353135.0642314, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.1725025177002, \"count\": 1, \"min\": 268.1725025177002, \"max\": 268.1725025177002}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 64.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353134.7960358, \"EndTime\": 1716353135.064466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 323, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22870540.0, \"count\": 1, \"min\": 22870540, \"max\": 22870540}, \"Total Batches Seen\": {\"sum\": 23005.0, \"count\": 1, \"min\": 23005, \"max\": 23005}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 325.0, \"count\": 1, \"min\": 325, \"max\": 325}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262844.54018733074 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, batch=0 train rmse <loss>=0.7269167483174225\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, batch=0 train mse <loss>=0.528407958984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, batch=0 train absolute_loss <loss>=0.5621905517578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:35.334] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 650, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, train rmse <loss>=0.8066575822336061\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, train mse <loss>=0.650696454974967\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=324, train absolute_loss <loss>=0.6056363645741637\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.0643463, \"EndTime\": 1716353135.3353186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.6270217895508, \"count\": 1, \"min\": 270.6270217895508, \"max\": 270.6270217895508}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.064669, \"EndTime\": 1716353135.3355305, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 324, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22941125.0, \"count\": 1, \"min\": 22941125, \"max\": 22941125}, \"Total Batches Seen\": {\"sum\": 23076.0, \"count\": 1, \"min\": 23076, \"max\": 23076}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 326.0, \"count\": 1, \"min\": 326, \"max\": 326}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260492.96873432712 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, batch=0 train rmse <loss>=0.7267426691935479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, batch=0 train mse <loss>=0.5281549072265626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, batch=0 train absolute_loss <loss>=0.5620411376953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:35.610] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 652, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, train rmse <loss>=0.8064829094081061\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, train mse <loss>=0.6504146831673635\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=325, train absolute_loss <loss>=0.6054875496877751\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.3353817, \"EndTime\": 1716353135.611278, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.3186225891113, \"count\": 1, \"min\": 275.3186225891113, \"max\": 275.3186225891113}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 65.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.33594, \"EndTime\": 1716353135.6114352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 325, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23011710.0, \"count\": 1, \"min\": 23011710, \"max\": 23011710}, \"Total Batches Seen\": {\"sum\": 23147.0, \"count\": 1, \"min\": 23147, \"max\": 23147}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 327.0, \"count\": 1, \"min\": 327, \"max\": 327}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256131.2566097284 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, batch=0 train rmse <loss>=0.726568800375909\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, batch=0 train mse <loss>=0.5279022216796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, batch=0 train absolute_loss <loss>=0.5618916015625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:35.876] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 654, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, train rmse <loss>=0.8063084061099973\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, train mse <loss>=0.6501332457636444\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=326, train absolute_loss <loss>=0.6053389213454555\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.6113322, \"EndTime\": 1716353135.877007, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.2301788330078, \"count\": 1, \"min\": 265.2301788330078, \"max\": 265.2301788330078}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #progress_metric: host=algo-1, completed 65.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.611756, \"EndTime\": 1716353135.8771596, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 326, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23082295.0, \"count\": 1, \"min\": 23082295, \"max\": 23082295}, \"Total Batches Seen\": {\"sum\": 23218.0, \"count\": 1, \"min\": 23218, \"max\": 23218}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 328.0, \"count\": 1, \"min\": 328, \"max\": 328}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265865.16119124996 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, batch=0 train rmse <loss>=0.7263951420155217\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, batch=0 train mse <loss>=0.52764990234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:35 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, batch=0 train absolute_loss <loss>=0.5617427978515624\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:36.145] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 656, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, train rmse <loss>=0.8061340452565287\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, train mse <loss>=0.649852098921655\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=327, train absolute_loss <loss>=0.6051906179508693\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.8770669, \"EndTime\": 1716353136.145631, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.0525779724121, \"count\": 1, \"min\": 268.0525779724121, \"max\": 268.0525779724121}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 65.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353135.8775535, \"EndTime\": 1716353136.1458323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 327, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23152880.0, \"count\": 1, \"min\": 23152880, \"max\": 23152880}, \"Total Batches Seen\": {\"sum\": 23289.0, \"count\": 1, \"min\": 23289, \"max\": 23289}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 329.0, \"count\": 1, \"min\": 329, \"max\": 329}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262980.8928676119 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, batch=0 train rmse <loss>=0.7262216942633634\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, batch=0 train mse <loss>=0.52739794921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, batch=0 train absolute_loss <loss>=0.5615946044921875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:36.410] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 658, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, train rmse <loss>=0.8059598722713512\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, train mse <loss>=0.6495713157116527\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=328, train absolute_loss <loss>=0.6050427383637764\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.1456954, \"EndTime\": 1716353136.4112358, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.9533748626709, \"count\": 1, \"min\": 264.9533748626709, \"max\": 264.9533748626709}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 65.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.1462612, \"EndTime\": 1716353136.4113872, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 328, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23223465.0, \"count\": 1, \"min\": 23223465, \"max\": 23223465}, \"Total Batches Seen\": {\"sum\": 23360.0, \"count\": 1, \"min\": 23360, \"max\": 23360}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 330.0, \"count\": 1, \"min\": 330, \"max\": 330}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266140.72980942106 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, batch=0 train rmse <loss>=0.7260484152379448\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, batch=0 train mse <loss>=0.5271463012695312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, batch=0 train absolute_loss <loss>=0.5614463500976562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:36.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 660, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, train rmse <loss>=0.8057858211317862\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, train mse <loss>=0.6492907895370269\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=329, train absolute_loss <loss>=0.6048950891629071\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.4112942, \"EndTime\": 1716353136.6797168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.90833473205566, \"count\": 1, \"min\": 267.90833473205566, \"max\": 267.90833473205566}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.411786, \"EndTime\": 1716353136.6798651, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 329, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23294050.0, \"count\": 1, \"min\": 23294050, \"max\": 23294050}, \"Total Batches Seen\": {\"sum\": 23431.0, \"count\": 1, \"min\": 23431, \"max\": 23431}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 331.0, \"count\": 1, \"min\": 331, \"max\": 331}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263209.55401373416 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, batch=0 train rmse <loss>=0.7258754311874472\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, batch=0 train mse <loss>=0.5268951416015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, batch=0 train absolute_loss <loss>=0.561298095703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:36.946] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 662, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, train rmse <loss>=0.8056119249961998\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, train mse <loss>=0.6490105736960827\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=330, train absolute_loss <loss>=0.6047476058745048\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.6797738, \"EndTime\": 1716353136.9470139, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.72935485839844, \"count\": 1, \"min\": 266.72935485839844, \"max\": 266.72935485839844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #progress_metric: host=algo-1, completed 66.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.6802619, \"EndTime\": 1716353136.9471676, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 330, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23364635.0, \"count\": 1, \"min\": 23364635, \"max\": 23364635}, \"Total Batches Seen\": {\"sum\": 23502.0, \"count\": 1, \"min\": 23502, \"max\": 23502}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 332.0, \"count\": 1, \"min\": 332, \"max\": 332}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264366.1683396332 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, batch=0 train rmse <loss>=0.7257025741129893\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, batch=0 train mse <loss>=0.5266442260742188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:36 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, batch=0 train absolute_loss <loss>=0.561149658203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:37.214] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 664, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, train rmse <loss>=0.8054382325274723\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, train mse <loss>=0.6487307464169785\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=331, train absolute_loss <loss>=0.6046003237442231\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.947074, \"EndTime\": 1716353137.2150512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.4539089202881, \"count\": 1, \"min\": 267.4539089202881, \"max\": 267.4539089202881}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 66.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353136.9475708, \"EndTime\": 1716353137.2152588, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 331, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23435220.0, \"count\": 1, \"min\": 23435220, \"max\": 23435220}, \"Total Batches Seen\": {\"sum\": 23573.0, \"count\": 1, \"min\": 23573, \"max\": 23573}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 333.0, \"count\": 1, \"min\": 333, \"max\": 333}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263574.17509472667 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, batch=0 train rmse <loss>=0.7255299282302643\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, batch=0 train mse <loss>=0.5263936767578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, batch=0 train absolute_loss <loss>=0.5610010986328124\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:37.486] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 666, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, train rmse <loss>=0.8052646403062764\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, train mse <loss>=0.6484511409275968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=332, train absolute_loss <loss>=0.6044531035087478\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.2151115, \"EndTime\": 1716353137.4867935, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.0909843444824, \"count\": 1, \"min\": 271.0909843444824, \"max\": 271.0909843444824}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 66.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.2156808, \"EndTime\": 1716353137.486947, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 332, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23505805.0, \"count\": 1, \"min\": 23505805, \"max\": 23505805}, \"Total Batches Seen\": {\"sum\": 23644.0, \"count\": 1, \"min\": 23644, \"max\": 23644}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 334.0, \"count\": 1, \"min\": 334, \"max\": 334}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260119.67487560943 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, batch=0 train rmse <loss>=0.7253574936900726\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, batch=0 train mse <loss>=0.5261434936523437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, batch=0 train absolute_loss <loss>=0.5608524780273437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:37.754] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 668, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, train rmse <loss>=0.8050911932436879\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, train mse <loss>=0.6481718294385453\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=333, train absolute_loss <loss>=0.6043061377296985\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.4868538, \"EndTime\": 1716353137.755036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.64845848083496, \"count\": 1, \"min\": 267.64845848083496, \"max\": 267.64845848083496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #progress_metric: host=algo-1, completed 66.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.4873645, \"EndTime\": 1716353137.7551975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 333, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23576390.0, \"count\": 1, \"min\": 23576390, \"max\": 23576390}, \"Total Batches Seen\": {\"sum\": 23715.0, \"count\": 1, \"min\": 23715, \"max\": 23715}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 335.0, \"count\": 1, \"min\": 335, \"max\": 335}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263450.33444863674 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, batch=0 train rmse <loss>=0.7251852706431733\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, batch=0 train mse <loss>=0.5258936767578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:37 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, batch=0 train absolute_loss <loss>=0.5607059326171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:38.030] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 670, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, train rmse <loss>=0.8049179432314094\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, train mse <loss>=0.6478928953358825\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=334, train absolute_loss <loss>=0.6041592802665603\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.7550948, \"EndTime\": 1716353138.0313573, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.7284641265869, \"count\": 1, \"min\": 275.7284641265869, \"max\": 275.7284641265869}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353137.7556076, \"EndTime\": 1716353138.0315855, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 334, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23646975.0, \"count\": 1, \"min\": 23646975, \"max\": 23646975}, \"Total Batches Seen\": {\"sum\": 23786.0, \"count\": 1, \"min\": 23786, \"max\": 23786}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 336.0, \"count\": 1, \"min\": 336, \"max\": 336}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255654.17432551345 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, batch=0 train rmse <loss>=0.7250132171478411\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, batch=0 train mse <loss>=0.5256441650390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, batch=0 train absolute_loss <loss>=0.5605597534179687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:38.293] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 672, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, train rmse <loss>=0.8047447814375626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, train mse <loss>=0.6476141632509903\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=335, train absolute_loss <loss>=0.6040124150665713\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.0314374, \"EndTime\": 1716353138.2938857, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.8579864501953, \"count\": 1, \"min\": 261.8579864501953, \"max\": 261.8579864501953}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 67.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.032004, \"EndTime\": 1716353138.2940526, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 335, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23717560.0, \"count\": 1, \"min\": 23717560, \"max\": 23717560}, \"Total Batches Seen\": {\"sum\": 23857.0, \"count\": 1, \"min\": 23857, \"max\": 23857}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 337.0, \"count\": 1, \"min\": 337, \"max\": 337}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269264.2336488718 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, batch=0 train rmse <loss>=0.7248413754272379\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, batch=0 train mse <loss>=0.52539501953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, batch=0 train absolute_loss <loss>=0.5604135131835938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:38.564] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 674, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, train rmse <loss>=0.8045718142305486\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, train mse <loss>=0.6473358042542363\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=336, train absolute_loss <loss>=0.6038656573228434\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.2939544, \"EndTime\": 1716353138.5645933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.1139450073242, \"count\": 1, \"min\": 270.1139450073242, \"max\": 270.1139450073242}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 67.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.2944543, \"EndTime\": 1716353138.5648057, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 336, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23788145.0, \"count\": 1, \"min\": 23788145, \"max\": 23788145}, \"Total Batches Seen\": {\"sum\": 23928.0, \"count\": 1, \"min\": 23928, \"max\": 23928}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 338.0, \"count\": 1, \"min\": 338, \"max\": 338}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260973.11492057223 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, batch=0 train rmse <loss>=0.7246697035196233\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, batch=0 train mse <loss>=0.5251461791992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, batch=0 train absolute_loss <loss>=0.5602671508789062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:38.847] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 676, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, train rmse <loss>=0.8043989658591737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, train mse <loss>=0.6470576962753081\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=337, train absolute_loss <loss>=0.6037190491582306\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.5646625, \"EndTime\": 1716353138.8481505, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.09059143066406, \"count\": 1, \"min\": 283.09059143066406, \"max\": 283.09059143066406}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #progress_metric: host=algo-1, completed 67.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.5650375, \"EndTime\": 1716353138.848383, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 337, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23858730.0, \"count\": 1, \"min\": 23858730, \"max\": 23858730}, \"Total Batches Seen\": {\"sum\": 23999.0, \"count\": 1, \"min\": 23999, \"max\": 23999}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 339.0, \"count\": 1, \"min\": 339, \"max\": 339}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249003.7056313175 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, batch=0 train rmse <loss>=0.7244982436680748\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, batch=0 train mse <loss>=0.524897705078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:38 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, batch=0 train absolute_loss <loss>=0.56012060546875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:39.124] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 678, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, train rmse <loss>=0.8042262668641584\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, train mse <loss>=0.6467798883142606\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=338, train absolute_loss <loss>=0.6035726198008363\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.848219, \"EndTime\": 1716353139.1253345, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.49855613708496, \"count\": 1, \"min\": 276.49855613708496, \"max\": 276.49855613708496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 67.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353138.8488119, \"EndTime\": 1716353139.1255577, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 338, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23929315.0, \"count\": 1, \"min\": 23929315, \"max\": 23929315}, \"Total Batches Seen\": {\"sum\": 24070.0, \"count\": 1, \"min\": 24070, \"max\": 24070}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 340.0, \"count\": 1, \"min\": 340, \"max\": 340}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254939.5688704226 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, batch=0 train rmse <loss>=0.7243269538908603\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, batch=0 train mse <loss>=0.5246495361328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, batch=0 train absolute_loss <loss>=0.5599739990234375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:39.384] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 680, \"duration\": 256, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, train rmse <loss>=0.8040537168071817\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, train mse <loss>=0.6465023795114436\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=339, train absolute_loss <loss>=0.6034265471982284\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.1254008, \"EndTime\": 1716353139.38501, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 258.9893341064453, \"count\": 1, \"min\": 258.9893341064453, \"max\": 258.9893341064453}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.1259966, \"EndTime\": 1716353139.3852048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 339, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23999900.0, \"count\": 1, \"min\": 23999900, \"max\": 23999900}, \"Total Batches Seen\": {\"sum\": 24141.0, \"count\": 1, \"min\": 24141, \"max\": 24141}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 341.0, \"count\": 1, \"min\": 341, \"max\": 341}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=272204.39844798733 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, batch=0 train rmse <loss>=0.7241558343086668\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, batch=0 train mse <loss>=0.5244016723632813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, batch=0 train absolute_loss <loss>=0.5598272094726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:39.661] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 682, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, train rmse <loss>=0.8038813034863451\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, train mse <loss>=0.6462251500949053\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=340, train absolute_loss <loss>=0.6032804797535212\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.3850732, \"EndTime\": 1716353139.6620734, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.4701843261719, \"count\": 1, \"min\": 276.4701843261719, \"max\": 276.4701843261719}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 68.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.3855813, \"EndTime\": 1716353139.6623325, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 340, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24070485.0, \"count\": 1, \"min\": 24070485, \"max\": 24070485}, \"Total Batches Seen\": {\"sum\": 24212.0, \"count\": 1, \"min\": 24212, \"max\": 24212}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 342.0, \"count\": 1, \"min\": 342, \"max\": 342}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254951.2047136551 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, batch=0 train rmse <loss>=0.723984885042175\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, batch=0 train mse <loss>=0.5241541137695312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, batch=0 train absolute_loss <loss>=0.5596802368164062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:39.937] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 684, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, train rmse <loss>=0.8037090269896474\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, train mse <loss>=0.6459482000646457\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=341, train absolute_loss <loss>=0.6031344707650198\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.6621602, \"EndTime\": 1716353139.9377801, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.8374938964844, \"count\": 1, \"min\": 274.8374938964844, \"max\": 274.8374938964844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #progress_metric: host=algo-1, completed 68.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.6629214, \"EndTime\": 1716353139.937931, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 341, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24141070.0, \"count\": 1, \"min\": 24141070, \"max\": 24141070}, \"Total Batches Seen\": {\"sum\": 24283.0, \"count\": 1, \"min\": 24283, \"max\": 24283}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 343.0, \"count\": 1, \"min\": 343, \"max\": 343}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256567.86983330516 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, batch=0 train rmse <loss>=0.7238141905364076\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, batch=0 train mse <loss>=0.523906982421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:39 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, batch=0 train absolute_loss <loss>=0.5595332641601563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:40.209] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 686, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, train rmse <loss>=0.8035369253841549\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, train mse <loss>=0.6456715904558209\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=342, train absolute_loss <loss>=0.602988524530975\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.9378393, \"EndTime\": 1716353140.2100382, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.6805934906006, \"count\": 1, \"min\": 271.6805934906006, \"max\": 271.6805934906006}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 68.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353139.9383347, \"EndTime\": 1716353140.2102287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 342, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24211655.0, \"count\": 1, \"min\": 24211655, \"max\": 24211655}, \"Total Batches Seen\": {\"sum\": 24354.0, \"count\": 1, \"min\": 24354, \"max\": 24354}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 344.0, \"count\": 1, \"min\": 344, \"max\": 344}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259504.51536446167 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, batch=0 train rmse <loss>=0.7236435822832173\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, batch=0 train mse <loss>=0.5236600341796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, batch=0 train absolute_loss <loss>=0.5593860473632812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:40.481] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 688, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, train rmse <loss>=0.8033649244129772\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, train mse <loss>=0.6453952017770687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=343, train absolute_loss <loss>=0.6028427373321963\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.2101016, \"EndTime\": 1716353140.481954, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.3274955749512, \"count\": 1, \"min\": 271.3274955749512, \"max\": 271.3274955749512}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 68.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.210597, \"EndTime\": 1716353140.482107, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 343, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24282240.0, \"count\": 1, \"min\": 24282240, \"max\": 24282240}, \"Total Batches Seen\": {\"sum\": 24425.0, \"count\": 1, \"min\": 24425, \"max\": 24425}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 345.0, \"count\": 1, \"min\": 345, \"max\": 345}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259886.7664411514 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, batch=0 train rmse <loss>=0.7234731868897682\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, batch=0 train mse <loss>=0.5234134521484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, batch=0 train absolute_loss <loss>=0.55923876953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:40.754] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 690, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, train rmse <loss>=0.8031931038774252\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, train mse <loss>=0.6451191621162522\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=344, train absolute_loss <loss>=0.6026973790988116\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.4820123, \"EndTime\": 1716353140.754979, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.49765396118164, \"count\": 1, \"min\": 272.49765396118164, \"max\": 272.49765396118164}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #progress_metric: host=algo-1, completed 69.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.4824605, \"EndTime\": 1716353140.7551246, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 344, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24352825.0, \"count\": 1, \"min\": 24352825, \"max\": 24352825}, \"Total Batches Seen\": {\"sum\": 24496.0, \"count\": 1, \"min\": 24496, \"max\": 24496}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 346.0, \"count\": 1, \"min\": 346, \"max\": 346}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258786.34931596057 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, batch=0 train rmse <loss>=0.7233029623145261\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, batch=0 train mse <loss>=0.5231671752929687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:40 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, batch=0 train absolute_loss <loss>=0.5590912475585937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:41.045] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 692, \"duration\": 287, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, train rmse <loss>=0.8030213852101378\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, train mse <loss>=0.6448433451048086\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=345, train absolute_loss <loss>=0.6025522813394036\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.7550344, \"EndTime\": 1716353141.0457644, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 290.21668434143066, \"count\": 1, \"min\": 290.21668434143066, \"max\": 290.21668434143066}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 69.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353140.7555234, \"EndTime\": 1716353141.046014, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 345, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24423410.0, \"count\": 1, \"min\": 24423410, \"max\": 24423410}, \"Total Batches Seen\": {\"sum\": 24567.0, \"count\": 1, \"min\": 24567, \"max\": 24567}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 347.0, \"count\": 1, \"min\": 347, \"max\": 347}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=242883.7982600934 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, batch=0 train rmse <loss>=0.7231329508800145\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, batch=0 train mse <loss>=0.5229212646484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, batch=0 train absolute_loss <loss>=0.5589437255859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:41.309] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 694, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, train rmse <loss>=0.8028498236200197\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, train mse <loss>=0.6445678392866967\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=346, train absolute_loss <loss>=0.6024073159661092\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.0458395, \"EndTime\": 1716353141.3103368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.02759552001953, \"count\": 1, \"min\": 264.02759552001953, \"max\": 264.02759552001953}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 69.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.0462856, \"EndTime\": 1716353141.3104908, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 346, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24493995.0, \"count\": 1, \"min\": 24493995, \"max\": 24493995}, \"Total Batches Seen\": {\"sum\": 24638.0, \"count\": 1, \"min\": 24638, \"max\": 24638}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 348.0, \"count\": 1, \"min\": 348, \"max\": 348}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267062.6288518438 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, batch=0 train rmse <loss>=0.7229630683129887\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, batch=0 train mse <loss>=0.5226755981445312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, batch=0 train absolute_loss <loss>=0.5587959594726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:41.575] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 696, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, train rmse <loss>=0.802678407962532\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, train mse <loss>=0.644292626609265\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=347, train absolute_loss <loss>=0.6022623763823174\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.310397, \"EndTime\": 1716353141.5759957, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.3176784515381, \"count\": 1, \"min\": 265.3176784515381, \"max\": 265.3176784515381}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 69.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.3106556, \"EndTime\": 1716353141.5761638, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 347, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24564580.0, \"count\": 1, \"min\": 24564580, \"max\": 24564580}, \"Total Batches Seen\": {\"sum\": 24709.0, \"count\": 1, \"min\": 24709, \"max\": 24709}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 349.0, \"count\": 1, \"min\": 349, \"max\": 349}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265758.0038815011 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, batch=0 train rmse <loss>=0.7227933569260347\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, batch=0 train mse <loss>=0.5224302368164062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, batch=0 train absolute_loss <loss>=0.5586480712890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:41.856] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 698, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, train rmse <loss>=0.8025071110154468\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, train mse <loss>=0.6440176632303587\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=348, train absolute_loss <loss>=0.6021176732022997\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.576068, \"EndTime\": 1716353141.856526, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.1477909088135, \"count\": 1, \"min\": 280.1477909088135, \"max\": 280.1477909088135}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #progress_metric: host=algo-1, completed 69.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.5763564, \"EndTime\": 1716353141.8566895, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 348, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24635165.0, \"count\": 1, \"min\": 24635165, \"max\": 24635165}, \"Total Batches Seen\": {\"sum\": 24780.0, \"count\": 1, \"min\": 24780, \"max\": 24780}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 350.0, \"count\": 1, \"min\": 350, \"max\": 350}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251711.87386814447 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, batch=0 train rmse <loss>=0.7226238590713835\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, batch=0 train mse <loss>=0.5221852416992188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:41 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, batch=0 train absolute_loss <loss>=0.5585001220703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:42.124] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 700, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, train rmse <loss>=0.8023359719621416\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, train mse <loss>=0.6437430119044344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=349, train absolute_loss <loss>=0.601973075759243\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.8565958, \"EndTime\": 1716353142.1248353, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.958402633667, \"count\": 1, \"min\": 267.958402633667, \"max\": 267.958402633667}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353141.856856, \"EndTime\": 1716353142.125049, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 349, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24705750.0, \"count\": 1, \"min\": 24705750, \"max\": 24705750}, \"Total Batches Seen\": {\"sum\": 24851.0, \"count\": 1, \"min\": 24851, \"max\": 24851}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 351.0, \"count\": 1, \"min\": 351, \"max\": 351}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263076.704473962 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, batch=0 train rmse <loss>=0.7224544481747621\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, batch=0 train mse <loss>=0.5219404296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, batch=0 train absolute_loss <loss>=0.5583518676757813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:42.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 702, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, train rmse <loss>=0.8021649453580196\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, train mse <loss>=0.6434685995612346\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=350, train absolute_loss <loss>=0.6018286751760563\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.1249003, \"EndTime\": 1716353142.4080825, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.76991844177246, \"count\": 1, \"min\": 282.76991844177246, \"max\": 282.76991844177246}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 70.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.1252859, \"EndTime\": 1716353142.4083273, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 350, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24776335.0, \"count\": 1, \"min\": 24776335, \"max\": 24776335}, \"Total Batches Seen\": {\"sum\": 24922.0, \"count\": 1, \"min\": 24922, \"max\": 24922}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 352.0, \"count\": 1, \"min\": 352, \"max\": 352}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249283.3993250389 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, batch=0 train rmse <loss>=0.7222852933030515\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, batch=0 train mse <loss>=0.521696044921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, batch=0 train absolute_loss <loss>=0.55820361328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:42.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 704, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, train rmse <loss>=0.8019940843336177\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, train mse <loss>=0.6431945113061179\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=351, train absolute_loss <loss>=0.6016844001017826\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.4081504, \"EndTime\": 1716353142.680181, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.59857749938965, \"count\": 1, \"min\": 271.59857749938965, \"max\": 271.59857749938965}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 70.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.4085581, \"EndTime\": 1716353142.6804066, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 351, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24846920.0, \"count\": 1, \"min\": 24846920, \"max\": 24846920}, \"Total Batches Seen\": {\"sum\": 24993.0, \"count\": 1, \"min\": 24993, \"max\": 24993}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 353.0, \"count\": 1, \"min\": 353, \"max\": 353}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259542.05277193818 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, batch=0 train rmse <loss>=0.7221162678522587\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, batch=0 train mse <loss>=0.521451904296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, batch=0 train absolute_loss <loss>=0.55805517578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:42.961] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 706, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, train rmse <loss>=0.8018233584393943\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, train mse <loss>=0.6429206981390295\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=352, train absolute_loss <loss>=0.6015403012557768\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.6802504, \"EndTime\": 1716353142.9620557, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.4021110534668, \"count\": 1, \"min\": 281.4021110534668, \"max\": 281.4021110534668}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #progress_metric: host=algo-1, completed 70.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.6806307, \"EndTime\": 1716353142.9622028, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 352, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24917505.0, \"count\": 1, \"min\": 24917505, \"max\": 24917505}, \"Total Batches Seen\": {\"sum\": 25064.0, \"count\": 1, \"min\": 25064, \"max\": 25064}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 354.0, \"count\": 1, \"min\": 354, \"max\": 354}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250596.7054680887 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, batch=0 train rmse <loss>=0.7219473719132856\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, batch=0 train mse <loss>=0.5212080078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:42 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, batch=0 train absolute_loss <loss>=0.5579072875976563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:43.223] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 708, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, train rmse <loss>=0.8016527286210112\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, train mse <loss>=0.6426470973055127\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=353, train absolute_loss <loss>=0.6013961929536201\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.962111, \"EndTime\": 1716353143.2240667, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.6763114929199, \"count\": 1, \"min\": 261.6763114929199, \"max\": 261.6763114929199}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 70.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353142.9623668, \"EndTime\": 1716353143.2242641, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 353, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24988090.0, \"count\": 1, \"min\": 24988090, \"max\": 24988090}, \"Total Batches Seen\": {\"sum\": 25135.0, \"count\": 1, \"min\": 25135, \"max\": 25135}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 355.0, \"count\": 1, \"min\": 355, \"max\": 355}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269390.4151573139 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, batch=0 train rmse <loss>=0.7217786478581271\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, batch=0 train mse <loss>=0.5209644165039062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, batch=0 train absolute_loss <loss>=0.55776171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:43.509] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 710, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, train rmse <loss>=0.8014822694838171\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, train mse <loss>=0.64237382829693\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=354, train absolute_loss <loss>=0.6012523494236905\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.2241306, \"EndTime\": 1716353143.5098226, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.2959632873535, \"count\": 1, \"min\": 285.2959632873535, \"max\": 285.2959632873535}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 71.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.224504, \"EndTime\": 1716353143.5100253, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 354, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25058675.0, \"count\": 1, \"min\": 25058675, \"max\": 25058675}, \"Total Batches Seen\": {\"sum\": 25206.0, \"count\": 1, \"min\": 25206, \"max\": 25206}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 356.0, \"count\": 1, \"min\": 356, \"max\": 356}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=247116.49199774966 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, batch=0 train rmse <loss>=0.7216101380983017\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, batch=0 train mse <loss>=0.52072119140625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, batch=0 train absolute_loss <loss>=0.5576160278320312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:43.780] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 712, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, train rmse <loss>=0.801311951098245\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, train mse <loss>=0.6421008429728763\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=355, train absolute_loss <loss>=0.6011086872799296\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.5098913, \"EndTime\": 1716353143.7811823, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.8849906921387, \"count\": 1, \"min\": 270.8849906921387, \"max\": 270.8849906921387}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #progress_metric: host=algo-1, completed 71.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.5102746, \"EndTime\": 1716353143.781333, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 355, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25129260.0, \"count\": 1, \"min\": 25129260, \"max\": 25129260}, \"Total Batches Seen\": {\"sum\": 25277.0, \"count\": 1, \"min\": 25277, \"max\": 25277}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 357.0, \"count\": 1, \"min\": 357, \"max\": 357}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260317.0599479814 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, batch=0 train rmse <loss>=0.7214417158815135\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, batch=0 train mse <loss>=0.5204781494140625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:43 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, batch=0 train absolute_loss <loss>=0.5574701538085938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:44.059] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 714, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, train rmse <loss>=0.8011417826748292\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, train mse <loss>=0.6418281559474032\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=356, train absolute_loss <loss>=0.6009651042239766\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.781239, \"EndTime\": 1716353144.059462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.94432640075684, \"count\": 1, \"min\": 277.94432640075684, \"max\": 277.94432640075684}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 71.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353143.781496, \"EndTime\": 1716353144.0596154, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 356, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25199845.0, \"count\": 1, \"min\": 25199845, \"max\": 25199845}, \"Total Batches Seen\": {\"sum\": 25348.0, \"count\": 1, \"min\": 25348, \"max\": 25348}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 358.0, \"count\": 1, \"min\": 358, \"max\": 358}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253712.38112867344 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, batch=0 train rmse <loss>=0.7212734658904737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, batch=0 train mse <loss>=0.5202354125976563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, batch=0 train absolute_loss <loss>=0.5573242797851562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:44.329] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 716, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, train rmse <loss>=0.8009717186956435\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, train mse <loss>=0.641555694150253\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=357, train absolute_loss <loss>=0.6008215865014305\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.0595222, \"EndTime\": 1716353144.3302927, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.4904079437256, \"count\": 1, \"min\": 270.4904079437256, \"max\": 270.4904079437256}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 71.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.0597808, \"EndTime\": 1716353144.3304482, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 357, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25270430.0, \"count\": 1, \"min\": 25270430, \"max\": 25270430}, \"Total Batches Seen\": {\"sum\": 25419.0, \"count\": 1, \"min\": 25419, \"max\": 25419}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 359.0, \"count\": 1, \"min\": 359, \"max\": 359}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260696.65986280743 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, batch=0 train rmse <loss>=0.7211054305662852\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, batch=0 train mse <loss>=0.5199930419921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, batch=0 train absolute_loss <loss>=0.5571783447265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:44.609] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 718, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, train rmse <loss>=0.8008017683518672\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, train mse <loss>=0.6412834721954775\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=358, train absolute_loss <loss>=0.6006780008665273\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.3303523, \"EndTime\": 1716353144.6105285, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.85286712646484, \"count\": 1, \"min\": 279.85286712646484, \"max\": 279.85286712646484}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 71.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.3306527, \"EndTime\": 1716353144.6107354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 358, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25341015.0, \"count\": 1, \"min\": 25341015, \"max\": 25341015}, \"Total Batches Seen\": {\"sum\": 25490.0, \"count\": 1, \"min\": 25490, \"max\": 25490}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 360.0, \"count\": 1, \"min\": 360, \"max\": 360}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251912.13288281197 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, batch=0 train rmse <loss>=0.7209375253982441\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, batch=0 train mse <loss>=0.5197509155273438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, batch=0 train absolute_loss <loss>=0.5570322875976562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:44.889] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 720, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, train rmse <loss>=0.8006320160024456\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, train mse <loss>=0.6410116250481404\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=359, train absolute_loss <loss>=0.6005348252847161\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.6106052, \"EndTime\": 1716353144.88973, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.7168025970459, \"count\": 1, \"min\": 278.7168025970459, \"max\": 278.7168025970459}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.610987, \"EndTime\": 1716353144.8899498, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 359, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25411600.0, \"count\": 1, \"min\": 25411600, \"max\": 25411600}, \"Total Batches Seen\": {\"sum\": 25561.0, \"count\": 1, \"min\": 25561, \"max\": 25561}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 361.0, \"count\": 1, \"min\": 361, \"max\": 361}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252912.60914656127 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, batch=0 train rmse <loss>=0.720769750477311\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, batch=0 train mse <loss>=0.519509033203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:44 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, batch=0 train absolute_loss <loss>=0.556885986328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:45.160] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 722, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, train rmse <loss>=0.8004623720991992\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, train mse <loss>=0.640740009146677\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=360, train absolute_loss <loss>=0.6003918010013204\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.8897989, \"EndTime\": 1716353145.1607754, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.5554962158203, \"count\": 1, \"min\": 270.5554962158203, \"max\": 270.5554962158203}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 72.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353144.8901968, \"EndTime\": 1716353145.1609502, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 360, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25482185.0, \"count\": 1, \"min\": 25482185, \"max\": 25482185}, \"Total Batches Seen\": {\"sum\": 25632.0, \"count\": 1, \"min\": 25632, \"max\": 25632}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 362.0, \"count\": 1, \"min\": 362, \"max\": 362}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260600.2797764183 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, batch=0 train rmse <loss>=0.7206021482445688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, batch=0 train mse <loss>=0.5192674560546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, batch=0 train absolute_loss <loss>=0.5567400512695313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:45.425] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 724, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, train rmse <loss>=0.8002928565832264\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, train mse <loss>=0.6404686562981404\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=361, train absolute_loss <loss>=0.6002491979464679\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.1608515, \"EndTime\": 1716353145.426051, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.9056911468506, \"count\": 1, \"min\": 264.9056911468506, \"max\": 264.9056911468506}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 72.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.161124, \"EndTime\": 1716353145.4261987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 361, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25552770.0, \"count\": 1, \"min\": 25552770, \"max\": 25552770}, \"Total Batches Seen\": {\"sum\": 25703.0, \"count\": 1, \"min\": 25703, \"max\": 25703}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 363.0, \"count\": 1, \"min\": 363, \"max\": 363}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266195.0504462885 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, batch=0 train rmse <loss>=0.7204347188205406\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, batch=0 train mse <loss>=0.5190261840820313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, batch=0 train absolute_loss <loss>=0.55659423828125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:45.706] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 726, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, train rmse <loss>=0.8001234673873342\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, train mse <loss>=0.6401975630639305\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=362, train absolute_loss <loss>=0.6001068407515405\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.4261062, \"EndTime\": 1716353145.7066035, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.2104949951172, \"count\": 1, \"min\": 280.2104949951172, \"max\": 280.2104949951172}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 72.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.4263685, \"EndTime\": 1716353145.706787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 362, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25623355.0, \"count\": 1, \"min\": 25623355, \"max\": 25623355}, \"Total Batches Seen\": {\"sum\": 25774.0, \"count\": 1, \"min\": 25774, \"max\": 25774}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 364.0, \"count\": 1, \"min\": 364, \"max\": 364}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251617.9583122628 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, batch=0 train rmse <loss>=0.7202674199559495\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, batch=0 train mse <loss>=0.51878515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, batch=0 train absolute_loss <loss>=0.556448486328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:45.981] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 728, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, train rmse <loss>=0.7999542379051146\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, train mse <loss>=0.6399267827423526\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=363, train absolute_loss <loss>=0.5999646408725793\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.7066677, \"EndTime\": 1716353145.9821408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.1202583312988, \"count\": 1, \"min\": 275.1202583312988, \"max\": 275.1202583312988}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #progress_metric: host=algo-1, completed 72.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.7069955, \"EndTime\": 1716353145.9823713, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 363, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25693940.0, \"count\": 1, \"min\": 25693940, \"max\": 25693940}, \"Total Batches Seen\": {\"sum\": 25845.0, \"count\": 1, \"min\": 25845, \"max\": 25845}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 365.0, \"count\": 1, \"min\": 365, \"max\": 365}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256209.7239852603 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, batch=0 train rmse <loss>=0.7201002941214162\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, batch=0 train mse <loss>=0.51854443359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:45 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, batch=0 train absolute_loss <loss>=0.556302734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:46.243] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 730, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, train rmse <loss>=0.7997851247064737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, train mse <loss>=0.6396562457017496\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=364, train absolute_loss <loss>=0.5998225630639304\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.9822202, \"EndTime\": 1716353146.24361, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.96534729003906, \"count\": 1, \"min\": 260.96534729003906, \"max\": 260.96534729003906}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 73.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353145.9826217, \"EndTime\": 1716353146.243822, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 364, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25764525.0, \"count\": 1, \"min\": 25764525, \"max\": 25764525}, \"Total Batches Seen\": {\"sum\": 25916.0, \"count\": 1, \"min\": 25916, \"max\": 25916}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 366.0, \"count\": 1, \"min\": 366, \"max\": 366}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270127.3175222608 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, batch=0 train rmse <loss>=0.7199332990479916\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, batch=0 train mse <loss>=0.518303955078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, batch=0 train absolute_loss <loss>=0.5561572265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:46.524] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 732, \"duration\": 278, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, train rmse <loss>=0.7996161622677015\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, train mse <loss>=0.6393860069597271\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=365, train absolute_loss <loss>=0.5996804611850792\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.2436807, \"EndTime\": 1716353146.5246208, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.51209449768066, \"count\": 1, \"min\": 280.51209449768066, \"max\": 280.51209449768066}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 73.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.244085, \"EndTime\": 1716353146.5248384, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 365, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25835110.0, \"count\": 1, \"min\": 25835110, \"max\": 25835110}, \"Total Batches Seen\": {\"sum\": 25987.0, \"count\": 1, \"min\": 25987, \"max\": 25987}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 367.0, \"count\": 1, \"min\": 367, \"max\": 367}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251307.40297387482 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, batch=0 train rmse <loss>=0.7197664348266909\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, batch=0 train mse <loss>=0.518063720703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, batch=0 train absolute_loss <loss>=0.5560125732421874\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:46.791] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 734, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, train rmse <loss>=0.799447344770207\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, train mse <loss>=0.6391160570601342\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=366, train absolute_loss <loss>=0.5995385183414943\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.524691, \"EndTime\": 1716353146.791701, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.6146755218506, \"count\": 1, \"min\": 266.6146755218506, \"max\": 266.6146755218506}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #progress_metric: host=algo-1, completed 73.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.5250626, \"EndTime\": 1716353146.7918878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 366, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25905695.0, \"count\": 1, \"min\": 25905695, \"max\": 25905695}, \"Total Batches Seen\": {\"sum\": 26058.0, \"count\": 1, \"min\": 26058, \"max\": 26058}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 368.0, \"count\": 1, \"min\": 368, \"max\": 368}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264423.3094473596 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, batch=0 train rmse <loss>=0.7195997863667433\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, batch=0 train mse <loss>=0.5178238525390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:46 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, batch=0 train absolute_loss <loss>=0.5558679809570313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:47.054] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 736, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, train rmse <loss>=0.7992786443419881\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, train mse <loss>=0.6388463513011664\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=367, train absolute_loss <loss>=0.5993966184804137\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.7917597, \"EndTime\": 1716353147.055508, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.3705139160156, \"count\": 1, \"min\": 263.3705139160156, \"max\": 263.3705139160156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 73.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353146.7921143, \"EndTime\": 1716353147.0556984, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 367, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25976280.0, \"count\": 1, \"min\": 25976280, \"max\": 25976280}, \"Total Batches Seen\": {\"sum\": 26129.0, \"count\": 1, \"min\": 26129, \"max\": 26129}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 369.0, \"count\": 1, \"min\": 369, \"max\": 369}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267680.542639654 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, batch=0 train rmse <loss>=0.7194332689802613\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, batch=0 train mse <loss>=0.517584228515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, batch=0 train absolute_loss <loss>=0.5557239379882812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:47.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 738, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, train rmse <loss>=0.7991100922542078\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, train mse <loss>=0.6385769395425286\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=368, train absolute_loss <loss>=0.5992551192162742\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.0555837, \"EndTime\": 1716353147.3238778, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.7040100097656, \"count\": 1, \"min\": 267.7040100097656, \"max\": 267.7040100097656}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 73.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.05615, \"EndTime\": 1716353147.3240619, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 368, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26046865.0, \"count\": 1, \"min\": 26046865, \"max\": 26046865}, \"Total Batches Seen\": {\"sum\": 26200.0, \"count\": 1, \"min\": 26200, \"max\": 26200}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 370.0, \"count\": 1, \"min\": 370, \"max\": 370}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263357.2960360519 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, batch=0 train rmse <loss>=0.7192668827582794\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, batch=0 train mse <loss>=0.5173448486328125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, batch=0 train absolute_loss <loss>=0.555580322265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:47.588] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 740, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, train rmse <loss>=0.7989416692330034\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, train mse <loss>=0.6383077908368178\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=369, train absolute_loss <loss>=0.599113847759408\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.323953, \"EndTime\": 1716353147.588546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.988733291626, \"count\": 1, \"min\": 263.988733291626, \"max\": 263.988733291626}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 74.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.3245363, \"EndTime\": 1716353147.5887465, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 369, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26117450.0, \"count\": 1, \"min\": 26117450, \"max\": 26117450}, \"Total Batches Seen\": {\"sum\": 26271.0, \"count\": 1, \"min\": 26271, \"max\": 26271}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 371.0, \"count\": 1, \"min\": 371, \"max\": 371}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267036.85402379616 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, batch=0 train rmse <loss>=0.7191006277918446\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, batch=0 train mse <loss>=0.517105712890625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, batch=0 train absolute_loss <loss>=0.5554373168945312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:47.865] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 742, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, train rmse <loss>=0.7987733758981229\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, train mse <loss>=0.638038906043684\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=370, train absolute_loss <loss>=0.598973017303037\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.5886087, \"EndTime\": 1716353147.865845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.6110897064209, \"count\": 1, \"min\": 276.6110897064209, \"max\": 276.6110897064209}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #progress_metric: host=algo-1, completed 74.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.5892098, \"EndTime\": 1716353147.866049, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 370, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26188035.0, \"count\": 1, \"min\": 26188035, \"max\": 26188035}, \"Total Batches Seen\": {\"sum\": 26342.0, \"count\": 1, \"min\": 26342, \"max\": 26342}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 372.0, \"count\": 1, \"min\": 372, \"max\": 372}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254877.01697716865 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, batch=0 train rmse <loss>=0.7189345466203573\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, batch=0 train mse <loss>=0.5168668823242187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:47 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, batch=0 train absolute_loss <loss>=0.5552942504882813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:48.136] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 744, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, train rmse <loss>=0.7986052274017055\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, train mse <loss>=0.6377703092333297\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=371, train absolute_loss <loss>=0.5988325117943992\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.8659065, \"EndTime\": 1716353148.1373618, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.9169387817383, \"count\": 1, \"min\": 270.9169387817383, \"max\": 270.9169387817383}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 74.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353147.866421, \"EndTime\": 1716353148.1375735, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 371, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26258620.0, \"count\": 1, \"min\": 26258620, \"max\": 26258620}, \"Total Batches Seen\": {\"sum\": 26413.0, \"count\": 1, \"min\": 26413, \"max\": 26413}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 373.0, \"count\": 1, \"min\": 373, \"max\": 373}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260199.46197925822 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, batch=0 train rmse <loss>=0.7187685969061514\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, batch=0 train mse <loss>=0.5166282958984375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, batch=0 train absolute_loss <loss>=0.5551509399414063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:48.412] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 746, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, train rmse <loss>=0.7984372324485853\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, train mse <loss>=0.6375020141601563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=372, train absolute_loss <loss>=0.5986921756368287\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.1374304, \"EndTime\": 1716353148.4132192, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.21514892578125, \"count\": 1, \"min\": 275.21514892578125, \"max\": 275.21514892578125}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 74.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.137979, \"EndTime\": 1716353148.4134297, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 372, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26329205.0, \"count\": 1, \"min\": 26329205, \"max\": 26329205}, \"Total Batches Seen\": {\"sum\": 26484.0, \"count\": 1, \"min\": 26484, \"max\": 26484}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 374.0, \"count\": 1, \"min\": 374, \"max\": 374}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256131.69979322935 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, batch=0 train rmse <loss>=0.7186027787403004\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, batch=0 train mse <loss>=0.5163899536132812\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, batch=0 train absolute_loss <loss>=0.5550074462890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:48.680] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 748, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, train rmse <loss>=0.7982693232914896\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, train mse <loss>=0.6372339125082527\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=373, train absolute_loss <loss>=0.598551934040768\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.4132898, \"EndTime\": 1716353148.680994, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.2855854034424, \"count\": 1, \"min\": 267.2855854034424, \"max\": 267.2855854034424}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 74.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.4136844, \"EndTime\": 1716353148.681193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 373, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26399790.0, \"count\": 1, \"min\": 26399790, \"max\": 26399790}, \"Total Batches Seen\": {\"sum\": 26555.0, \"count\": 1, \"min\": 26555, \"max\": 26555}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263760.85948699125 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, batch=0 train rmse <loss>=0.718437134691621\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, batch=0 train mse <loss>=0.5161519165039062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, batch=0 train absolute_loss <loss>=0.5548638305664062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:48.959] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 750, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, train rmse <loss>=0.7981016001566061\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, train mse <loss>=0.6369661641725353\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=374, train absolute_loss <loss>=0.5984119718309859\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.681062, \"EndTime\": 1716353148.9601817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.7609100341797, \"count\": 1, \"min\": 278.7609100341797, \"max\": 278.7609100341797}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.681394, \"EndTime\": 1716353148.9604373, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 374, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26470375.0, \"count\": 1, \"min\": 26470375, \"max\": 26470375}, \"Total Batches Seen\": {\"sum\": 26626.0, \"count\": 1, \"min\": 26626, \"max\": 26626}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 376.0, \"count\": 1, \"min\": 376, \"max\": 376}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252850.39999316746 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, batch=0 train rmse <loss>=0.7182716223930583\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, batch=0 train mse <loss>=0.5159141235351562\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:48 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, batch=0 train absolute_loss <loss>=0.554719970703125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:49.223] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 752, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, train rmse <loss>=0.7979339828990496\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, train mse <loss>=0.6366986410651408\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=375, train absolute_loss <loss>=0.5982720457265075\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.9602566, \"EndTime\": 1716353149.2235236, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.82644271850586, \"count\": 1, \"min\": 262.82644271850586, \"max\": 262.82644271850586}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 75.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353148.9606745, \"EndTime\": 1716353149.2236793, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 375, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26540960.0, \"count\": 1, \"min\": 26540960, \"max\": 26540960}, \"Total Batches Seen\": {\"sum\": 26697.0, \"count\": 1, \"min\": 26697, \"max\": 26697}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 377.0, \"count\": 1, \"min\": 377, \"max\": 377}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268288.19301565207 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, batch=0 train rmse <loss>=0.718106284433013\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, batch=0 train mse <loss>=0.5156766357421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, batch=0 train absolute_loss <loss>=0.5545761108398437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:49.497] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 754, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, train rmse <loss>=0.7977665470155301\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, train mse <loss>=0.6364314635370819\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=376, train absolute_loss <loss>=0.5981322322361906\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.2235825, \"EndTime\": 1716353149.498058, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.88906478881836, \"count\": 1, \"min\": 273.88906478881836, \"max\": 273.88906478881836}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 75.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.2241445, \"EndTime\": 1716353149.4982605, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 376, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26611545.0, \"count\": 1, \"min\": 26611545, \"max\": 26611545}, \"Total Batches Seen\": {\"sum\": 26768.0, \"count\": 1, \"min\": 26768, \"max\": 26768}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 378.0, \"count\": 1, \"min\": 378, \"max\": 378}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257399.24415177476 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, batch=0 train rmse <loss>=0.7179410359177747\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, batch=0 train mse <loss>=0.5154393310546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, batch=0 train absolute_loss <loss>=0.5544319458007813\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:49.770] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 756, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, train rmse <loss>=0.797599214479989\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, train mse <loss>=0.6361645069390955\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=377, train absolute_loss <loss>=0.5979925571495378\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.4981227, \"EndTime\": 1716353149.770765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.9898223876953, \"count\": 1, \"min\": 271.9898223876953, \"max\": 271.9898223876953}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #progress_metric: host=algo-1, completed 75.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.4987528, \"EndTime\": 1716353149.770953, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 377, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26682130.0, \"count\": 1, \"min\": 26682130, \"max\": 26682130}, \"Total Batches Seen\": {\"sum\": 26839.0, \"count\": 1, \"min\": 26839, \"max\": 26839}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 379.0, \"count\": 1, \"min\": 379, \"max\": 379}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259208.91849392548 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, batch=0 train rmse <loss>=0.7177759619428397\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, batch=0 train mse <loss>=0.5152023315429688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:49 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, batch=0 train absolute_loss <loss>=0.5542889404296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:50.049] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 758, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, train rmse <loss>=0.7974320106910281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, train mse <loss>=0.6358978116747359\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=378, train absolute_loss <loss>=0.597853076343805\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.7708292, \"EndTime\": 1716353150.0500488, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.6285877227783, \"count\": 1, \"min\": 278.6285877227783, \"max\": 278.6285877227783}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 75.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353149.7713945, \"EndTime\": 1716353150.0503106, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 378, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26752715.0, \"count\": 1, \"min\": 26752715, \"max\": 26752715}, \"Total Batches Seen\": {\"sum\": 26910.0, \"count\": 1, \"min\": 26910, \"max\": 26910}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 380.0, \"count\": 1, \"min\": 380, \"max\": 380}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252967.49957276933 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, batch=0 train rmse <loss>=0.7176110626286577\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, batch=0 train mse <loss>=0.5149656372070313\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, batch=0 train absolute_loss <loss>=0.5541466674804687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:50.328] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 760, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, train rmse <loss>=0.7972649556772556\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, train mse <loss>=0.6356314095510563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=379, train absolute_loss <loss>=0.597713700415383\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.050124, \"EndTime\": 1716353150.328956, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.14674377441406, \"count\": 1, \"min\": 278.14674377441406, \"max\": 278.14674377441406}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.050784, \"EndTime\": 1716353150.329172, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 379, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26823300.0, \"count\": 1, \"min\": 26823300, \"max\": 26823300}, \"Total Batches Seen\": {\"sum\": 26981.0, \"count\": 1, \"min\": 26981, \"max\": 26981}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 381.0, \"count\": 1, \"min\": 381, \"max\": 381}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253447.18177094168 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, batch=0 train rmse <loss>=0.7174462530228746\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, batch=0 train mse <loss>=0.5147291259765625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, batch=0 train absolute_loss <loss>=0.5540043334960938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:50.601] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 762, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, train rmse <loss>=0.7970980581600097\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, train mse <loss>=0.6353653143224582\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=380, train absolute_loss <loss>=0.597574541118783\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.3290248, \"EndTime\": 1716353150.6020484, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.3710536956787, \"count\": 1, \"min\": 272.3710536956787, \"max\": 272.3710536956787}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 76.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.3296535, \"EndTime\": 1716353150.6022003, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 380, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26893885.0, \"count\": 1, \"min\": 26893885, \"max\": 26893885}, \"Total Batches Seen\": {\"sum\": 27052.0, \"count\": 1, \"min\": 27052, \"max\": 27052}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 382.0, \"count\": 1, \"min\": 382, \"max\": 382}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258895.6545433876 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, batch=0 train rmse <loss>=0.717281618279651\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, batch=0 train mse <loss>=0.514492919921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, batch=0 train absolute_loss <loss>=0.5538619384765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:50.873] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 764, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, train rmse <loss>=0.7969312702360748\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, train mse <loss>=0.6350994494800837\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=381, train absolute_loss <loss>=0.5974356139277068\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.6021078, \"EndTime\": 1716353150.87382, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.1501121520996, \"count\": 1, \"min\": 271.1501121520996, \"max\": 271.1501121520996}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #progress_metric: host=algo-1, completed 76.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.6026478, \"EndTime\": 1716353150.8739798, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 381, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26964470.0, \"count\": 1, \"min\": 26964470, \"max\": 26964470}, \"Total Batches Seen\": {\"sum\": 27123.0, \"count\": 1, \"min\": 27123, \"max\": 27123}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 383.0, \"count\": 1, \"min\": 383, \"max\": 383}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260053.41334933185 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, batch=0 train rmse <loss>=0.7171171159635031\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, batch=0 train mse <loss>=0.5142569580078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:50 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, batch=0 train absolute_loss <loss>=0.5537192993164063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:51.143] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 766, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, train rmse <loss>=0.7967646345918533\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, train mse <loss>=0.6348338829362896\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=382, train absolute_loss <loss>=0.5972968517894476\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.8738768, \"EndTime\": 1716353151.1436234, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.1328525543213, \"count\": 1, \"min\": 269.1328525543213, \"max\": 269.1328525543213}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 76.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353150.874467, \"EndTime\": 1716353151.14381, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 382, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27035055.0, \"count\": 1, \"min\": 27035055, \"max\": 27035055}, \"Total Batches Seen\": {\"sum\": 27194.0, \"count\": 1, \"min\": 27194, \"max\": 27194}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 384.0, \"count\": 1, \"min\": 384, \"max\": 384}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261970.72298463774 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, batch=0 train rmse <loss>=0.7169527461655859\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, batch=0 train mse <loss>=0.514021240234375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, batch=0 train absolute_loss <loss>=0.5535804443359374\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:51.429] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 768, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, train rmse <loss>=0.7965981497041817\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, train mse <loss>=0.6345686121121259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=383, train absolute_loss <loss>=0.597158193668849\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.1436822, \"EndTime\": 1716353151.4301355, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.69912910461426, \"count\": 1, \"min\": 285.69912910461426, \"max\": 285.69912910461426}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 76.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.1444094, \"EndTime\": 1716353151.430342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 383, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27105640.0, \"count\": 1, \"min\": 27105640, \"max\": 27105640}, \"Total Batches Seen\": {\"sum\": 27265.0, \"count\": 1, \"min\": 27265, \"max\": 27265}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 385.0, \"count\": 1, \"min\": 385, \"max\": 385}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246763.865672015 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, batch=0 train rmse <loss>=0.7167884664016339\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, batch=0 train mse <loss>=0.5137857055664062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, batch=0 train absolute_loss <loss>=0.5534434204101563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:51.705] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 770, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, train rmse <loss>=0.7964317854450483\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, train mse <loss>=0.6343035888671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=384, train absolute_loss <loss>=0.5970195321096501\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.430209, \"EndTime\": 1716353151.7057357, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.1452922821045, \"count\": 1, \"min\": 275.1452922821045, \"max\": 275.1452922821045}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 77.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.430564, \"EndTime\": 1716353151.7059567, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 384, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27176225.0, \"count\": 1, \"min\": 27176225, \"max\": 27176225}, \"Total Batches Seen\": {\"sum\": 27336.0, \"count\": 1, \"min\": 27336, \"max\": 27336}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 386.0, \"count\": 1, \"min\": 386, \"max\": 386}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256194.64742563514 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, batch=0 train rmse <loss>=0.7166244044891125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, batch=0 train mse <loss>=0.513550537109375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, batch=0 train absolute_loss <loss>=0.5533080444335937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:51.978] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 772, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, train rmse <loss>=0.7962655607831017\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, train mse <loss>=0.6340388432892275\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=385, train absolute_loss <loss>=0.5968808430416483\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.705808, \"EndTime\": 1716353151.9792917, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.06318283081055, \"count\": 1, \"min\": 273.06318283081055, \"max\": 273.06318283081055}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #progress_metric: host=algo-1, completed 77.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.7062056, \"EndTime\": 1716353151.9795182, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 385, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27246810.0, \"count\": 1, \"min\": 27246810, \"max\": 27246810}, \"Total Batches Seen\": {\"sum\": 27407.0, \"count\": 1, \"min\": 27407, \"max\": 27407}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 387.0, \"count\": 1, \"min\": 387, \"max\": 387}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258137.4028698505 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, batch=0 train rmse <loss>=0.716460432792916\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, batch=0 train mse <loss>=0.5133155517578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:51 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, batch=0 train absolute_loss <loss>=0.5531727905273438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:52.252] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 774, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, train rmse <loss>=0.7960994704066479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, train mse <loss>=0.6337743667817451\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=386, train absolute_loss <loss>=0.5967421754648987\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.9793742, \"EndTime\": 1716353152.2533696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.5912799835205, \"count\": 1, \"min\": 273.5912799835205, \"max\": 273.5912799835205}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 77.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353151.9797544, \"EndTime\": 1716353152.253702, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 386, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27317395.0, \"count\": 1, \"min\": 27317395, \"max\": 27317395}, \"Total Batches Seen\": {\"sum\": 27478.0, \"count\": 1, \"min\": 27478, \"max\": 27478}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 388.0, \"count\": 1, \"min\": 388, \"max\": 388}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257565.40411123369 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, batch=0 train rmse <loss>=0.7162965939796692\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, batch=0 train mse <loss>=0.513080810546875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, batch=0 train absolute_loss <loss>=0.5530384521484375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:52.516] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 776, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, train rmse <loss>=0.7959335419410937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, train mse <loss>=0.6335102031868948\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=387, train absolute_loss <loss>=0.59660351648465\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.2534983, \"EndTime\": 1716353152.5177114, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.69595527648926, \"count\": 1, \"min\": 263.69595527648926, \"max\": 263.69595527648926}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 77.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.2539847, \"EndTime\": 1716353152.5179448, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 387, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27387980.0, \"count\": 1, \"min\": 27387980, \"max\": 27387980}, \"Total Batches Seen\": {\"sum\": 27549.0, \"count\": 1, \"min\": 27549, \"max\": 27549}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 389.0, \"count\": 1, \"min\": 389, \"max\": 389}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267293.6197659448 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, batch=0 train rmse <loss>=0.7161329307549813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, batch=0 train mse <loss>=0.5128463745117188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, batch=0 train absolute_loss <loss>=0.5529039306640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:52.792] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 778, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, train rmse <loss>=0.7957677274153675\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, train mse <loss>=0.6332462759958186\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=388, train absolute_loss <loss>=0.5964648325745489\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.5177724, \"EndTime\": 1716353152.7930906, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.8863697052002, \"count\": 1, \"min\": 274.8863697052002, \"max\": 274.8863697052002}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #progress_metric: host=algo-1, completed 77.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.5181806, \"EndTime\": 1716353152.7932935, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 388, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27458565.0, \"count\": 1, \"min\": 27458565, \"max\": 27458565}, \"Total Batches Seen\": {\"sum\": 27620.0, \"count\": 1, \"min\": 27620, \"max\": 27620}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 390.0, \"count\": 1, \"min\": 390, \"max\": 390}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256456.2999358112 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, batch=0 train rmse <loss>=0.7159694006151294\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, batch=0 train mse <loss>=0.5126121826171876\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:52 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, batch=0 train absolute_loss <loss>=0.5527705688476563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:53.096] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 780, \"duration\": 300, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, train rmse <loss>=0.795602058235285\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, train mse <loss>=0.6329826350682218\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=389, train absolute_loss <loss>=0.5963263059804137\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.7931502, \"EndTime\": 1716353153.0967088, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 303.180456161499, \"count\": 1, \"min\": 303.180456161499, \"max\": 303.180456161499}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 78.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353152.7935047, \"EndTime\": 1716353153.0968575, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 389, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27529150.0, \"count\": 1, \"min\": 27529150, \"max\": 27529150}, \"Total Batches Seen\": {\"sum\": 27691.0, \"count\": 1, \"min\": 27691, \"max\": 27691}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 391.0, \"count\": 1, \"min\": 391, \"max\": 391}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=232616.2966501613 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, batch=0 train rmse <loss>=0.7158060036513254\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, batch=0 train mse <loss>=0.5123782348632813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, batch=0 train absolute_loss <loss>=0.552637939453125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:53.366] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 782, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, train rmse <loss>=0.7954365290880244\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, train mse <loss>=0.6327192718076035\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=390, train absolute_loss <loss>=0.5961878541758363\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.0967658, \"EndTime\": 1716353153.367047, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.0028419494629, \"count\": 1, \"min\": 270.0028419494629, \"max\": 270.0028419494629}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 78.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.0970213, \"EndTime\": 1716353153.3672786, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 390, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27599735.0, \"count\": 1, \"min\": 27599735, \"max\": 27599735}, \"Total Batches Seen\": {\"sum\": 27762.0, \"count\": 1, \"min\": 27762, \"max\": 27762}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 392.0, \"count\": 1, \"min\": 392, \"max\": 392}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261080.1312918775 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, batch=0 train rmse <loss>=0.7156426973111958\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, batch=0 train mse <loss>=0.5121444702148438\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, batch=0 train absolute_loss <loss>=0.5525050659179688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:53.634] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 784, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, train rmse <loss>=0.7952711179015053\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, train mse <loss>=0.6324561509683099\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=391, train absolute_loss <loss>=0.5960493722835057\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.3671055, \"EndTime\": 1716353153.635127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.6370143890381, \"count\": 1, \"min\": 267.6370143890381, \"max\": 267.6370143890381}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 78.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.3674686, \"EndTime\": 1716353153.6352732, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 391, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27670320.0, \"count\": 1, \"min\": 27670320, \"max\": 27670320}, \"Total Batches Seen\": {\"sum\": 27833.0, \"count\": 1, \"min\": 27833, \"max\": 27833}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 393.0, \"count\": 1, \"min\": 393, \"max\": 393}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263483.3941398285 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, batch=0 train rmse <loss>=0.7154795669634371\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, batch=0 train mse <loss>=0.5119110107421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, batch=0 train absolute_loss <loss>=0.5523720092773438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:53.907] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 786, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, train rmse <loss>=0.7951058901605508\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, train mse <loss>=0.6321933765680018\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=392, train absolute_loss <loss>=0.5959110098825374\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.6351826, \"EndTime\": 1716353153.907845, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.39084243774414, \"count\": 1, \"min\": 272.39084243774414, \"max\": 272.39084243774414}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #progress_metric: host=algo-1, completed 78.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.6354296, \"EndTime\": 1716353153.908067, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 392, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27740905.0, \"count\": 1, \"min\": 27740905, \"max\": 27740905}, \"Total Batches Seen\": {\"sum\": 27904.0, \"count\": 1, \"min\": 27904, \"max\": 27904}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 394.0, \"count\": 1, \"min\": 394, \"max\": 394}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258787.7065787185 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, batch=0 train rmse <loss>=0.71531652740238\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, batch=0 train mse <loss>=0.511677734375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:53 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, batch=0 train absolute_loss <loss>=0.5522387084960938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:54.174] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 788, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, train rmse <loss>=0.794940772444254\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, train mse <loss>=0.6319308316942671\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=393, train absolute_loss <loss>=0.5957727300079776\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.9079163, \"EndTime\": 1716353154.1747746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.41225814819336, \"count\": 1, \"min\": 266.41225814819336, \"max\": 266.41225814819336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 78.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353153.908338, \"EndTime\": 1716353154.17494, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 393, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27811490.0, \"count\": 1, \"min\": 27811490, \"max\": 27811490}, \"Total Batches Seen\": {\"sum\": 27975.0, \"count\": 1, \"min\": 27975, \"max\": 27975}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 395.0, \"count\": 1, \"min\": 395, \"max\": 395}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264656.85279496387 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, batch=0 train rmse <loss>=0.715153664035635\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, batch=0 train mse <loss>=0.5114447631835938\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, batch=0 train absolute_loss <loss>=0.5521052856445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:54.448] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 790, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, train rmse <loss>=0.7947757929434632\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, train mse <loss>=0.6316685610489107\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=394, train absolute_loss <loss>=0.595634755309199\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.1748466, \"EndTime\": 1716353154.4486823, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.529052734375, \"count\": 1, \"min\": 273.529052734375, \"max\": 273.529052734375}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 79.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.1751294, \"EndTime\": 1716353154.4489202, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 394, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27882075.0, \"count\": 1, \"min\": 27882075, \"max\": 27882075}, \"Total Batches Seen\": {\"sum\": 28046.0, \"count\": 1, \"min\": 28046, \"max\": 28046}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 396.0, \"count\": 1, \"min\": 396, \"max\": 396}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257709.56807710353 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, batch=0 train rmse <loss>=0.7149909129599021\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, batch=0 train mse <loss>=0.5112120056152344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, batch=0 train absolute_loss <loss>=0.5519716186523438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:54.708] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 792, \"duration\": 257, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, train rmse <loss>=0.7946109828474638\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, train mse <loss>=0.6314066140618123\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=395, train absolute_loss <loss>=0.5954971124353543\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.4487703, \"EndTime\": 1716353154.7094445, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.1158618927002, \"count\": 1, \"min\": 260.1158618927002, \"max\": 260.1158618927002}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 79.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.4493048, \"EndTime\": 1716353154.7096624, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 395, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27952660.0, \"count\": 1, \"min\": 27952660, \"max\": 27952660}, \"Total Batches Seen\": {\"sum\": 28117.0, \"count\": 1, \"min\": 28117, \"max\": 28117}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 397.0, \"count\": 1, \"min\": 397, \"max\": 397}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270973.8767791945 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, batch=0 train rmse <loss>=0.7148282742518807\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, batch=0 train mse <loss>=0.5109794616699219\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, batch=0 train absolute_loss <loss>=0.5518377685546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:54.989] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 794, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, train rmse <loss>=0.794446276255142\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, train mse <loss>=0.6311448858556613\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=396, train absolute_loss <loss>=0.595359657824879\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.7095196, \"EndTime\": 1716353154.9898758, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.93130683898926, \"count\": 1, \"min\": 279.93130683898926, \"max\": 279.93130683898926}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #progress_metric: host=algo-1, completed 79.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.7099204, \"EndTime\": 1716353154.9900658, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 396, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28023245.0, \"count\": 1, \"min\": 28023245, \"max\": 28023245}, \"Total Batches Seen\": {\"sum\": 28188.0, \"count\": 1, \"min\": 28188, \"max\": 28188}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 398.0, \"count\": 1, \"min\": 398, \"max\": 398}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251836.0611984151 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, batch=0 train rmse <loss>=0.714665812041118\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, batch=0 train mse <loss>=0.5107472229003907\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:54 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, batch=0 train absolute_loss <loss>=0.5517037353515625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:55.258] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 796, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, train rmse <loss>=0.7942817238283536\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, train mse <loss>=0.6308834568077409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=397, train absolute_loss <loss>=0.5952224387585278\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.989947, \"EndTime\": 1716353155.2592287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.8877582550049, \"count\": 1, \"min\": 268.8877582550049, \"max\": 268.8877582550049}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 79.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353154.9903183, \"EndTime\": 1716353155.2593803, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 397, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28093830.0, \"count\": 1, \"min\": 28093830, \"max\": 28093830}, \"Total Batches Seen\": {\"sum\": 28259.0, \"count\": 1, \"min\": 28259, \"max\": 28259}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 399.0, \"count\": 1, \"min\": 399, \"max\": 399}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262246.1714204727 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, batch=0 train rmse <loss>=0.7145033983132424\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, batch=0 train mse <loss>=0.5105151062011719\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, batch=0 train absolute_loss <loss>=0.5515693969726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:55.536] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 798, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, train rmse <loss>=0.7941172964348192\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, train mse <loss>=0.6306222804969466\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=398, train absolute_loss <loss>=0.5950853159729863\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.2592869, \"EndTime\": 1716353155.5373824, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.8134346008301, \"count\": 1, \"min\": 277.8134346008301, \"max\": 277.8134346008301}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 79.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.259545, \"EndTime\": 1716353155.537599, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 398, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28164415.0, \"count\": 1, \"min\": 28164415, \"max\": 28164415}, \"Total Batches Seen\": {\"sum\": 28330.0, \"count\": 1, \"min\": 28330, \"max\": 28330}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253759.78880132752 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, batch=0 train rmse <loss>=0.7143411826258602\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, batch=0 train mse <loss>=0.5102833251953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, batch=0 train absolute_loss <loss>=0.5514349365234374\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:55.809] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 800, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, train rmse <loss>=0.7939530084986172\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, train mse <loss>=0.6303613797040053\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=399, train absolute_loss <loss>=0.594948231871699\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.5374546, \"EndTime\": 1716353155.809603, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.55184745788574, \"count\": 1, \"min\": 271.55184745788574, \"max\": 271.55184745788574}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.5380275, \"EndTime\": 1716353155.8098512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 399, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28235000.0, \"count\": 1, \"min\": 28235000, \"max\": 28235000}, \"Total Batches Seen\": {\"sum\": 28401.0, \"count\": 1, \"min\": 28401, \"max\": 28401}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 401.0, \"count\": 1, \"min\": 401, \"max\": 401}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259551.3819334918 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, batch=0 train rmse <loss>=0.7141790796519456\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, batch=0 train mse <loss>=0.5100517578125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:55 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, batch=0 train absolute_loss <loss>=0.55130029296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:56.088] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 802, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, train rmse <loss>=0.7937888898880306\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, train mse <loss>=0.6301008017096721\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=400, train absolute_loss <loss>=0.5948113128232284\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.8096688, \"EndTime\": 1716353156.0894644, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.31928634643555, \"count\": 1, \"min\": 279.31928634643555, \"max\": 279.31928634643555}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 80.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353155.8101215, \"EndTime\": 1716353156.0896497, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 400, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28305585.0, \"count\": 1, \"min\": 28305585, \"max\": 28305585}, \"Total Batches Seen\": {\"sum\": 28472.0, \"count\": 1, \"min\": 28472, \"max\": 28472}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 402.0, \"count\": 1, \"min\": 402, \"max\": 402}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252426.98271025566 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, batch=0 train rmse <loss>=0.7140171108386076\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, batch=0 train mse <loss>=0.5098204345703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, batch=0 train absolute_loss <loss>=0.5511654052734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:56.357] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 804, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, train rmse <loss>=0.7936248749040451\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, train mse <loss>=0.6298404420664613\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=401, train absolute_loss <loss>=0.5946745347573723\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.0895355, \"EndTime\": 1716353156.3576918, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.84563064575195, \"count\": 1, \"min\": 267.84563064575195, \"max\": 267.84563064575195}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 80.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.0898197, \"EndTime\": 1716353156.3578942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 401, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28376170.0, \"count\": 1, \"min\": 28376170, \"max\": 28376170}, \"Total Batches Seen\": {\"sum\": 28543.0, \"count\": 1, \"min\": 28543, \"max\": 28543}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 403.0, \"count\": 1, \"min\": 403, \"max\": 403}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263190.8346934929 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, batch=0 train rmse <loss>=0.7138552549019808\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, batch=0 train mse <loss>=0.5095893249511719\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, batch=0 train absolute_loss <loss>=0.5510303344726563\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:56.625] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 806, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, train rmse <loss>=0.7934610045099597\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, train mse <loss>=0.6295803656779544\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=402, train absolute_loss <loss>=0.5945380231830436\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.3577607, \"EndTime\": 1716353156.6259649, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.8201198577881, \"count\": 1, \"min\": 267.8201198577881, \"max\": 267.8201198577881}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 80.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.3581219, \"EndTime\": 1716353156.6262312, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 402, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28446755.0, \"count\": 1, \"min\": 28446755, \"max\": 28446755}, \"Total Batches Seen\": {\"sum\": 28614.0, \"count\": 1, \"min\": 28614, \"max\": 28614}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 404.0, \"count\": 1, \"min\": 404, \"max\": 404}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263146.6208734313 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, batch=0 train rmse <loss>=0.7136935546789213\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, batch=0 train mse <loss>=0.5093584899902344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, batch=0 train absolute_loss <loss>=0.550895751953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:56.887] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 808, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, train rmse <loss>=0.7932972825881243\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, train mse <loss>=0.6293205785617022\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=403, train absolute_loss <loss>=0.5944016078895247\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.6260433, \"EndTime\": 1716353156.887668, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.16371154785156, \"count\": 1, \"min\": 261.16371154785156, \"max\": 261.16371154785156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #progress_metric: host=algo-1, completed 80.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.6264827, \"EndTime\": 1716353156.8878186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 403, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28517340.0, \"count\": 1, \"min\": 28517340, \"max\": 28517340}, \"Total Batches Seen\": {\"sum\": 28685.0, \"count\": 1, \"min\": 28685, \"max\": 28685}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 405.0, \"count\": 1, \"min\": 405, \"max\": 405}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270004.87728002336 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, batch=0 train rmse <loss>=0.7135319247358085\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, batch=0 train mse <loss>=0.5091278076171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:56 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, batch=0 train absolute_loss <loss>=0.550760986328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:57.165] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 810, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, train rmse <loss>=0.793133704895022\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, train mse <loss>=0.6290610738405039\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=404, train absolute_loss <loss>=0.5942652708241637\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.8877246, \"EndTime\": 1716353157.1661563, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.1507968902588, \"count\": 1, \"min\": 278.1507968902588, \"max\": 278.1507968902588}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 81.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353156.8879824, \"EndTime\": 1716353157.166387, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 404, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28587925.0, \"count\": 1, \"min\": 28587925, \"max\": 28587925}, \"Total Batches Seen\": {\"sum\": 28756.0, \"count\": 1, \"min\": 28756, \"max\": 28756}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 406.0, \"count\": 1, \"min\": 406, \"max\": 406}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253425.26954821634 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, batch=0 train rmse <loss>=0.7133704506792693\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, batch=0 train mse <loss>=0.5088973999023437\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, batch=0 train absolute_loss <loss>=0.5506270141601562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:57.446] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 812, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, train rmse <loss>=0.7929702455017813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, train mse <loss>=0.6288018102511553\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=405, train absolute_loss <loss>=0.5941289053903499\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.1662288, \"EndTime\": 1716353157.446837, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.179500579834, \"count\": 1, \"min\": 280.179500579834, \"max\": 280.179500579834}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 81.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.1666331, \"EndTime\": 1716353157.446992, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 405, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28658510.0, \"count\": 1, \"min\": 28658510, \"max\": 28658510}, \"Total Batches Seen\": {\"sum\": 28827.0, \"count\": 1, \"min\": 28827, \"max\": 28827}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 407.0, \"count\": 1, \"min\": 407, \"max\": 407}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251669.72085997264 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, batch=0 train rmse <loss>=0.7132090684315285\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, batch=0 train mse <loss>=0.5086671752929688\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, batch=0 train absolute_loss <loss>=0.5504946899414063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:57.708] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 814, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, train rmse <loss>=0.7928069101742128\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, train mse <loss>=0.6285427968199824\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=406, train absolute_loss <loss>=0.5939925898162411\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.4468963, \"EndTime\": 1716353157.7087789, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.28149032592773, \"count\": 1, \"min\": 261.28149032592773, \"max\": 261.28149032592773}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 81.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.447473, \"EndTime\": 1716353157.7090025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 406, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28729095.0, \"count\": 1, \"min\": 28729095, \"max\": 28729095}, \"Total Batches Seen\": {\"sum\": 28898.0, \"count\": 1, \"min\": 28898, \"max\": 28898}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 408.0, \"count\": 1, \"min\": 408, \"max\": 408}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269778.27415867127 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, batch=0 train rmse <loss>=0.7130478850518759\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, batch=0 train mse <loss>=0.5084372863769532\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, batch=0 train absolute_loss <loss>=0.5503621826171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:57.991] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 816, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, train rmse <loss>=0.7926437665013338\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, train mse <loss>=0.628284140573421\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #quality_metric: host=algo-1, epoch=407, train absolute_loss <loss>=0.5938563911545445\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.7088506, \"EndTime\": 1716353157.9921203, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.8695774078369, \"count\": 1, \"min\": 282.8695774078369, \"max\": 282.8695774078369}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #progress_metric: host=algo-1, completed 81.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.7092261, \"EndTime\": 1716353157.9923527, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 407, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28799680.0, \"count\": 1, \"min\": 28799680, \"max\": 28799680}, \"Total Batches Seen\": {\"sum\": 28969.0, \"count\": 1, \"min\": 28969, \"max\": 28969}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 409.0, \"count\": 1, \"min\": 409, \"max\": 409}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:57 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249202.82341533052 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, batch=0 train rmse <loss>=0.7128867508456375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, batch=0 train mse <loss>=0.50820751953125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, batch=0 train absolute_loss <loss>=0.5502293701171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:58.257] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 818, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, train rmse <loss>=0.7924806857864584\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, train mse <loss>=0.6280256373445753\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=408, train absolute_loss <loss>=0.5937201357559418\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.9921908, \"EndTime\": 1716353158.2576978, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.76216316223145, \"count\": 1, \"min\": 264.76216316223145, \"max\": 264.76216316223145}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 81.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353157.9929142, \"EndTime\": 1716353158.2578483, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 408, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28870265.0, \"count\": 1, \"min\": 28870265, \"max\": 28870265}, \"Total Batches Seen\": {\"sum\": 29040.0, \"count\": 1, \"min\": 29040, \"max\": 29040}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 410.0, \"count\": 1, \"min\": 410, \"max\": 410}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266332.2668585822 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, batch=0 train rmse <loss>=0.7127257728914747\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, batch=0 train mse <loss>=0.50797802734375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, batch=0 train absolute_loss <loss>=0.550096435546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:58.533] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 820, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, train rmse <loss>=0.7923178034199043\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, train mse <loss>=0.6277675016161421\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=409, train absolute_loss <loss>=0.5935841451295665\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.2577546, \"EndTime\": 1716353158.5340743, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.64406394958496, \"count\": 1, \"min\": 275.64406394958496, \"max\": 275.64406394958496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 82.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.258407, \"EndTime\": 1716353158.5342286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 409, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28940850.0, \"count\": 1, \"min\": 28940850, \"max\": 28940850}, \"Total Batches Seen\": {\"sum\": 29111.0, \"count\": 1, \"min\": 29111, \"max\": 29111}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 411.0, \"count\": 1, \"min\": 411, \"max\": 411}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255824.2777459497 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, batch=0 train rmse <loss>=0.7125648870536063\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, batch=0 train mse <loss>=0.5077487182617187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, batch=0 train absolute_loss <loss>=0.5499631958007812\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:58.809] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 822, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, train rmse <loss>=0.7921550291807672\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, train mse <loss>=0.6275095902563821\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=410, train absolute_loss <loss>=0.5934481261347381\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.5341306, \"EndTime\": 1716353158.8102865, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.4833698272705, \"count\": 1, \"min\": 275.4833698272705, \"max\": 275.4833698272705}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #progress_metric: host=algo-1, completed 82.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.534779, \"EndTime\": 1716353158.8105009, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 410, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29011435.0, \"count\": 1, \"min\": 29011435, \"max\": 29011435}, \"Total Batches Seen\": {\"sum\": 29182.0, \"count\": 1, \"min\": 29182, \"max\": 29182}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 412.0, \"count\": 1, \"min\": 412, \"max\": 412}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255897.02733959703 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, batch=0 train rmse <loss>=0.712404136231895\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, batch=0 train mse <loss>=0.5075196533203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:58 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, batch=0 train absolute_loss <loss>=0.5498297729492188\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:45:59.101] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 824, \"duration\": 288, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, train rmse <loss>=0.7919923821306919\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, train mse <loss>=0.627251933353048\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=411, train absolute_loss <loss>=0.5933122507014744\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.8103604, \"EndTime\": 1716353159.1015286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 290.4942035675049, \"count\": 1, \"min\": 290.4942035675049, \"max\": 290.4942035675049}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 82.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353158.811009, \"EndTime\": 1716353159.101767, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 411, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29082020.0, \"count\": 1, \"min\": 29082020, \"max\": 29082020}, \"Total Batches Seen\": {\"sum\": 29253.0, \"count\": 1, \"min\": 29253, \"max\": 29253}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 413.0, \"count\": 1, \"min\": 413, \"max\": 413}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=242625.62998427323 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, batch=0 train rmse <loss>=0.7122434562470875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, batch=0 train mse <loss>=0.5072907409667968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, batch=0 train absolute_loss <loss>=0.5496973876953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:59.382] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 826, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, train rmse <loss>=0.791829890846367\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, train mse <loss>=0.6269945760377695\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=412, train absolute_loss <loss>=0.5931764242682659\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.101602, \"EndTime\": 1716353159.3826923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.2765369415283, \"count\": 1, \"min\": 280.2765369415283, \"max\": 280.2765369415283}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 82.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.102391, \"EndTime\": 1716353159.382905, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 412, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29152605.0, \"count\": 1, \"min\": 29152605, \"max\": 29152605}, \"Total Batches Seen\": {\"sum\": 29324.0, \"count\": 1, \"min\": 29324, \"max\": 29324}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 414.0, \"count\": 1, \"min\": 414, \"max\": 414}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=251532.44704992758 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, batch=0 train rmse <loss>=0.7120829114323038\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, batch=0 train mse <loss>=0.5070620727539062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, batch=0 train absolute_loss <loss>=0.549567626953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:59.656] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 828, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, train rmse <loss>=0.7916675073738432\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, train mse <loss>=0.6267374422315141\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=413, train absolute_loss <loss>=0.5930406528526628\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.3827615, \"EndTime\": 1716353159.656945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.47874641418457, \"count\": 1, \"min\": 273.47874641418457, \"max\": 273.47874641418457}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 82.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.3834407, \"EndTime\": 1716353159.6571462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 413, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29223190.0, \"count\": 1, \"min\": 29223190, \"max\": 29223190}, \"Total Batches Seen\": {\"sum\": 29395.0, \"count\": 1, \"min\": 29395, \"max\": 29395}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 415.0, \"count\": 1, \"min\": 415, \"max\": 415}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257774.86485874644 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, batch=0 train rmse <loss>=0.7119225233122062\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, batch=0 train mse <loss>=0.5068336791992187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, batch=0 train absolute_loss <loss>=0.549437744140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:45:59.921] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 830, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, train rmse <loss>=0.7915052934153798\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, train mse <loss>=0.6264806295045665\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=414, train absolute_loss <loss>=0.5929050232793244\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.65701, \"EndTime\": 1716353159.921637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.9036178588867, \"count\": 1, \"min\": 263.9036178588867, \"max\": 263.9036178588867}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #progress_metric: host=algo-1, completed 83.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.65771, \"EndTime\": 1716353159.9218237, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 414, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29293775.0, \"count\": 1, \"min\": 29293775, \"max\": 29293775}, \"Total Batches Seen\": {\"sum\": 29466.0, \"count\": 1, \"min\": 29466, \"max\": 29466}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 416.0, \"count\": 1, \"min\": 416, \"max\": 416}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267141.1884493708 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, batch=0 train rmse <loss>=0.7117622062405546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, batch=0 train mse <loss>=0.5066054382324219\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:45:59 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, batch=0 train absolute_loss <loss>=0.5493076171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:00.200] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 832, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, train rmse <loss>=0.7913431599971736\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, train mse <loss>=0.6262239968743123\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=415, train absolute_loss <loss>=0.5927693661971831\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.9216957, \"EndTime\": 1716353160.2011764, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.8355350494385, \"count\": 1, \"min\": 278.8355350494385, \"max\": 278.8355350494385}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 83.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353159.922318, \"EndTime\": 1716353160.2013245, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 415, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29364360.0, \"count\": 1, \"min\": 29364360, \"max\": 29364360}, \"Total Batches Seen\": {\"sum\": 29537.0, \"count\": 1, \"min\": 29537, \"max\": 29537}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 417.0, \"count\": 1, \"min\": 417, \"max\": 417}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252908.50412736705 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, batch=0 train rmse <loss>=0.7116020460368478\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, batch=0 train mse <loss>=0.5063774719238281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, batch=0 train absolute_loss <loss>=0.5491773071289062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:00.476] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 834, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, train rmse <loss>=0.7911812016977318\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, train mse <loss>=0.6259676939198668\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=416, train absolute_loss <loss>=0.592633916290713\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.201234, \"EndTime\": 1716353160.4769416, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.0682830810547, \"count\": 1, \"min\": 275.0682830810547, \"max\": 275.0682830810547}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 83.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.201851, \"EndTime\": 1716353160.4771352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 416, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29434945.0, \"count\": 1, \"min\": 29434945, \"max\": 29434945}, \"Total Batches Seen\": {\"sum\": 29608.0, \"count\": 1, \"min\": 29608, \"max\": 29608}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 418.0, \"count\": 1, \"min\": 418, \"max\": 418}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256316.64107439076 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, batch=0 train rmse <loss>=0.7114419355685655\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, batch=0 train mse <loss>=0.5061496276855468\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, batch=0 train absolute_loss <loss>=0.5490466918945313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:00.740] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 836, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, train rmse <loss>=0.791019358037618\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, train mse <loss>=0.6257116247902453\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=417, train absolute_loss <loss>=0.5924986056475572\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.4770074, \"EndTime\": 1716353160.7409256, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.28110694885254, \"count\": 1, \"min\": 263.28110694885254, \"max\": 263.28110694885254}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #progress_metric: host=algo-1, completed 83.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.4776208, \"EndTime\": 1716353160.7411358, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 417, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29505530.0, \"count\": 1, \"min\": 29505530, \"max\": 29505530}, \"Total Batches Seen\": {\"sum\": 29679.0, \"count\": 1, \"min\": 29679, \"max\": 29679}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 419.0, \"count\": 1, \"min\": 419, \"max\": 419}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267752.9278594052 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, batch=0 train rmse <loss>=0.7112819606793712\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, batch=0 train mse <loss>=0.5059220275878906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:00 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, batch=0 train absolute_loss <loss>=0.5489178466796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:01.013] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 838, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, train rmse <loss>=0.7908576660446897\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, train mse <loss>=0.6254558479416539\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=418, train absolute_loss <loss>=0.5923635580573283\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.7409897, \"EndTime\": 1716353161.014129, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.42183685302734, \"count\": 1, \"min\": 272.42183685302734, \"max\": 272.42183685302734}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 83.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353160.7416854, \"EndTime\": 1716353161.0142765, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 418, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29576115.0, \"count\": 1, \"min\": 29576115, \"max\": 29576115}, \"Total Batches Seen\": {\"sum\": 29750.0, \"count\": 1, \"min\": 29750, \"max\": 29750}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 420.0, \"count\": 1, \"min\": 420, \"max\": 420}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258808.51972393054 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, batch=0 train rmse <loss>=0.7111220785460841\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, batch=0 train mse <loss>=0.5056946105957031\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, batch=0 train absolute_loss <loss>=0.5487901611328125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:01.398] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 840, \"duration\": 382, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, train rmse <loss>=0.790696066015623\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, train mse <loss>=0.6252002688125825\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=419, train absolute_loss <loss>=0.5922285929935079\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.014185, \"EndTime\": 1716353161.399896, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 385.007381439209, \"count\": 1, \"min\": 385.007381439209, \"max\": 385.007381439209}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.0148637, \"EndTime\": 1716353161.4003558, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 419, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29646700.0, \"count\": 1, \"min\": 29646700, \"max\": 29646700}, \"Total Batches Seen\": {\"sum\": 29821.0, \"count\": 1, \"min\": 29821, \"max\": 29821}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 421.0, \"count\": 1, \"min\": 421, \"max\": 421}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=183043.17585267758 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, batch=0 train rmse <loss>=0.7109623750799312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, batch=0 train mse <loss>=0.5054674987792969\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, batch=0 train absolute_loss <loss>=0.5486622924804687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:01.739] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 842, \"duration\": 336, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, train rmse <loss>=0.7905346221651155\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, train mse <loss>=0.6249449888417419\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=420, train absolute_loss <loss>=0.5920936528595401\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.3999674, \"EndTime\": 1716353161.7409203, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 339.7233486175537, \"count\": 1, \"min\": 339.7233486175537, \"max\": 339.7233486175537}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #progress_metric: host=algo-1, completed 84.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.4011505, \"EndTime\": 1716353161.7413282, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 420, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29717285.0, \"count\": 1, \"min\": 29717285, \"max\": 29717285}, \"Total Batches Seen\": {\"sum\": 29892.0, \"count\": 1, \"min\": 29892, \"max\": 29892}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 422.0, \"count\": 1, \"min\": 422, \"max\": 422}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=207407.66666246325 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, batch=0 train rmse <loss>=0.7108026786654977\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, batch=0 train mse <loss>=0.5052404479980469\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:01 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, batch=0 train absolute_loss <loss>=0.5485341186523438\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:02.086] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 844, \"duration\": 341, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, train rmse <loss>=0.790373319905587\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, train mse <loss>=0.6246899848185794\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=421, train absolute_loss <loss>=0.591958779778279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.7409909, \"EndTime\": 1716353162.0866957, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 344.91491317749023, \"count\": 1, \"min\": 344.91491317749023, \"max\": 344.91491317749023}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #progress_metric: host=algo-1, completed 84.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353161.7417552, \"EndTime\": 1716353162.0869248, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 421, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29787870.0, \"count\": 1, \"min\": 29787870, \"max\": 29787870}, \"Total Batches Seen\": {\"sum\": 29963.0, \"count\": 1, \"min\": 29963, \"max\": 29963}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 423.0, \"count\": 1, \"min\": 423, \"max\": 423}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=204423.67217633518 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, batch=0 train rmse <loss>=0.7106431610819723\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, batch=0 train mse <loss>=0.5050137023925781\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, batch=0 train absolute_loss <loss>=0.5484057006835937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:02.445] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 846, \"duration\": 356, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, train rmse <loss>=0.790212119616397\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, train mse <loss>=0.6244351939886389\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=422, train absolute_loss <loss>=0.5918239780479754\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.0867698, \"EndTime\": 1716353162.4463193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 359.12036895751953, \"count\": 1, \"min\": 359.12036895751953, \"max\": 359.12036895751953}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #progress_metric: host=algo-1, completed 84.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.0871718, \"EndTime\": 1716353162.4465437, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 422, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29858455.0, \"count\": 1, \"min\": 29858455, \"max\": 29858455}, \"Total Batches Seen\": {\"sum\": 30034.0, \"count\": 1, \"min\": 30034, \"max\": 30034}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 424.0, \"count\": 1, \"min\": 424, \"max\": 424}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=196343.87215080656 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, batch=0 train rmse <loss>=0.7104836935900936\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, batch=0 train mse <loss>=0.5047870788574219\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, batch=0 train absolute_loss <loss>=0.5482770385742187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:02.823] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 848, \"duration\": 371, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, train rmse <loss>=0.7900510436658974\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, train mse <loss>=0.6241806515975737\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=423, train absolute_loss <loss>=0.5916893026862345\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.4463897, \"EndTime\": 1716353162.8238606, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 377.0406246185303, \"count\": 1, \"min\": 377.0406246185303, \"max\": 377.0406246185303}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #progress_metric: host=algo-1, completed 84.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.4467945, \"EndTime\": 1716353162.8241062, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 423, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29929040.0, \"count\": 1, \"min\": 29929040, \"max\": 29929040}, \"Total Batches Seen\": {\"sum\": 30105.0, \"count\": 1, \"min\": 30105, \"max\": 30105}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 425.0, \"count\": 1, \"min\": 425, \"max\": 425}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=187006.5603369536 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, batch=0 train rmse <loss>=0.710324340667918\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, batch=0 train mse <loss>=0.5045606689453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:02 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, batch=0 train absolute_loss <loss>=0.5481482543945313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:03.239] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 850, \"duration\": 413, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, train rmse <loss>=0.7898900902256014\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, train mse <loss>=0.6239263546366087\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=424, train absolute_loss <loss>=0.5915547313421545\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.8239346, \"EndTime\": 1716353163.2409182, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 416.5005683898926, \"count\": 1, \"min\": 416.5005683898926, \"max\": 416.5005683898926}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353162.8243928, \"EndTime\": 1716353163.2411263, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 424, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29999625.0, \"count\": 1, \"min\": 29999625, \"max\": 29999625}, \"Total Batches Seen\": {\"sum\": 30176.0, \"count\": 1, \"min\": 30176, \"max\": 30176}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 426.0, \"count\": 1, \"min\": 426, \"max\": 426}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=169340.20931369884 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, batch=0 train rmse <loss>=0.7101651238788259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, batch=0 train mse <loss>=0.5043345031738281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, batch=0 train absolute_loss <loss>=0.5480196533203125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:03.625] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 852, \"duration\": 381, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, train rmse <loss>=0.7897292623638935\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, train mse <loss>=0.6236723078338193\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=425, train absolute_loss <loss>=0.5914201445243727\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.2409854, \"EndTime\": 1716353163.6256337, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 384.31859016418457, \"count\": 1, \"min\": 384.31859016418457, \"max\": 384.31859016418457}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 85.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.2412913, \"EndTime\": 1716353163.6258492, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 425, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30070210.0, \"count\": 1, \"min\": 30070210, \"max\": 30070210}, \"Total Batches Seen\": {\"sum\": 30247.0, \"count\": 1, \"min\": 30247, \"max\": 30247}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 427.0, \"count\": 1, \"min\": 427, \"max\": 427}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=183490.04431453778 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, batch=0 train rmse <loss>=0.7100060003322596\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, batch=0 train mse <loss>=0.5041085205078125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, batch=0 train absolute_loss <loss>=0.5478908081054688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:03.897] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 854, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, train rmse <loss>=0.7895685884652518\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, train mse <loss>=0.6234185558910101\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=426, train absolute_loss <loss>=0.5912856496891505\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.6257057, \"EndTime\": 1716353163.8980792, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.92044258117676, \"count\": 1, \"min\": 271.92044258117676, \"max\": 271.92044258117676}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #progress_metric: host=algo-1, completed 85.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.6261332, \"EndTime\": 1716353163.8982737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 426, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30140795.0, \"count\": 1, \"min\": 30140795, \"max\": 30140795}, \"Total Batches Seen\": {\"sum\": 30318.0, \"count\": 1, \"min\": 30318, \"max\": 30318}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 428.0, \"count\": 1, \"min\": 428, \"max\": 428}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259275.65856930922 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, batch=0 train rmse <loss>=0.7098469056032655\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, batch=0 train mse <loss>=0.5038826293945312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:03 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, batch=0 train absolute_loss <loss>=0.5477615356445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:04.176] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 856, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, train rmse <loss>=0.7894080253367071\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, train mse <loss>=0.6231650304659991\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=427, train absolute_loss <loss>=0.5911512244855854\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.8981383, \"EndTime\": 1716353164.1772683, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.75661849975586, \"count\": 1, \"min\": 278.75661849975586, \"max\": 278.75661849975586}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 85.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353163.8984857, \"EndTime\": 1716353164.1774876, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 427, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30211380.0, \"count\": 1, \"min\": 30211380, \"max\": 30211380}, \"Total Batches Seen\": {\"sum\": 30389.0, \"count\": 1, \"min\": 30389, \"max\": 30389}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 429.0, \"count\": 1, \"min\": 429, \"max\": 429}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252901.80675054158 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, batch=0 train rmse <loss>=0.709687968715444\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, batch=0 train mse <loss>=0.5036570129394531\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, batch=0 train absolute_loss <loss>=0.5476322021484376\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:04.442] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 858, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, train rmse <loss>=0.7892475686890557\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, train mse <loss>=0.6229117246815856\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=428, train absolute_loss <loss>=0.5910167605977663\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.177337, \"EndTime\": 1716353164.443242, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.5160427093506, \"count\": 1, \"min\": 265.5160427093506, \"max\": 265.5160427093506}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 85.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.1777027, \"EndTime\": 1716353164.4434092, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 428, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30281965.0, \"count\": 1, \"min\": 30281965, \"max\": 30281965}, \"Total Batches Seen\": {\"sum\": 30460.0, \"count\": 1, \"min\": 30460, \"max\": 30460}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 430.0, \"count\": 1, \"min\": 430, \"max\": 430}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265549.4263851528 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, batch=0 train rmse <loss>=0.7095291037528099\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, batch=0 train mse <loss>=0.5034315490722656\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, batch=0 train absolute_loss <loss>=0.5475025634765625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:04.713] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 860, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, train rmse <loss>=0.7890872360180289\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, train mse <loss>=0.6226586660465724\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=429, train absolute_loss <loss>=0.5908824187802597\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.4433022, \"EndTime\": 1716353164.7139752, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.3685760498047, \"count\": 1, \"min\": 270.3685760498047, \"max\": 270.3685760498047}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 86.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.4435825, \"EndTime\": 1716353164.71419, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 429, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30352550.0, \"count\": 1, \"min\": 30352550, \"max\": 30352550}, \"Total Batches Seen\": {\"sum\": 30531.0, \"count\": 1, \"min\": 30531, \"max\": 30531}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 431.0, \"count\": 1, \"min\": 431, \"max\": 431}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260738.21707535963 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, batch=0 train rmse <loss>=0.7093703322740152\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, batch=0 train mse <loss>=0.5032062683105468\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, batch=0 train absolute_loss <loss>=0.54737255859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:04.978] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 862, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, train rmse <loss>=0.7889270200441124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, train mse <loss>=0.6224058429556834\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=430, train absolute_loss <loss>=0.590748213647117\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.714049, \"EndTime\": 1716353164.9786372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.21499252319336, \"count\": 1, \"min\": 264.21499252319336, \"max\": 264.21499252319336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #progress_metric: host=algo-1, completed 86.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.7144015, \"EndTime\": 1716353164.9787838, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 430, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30423135.0, \"count\": 1, \"min\": 30423135, \"max\": 30423135}, \"Total Batches Seen\": {\"sum\": 30602.0, \"count\": 1, \"min\": 30602, \"max\": 30602}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 432.0, \"count\": 1, \"min\": 432, \"max\": 432}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266887.60243291414 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, batch=0 train rmse <loss>=0.7092116758569863\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, batch=0 train mse <loss>=0.502981201171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:04 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, batch=0 train absolute_loss <loss>=0.547242431640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:05.252] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 864, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, train rmse <loss>=0.788766940728468\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, train mse <loss>=0.6221532867861466\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=431, train absolute_loss <loss>=0.5906141529351893\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.9786937, \"EndTime\": 1716353165.2528777, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.70429039001465, \"count\": 1, \"min\": 273.70429039001465, \"max\": 273.70429039001465}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 86.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353164.979151, \"EndTime\": 1716353165.2530284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 431, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30493720.0, \"count\": 1, \"min\": 30493720, \"max\": 30493720}, \"Total Batches Seen\": {\"sum\": 30673.0, \"count\": 1, \"min\": 30673, \"max\": 30673}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 433.0, \"count\": 1, \"min\": 433, \"max\": 433}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257641.3895780774 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, batch=0 train rmse <loss>=0.7090530484991496\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, batch=0 train mse <loss>=0.5027562255859375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, batch=0 train absolute_loss <loss>=0.547113037109375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:05.520] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 866, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, train rmse <loss>=0.7886069485553651\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, train mse <loss>=0.6219009193098042\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=432, train absolute_loss <loss>=0.5904801670128191\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.2529361, \"EndTime\": 1716353165.52132, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.1012153625488, \"count\": 1, \"min\": 268.1012153625488, \"max\": 268.1012153625488}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 86.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.2531927, \"EndTime\": 1716353165.5215418, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 432, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30564305.0, \"count\": 1, \"min\": 30564305, \"max\": 30564305}, \"Total Batches Seen\": {\"sum\": 30744.0, \"count\": 1, \"min\": 30744, \"max\": 30744}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 434.0, \"count\": 1, \"min\": 434, \"max\": 434}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262933.24674724904 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, batch=0 train rmse <loss>=0.7088946008933777\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, batch=0 train mse <loss>=0.5025315551757813\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, batch=0 train absolute_loss <loss>=0.5469841918945313\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:05.802] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 868, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, train rmse <loss>=0.7884470852821308\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, train mse <loss>=0.6216488062898877\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=433, train absolute_loss <loss>=0.5903462765116088\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.5213962, \"EndTime\": 1716353165.8034508, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.482458114624, \"count\": 1, \"min\": 281.482458114624, \"max\": 281.482458114624}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #progress_metric: host=algo-1, completed 86.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.5219347, \"EndTime\": 1716353165.803659, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 433, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30634890.0, \"count\": 1, \"min\": 30634890, \"max\": 30634890}, \"Total Batches Seen\": {\"sum\": 30815.0, \"count\": 1, \"min\": 30815, \"max\": 30815}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 435.0, \"count\": 1, \"min\": 435, \"max\": 435}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250453.81916868148 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, batch=0 train rmse <loss>=0.7087361393940648\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, batch=0 train mse <loss>=0.5023069152832031\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:05 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, batch=0 train absolute_loss <loss>=0.54685498046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:06.078] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 870, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, train rmse <loss>=0.7882873496240265\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, train mse <loss>=0.6213969455772722\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=434, train absolute_loss <loss>=0.5902124367297535\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.8035083, \"EndTime\": 1716353166.0790787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.9767303466797, \"count\": 1, \"min\": 274.9767303466797, \"max\": 274.9767303466797}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 87.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353165.8040805, \"EndTime\": 1716353166.079248, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 434, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30705475.0, \"count\": 1, \"min\": 30705475, \"max\": 30705475}, \"Total Batches Seen\": {\"sum\": 30886.0, \"count\": 1, \"min\": 30886, \"max\": 30886}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 436.0, \"count\": 1, \"min\": 436, \"max\": 436}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256429.86631743243 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, batch=0 train rmse <loss>=0.7085777931982288\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, batch=0 train mse <loss>=0.5020824890136719\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, batch=0 train absolute_loss <loss>=0.5467255249023437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:06.358] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 872, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, train rmse <loss>=0.7881277029370312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, train mse <loss>=0.6211452761368013\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=435, train absolute_loss <loss>=0.5900788032639195\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.079136, \"EndTime\": 1716353166.3592198, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.5445919036865, \"count\": 1, \"min\": 279.5445919036865, \"max\": 279.5445919036865}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 87.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.0796487, \"EndTime\": 1716353166.359434, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 435, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30776060.0, \"count\": 1, \"min\": 30776060, \"max\": 30776060}, \"Total Batches Seen\": {\"sum\": 30957.0, \"count\": 1, \"min\": 30957, \"max\": 30957}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 437.0, \"count\": 1, \"min\": 437, \"max\": 437}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252175.20184326303 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, batch=0 train rmse <loss>=0.7084195623831879\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, batch=0 train mse <loss>=0.5018582763671875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, batch=0 train absolute_loss <loss>=0.5465958862304687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:06.633] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 874, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, train rmse <loss>=0.7879681785498259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, train mse <loss>=0.6208938504071303\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=436, train absolute_loss <loss>=0.589945351184254\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.3592818, \"EndTime\": 1716353166.634505, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.78814125061035, \"count\": 1, \"min\": 274.78814125061035, \"max\": 274.78814125061035}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 87.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.3596914, \"EndTime\": 1716353166.6347406, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 436, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30846645.0, \"count\": 1, \"min\": 30846645, \"max\": 30846645}, \"Total Batches Seen\": {\"sum\": 31028.0, \"count\": 1, \"min\": 31028, \"max\": 31028}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 438.0, \"count\": 1, \"min\": 438, \"max\": 438}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256502.73855958856 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, batch=0 train rmse <loss>=0.708261403938259\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, batch=0 train mse <loss>=0.5016342163085937\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, batch=0 train absolute_loss <loss>=0.5464664306640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:06.901] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 876, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, train rmse <loss>=0.7878087672615784\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, train mse <loss>=0.6206426537742078\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=437, train absolute_loss <loss>=0.589811904262489\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.6345758, \"EndTime\": 1716353166.9021132, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.08078384399414, \"count\": 1, \"min\": 267.08078384399414, \"max\": 267.08078384399414}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #progress_metric: host=algo-1, completed 87.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.635008, \"EndTime\": 1716353166.902269, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 437, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30917230.0, \"count\": 1, \"min\": 30917230, \"max\": 30917230}, \"Total Batches Seen\": {\"sum\": 31099.0, \"count\": 1, \"min\": 31099, \"max\": 31099}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 439.0, \"count\": 1, \"min\": 439, \"max\": 439}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264010.6546338201 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, batch=0 train rmse <loss>=0.7081032963631171\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, batch=0 train mse <loss>=0.5014102783203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:06 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, batch=0 train absolute_loss <loss>=0.5463369140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:07.184] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 878, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, train rmse <loss>=0.7876494530426312\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, train mse <loss>=0.6203916608783561\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=438, train absolute_loss <loss>=0.5896784263933209\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.9021742, \"EndTime\": 1716353167.1856637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.94920921325684, \"count\": 1, \"min\": 282.94920921325684, \"max\": 282.94920921325684}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 87.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353166.90269, \"EndTime\": 1716353167.185882, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 438, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30987815.0, \"count\": 1, \"min\": 30987815, \"max\": 30987815}, \"Total Batches Seen\": {\"sum\": 31170.0, \"count\": 1, \"min\": 31170, \"max\": 31170}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 440.0, \"count\": 1, \"min\": 440, \"max\": 440}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249131.3139826768 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, batch=0 train rmse <loss>=0.7079453043527291\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, batch=0 train mse <loss>=0.5011865539550782\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, batch=0 train absolute_loss <loss>=0.546207275390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:07.465] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 880, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, train rmse <loss>=0.7874902553283776\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, train mse <loss>=0.6201409022371533\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=439, train absolute_loss <loss>=0.5895448788924956\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.185734, \"EndTime\": 1716353167.4659815, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.6018123626709, \"count\": 1, \"min\": 279.6018123626709, \"max\": 279.6018123626709}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.186356, \"EndTime\": 1716353167.4661376, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 439, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31058400.0, \"count\": 1, \"min\": 31058400, \"max\": 31058400}, \"Total Batches Seen\": {\"sum\": 31241.0, \"count\": 1, \"min\": 31241, \"max\": 31241}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 441.0, \"count\": 1, \"min\": 441, \"max\": 441}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252206.56641044622 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, batch=0 train rmse <loss>=0.7077873633091766\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, batch=0 train mse <loss>=0.5009629516601563\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, batch=0 train absolute_loss <loss>=0.5460773315429688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:07.769] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 882, \"duration\": 301, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, train rmse <loss>=0.7873311673654064\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, train mse <loss>=0.6198903671049736\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=440, train absolute_loss <loss>=0.5894113829706756\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.4660408, \"EndTime\": 1716353167.7696972, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 303.1594753265381, \"count\": 1, \"min\": 303.1594753265381, \"max\": 303.1594753265381}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #progress_metric: host=algo-1, completed 88.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.4665132, \"EndTime\": 1716353167.7699127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 440, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31128985.0, \"count\": 1, \"min\": 31128985, \"max\": 31128985}, \"Total Batches Seen\": {\"sum\": 31312.0, \"count\": 1, \"min\": 31312, \"max\": 31312}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 442.0, \"count\": 1, \"min\": 442, \"max\": 442}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=232550.70026400604 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, batch=0 train rmse <loss>=0.7076295163930791\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, batch=0 train mse <loss>=0.5007395324707031\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:07 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, batch=0 train absolute_loss <loss>=0.5459484252929687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:08.049] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 884, \"duration\": 277, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, train rmse <loss>=0.7871721690168952\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, train mse <loss>=0.6196400236747635\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=441, train absolute_loss <loss>=0.5892779171366087\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.7697623, \"EndTime\": 1716353168.0499594, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.5982360839844, \"count\": 1, \"min\": 279.5982360839844, \"max\": 279.5982360839844}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 88.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353167.7703393, \"EndTime\": 1716353168.0501094, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 441, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31199570.0, \"count\": 1, \"min\": 31199570, \"max\": 31199570}, \"Total Batches Seen\": {\"sum\": 31383.0, \"count\": 1, \"min\": 31383, \"max\": 31383}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 443.0, \"count\": 1, \"min\": 443, \"max\": 443}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252212.58242455687 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, batch=0 train rmse <loss>=0.7074717205313316\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, batch=0 train mse <loss>=0.5005162353515625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, batch=0 train absolute_loss <loss>=0.5458199462890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:08.332] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 886, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, train rmse <loss>=0.7870132931059857\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, train mse <loss>=0.6193899235255281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=442, train absolute_loss <loss>=0.5891445140569982\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.050017, \"EndTime\": 1716353168.3333828, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.0832004547119, \"count\": 1, \"min\": 283.0832004547119, \"max\": 283.0832004547119}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 88.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.0502758, \"EndTime\": 1716353168.3335967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 442, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31270155.0, \"count\": 1, \"min\": 31270155, \"max\": 31270155}, \"Total Batches Seen\": {\"sum\": 31454.0, \"count\": 1, \"min\": 31454, \"max\": 31454}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 444.0, \"count\": 1, \"min\": 444, \"max\": 444}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249035.96205934705 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, batch=0 train rmse <loss>=0.7073139757581031\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, batch=0 train mse <loss>=0.5002930603027343\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, batch=0 train absolute_loss <loss>=0.5456912231445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:08.621] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 888, \"duration\": 286, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, train rmse <loss>=0.7868544981912864\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, train mse <loss>=0.6191400013238612\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=443, train absolute_loss <loss>=0.5890111015212368\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.3334472, \"EndTime\": 1716353168.621971, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.06185722351074, \"count\": 1, \"min\": 288.06185722351074, \"max\": 288.06185722351074}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 88.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.3338466, \"EndTime\": 1716353168.6221702, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 443, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31340740.0, \"count\": 1, \"min\": 31340740, \"max\": 31340740}, \"Total Batches Seen\": {\"sum\": 31525.0, \"count\": 1, \"min\": 31525, \"max\": 31525}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 445.0, \"count\": 1, \"min\": 445, \"max\": 445}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=244722.8596841016 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, batch=0 train rmse <loss>=0.707156303685258\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, batch=0 train mse <loss>=0.5000700378417968\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, batch=0 train absolute_loss <loss>=0.5455621337890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:08.886] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 890, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, train rmse <loss>=0.7866957933369091\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, train mse <loss>=0.6188902712539888\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=444, train absolute_loss <loss>=0.5888777680732834\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.6220388, \"EndTime\": 1716353168.8872259, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.833927154541, \"count\": 1, \"min\": 264.833927154541, \"max\": 264.833927154541}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #progress_metric: host=algo-1, completed 89.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.6223645, \"EndTime\": 1716353168.8874393, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 444, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31411325.0, \"count\": 1, \"min\": 31411325, \"max\": 31411325}, \"Total Batches Seen\": {\"sum\": 31596.0, \"count\": 1, \"min\": 31596, \"max\": 31596}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 446.0, \"count\": 1, \"min\": 446, \"max\": 446}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266181.8870231643 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, batch=0 train rmse <loss>=0.7069987259439214\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, batch=0 train mse <loss>=0.49984719848632814\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:08 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, batch=0 train absolute_loss <loss>=0.545434326171875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:46:09.164] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 892, \"duration\": 274, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, train rmse <loss>=0.7865371996367619\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, train mse <loss>=0.6186407664124395\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=445, train absolute_loss <loss>=0.5887444690113336\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.8872945, \"EndTime\": 1716353169.1648202, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 276.9632339477539, \"count\": 1, \"min\": 276.9632339477539, \"max\": 276.9632339477539}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 89.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353168.887834, \"EndTime\": 1716353169.1649678, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 445, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31481910.0, \"count\": 1, \"min\": 31481910, \"max\": 31481910}, \"Total Batches Seen\": {\"sum\": 31667.0, \"count\": 1, \"min\": 31667, \"max\": 31667}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 447.0, \"count\": 1, \"min\": 447, \"max\": 447}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=254614.6338744897 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, batch=0 train rmse <loss>=0.7068411778352996\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, batch=0 train mse <loss>=0.49962445068359373\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, batch=0 train absolute_loss <loss>=0.545306396484375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:09.435] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 894, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, train rmse <loss>=0.7863787163382145\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, train mse <loss>=0.6183914855097381\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=446, train absolute_loss <loss>=0.5886113152302487\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.1648788, \"EndTime\": 1716353169.4358752, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.4744338989258, \"count\": 1, \"min\": 270.4744338989258, \"max\": 270.4744338989258}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 89.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.1653776, \"EndTime\": 1716353169.436043, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 446, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31552495.0, \"count\": 1, \"min\": 31552495, \"max\": 31552495}, \"Total Batches Seen\": {\"sum\": 31738.0, \"count\": 1, \"min\": 31738, \"max\": 31738}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 448.0, \"count\": 1, \"min\": 448, \"max\": 448}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260692.29827173712 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, batch=0 train rmse <loss>=0.7066837241555293\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, batch=0 train mse <loss>=0.4994018859863281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, batch=0 train absolute_loss <loss>=0.5451782836914062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:09.711] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 896, \"duration\": 273, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, train rmse <loss>=0.7862202956719586\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, train mse <loss>=0.618142353326502\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=447, train absolute_loss <loss>=0.5884782405369718\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.43595, \"EndTime\": 1716353169.712091, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.653600692749, \"count\": 1, \"min\": 275.653600692749, \"max\": 275.653600692749}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 89.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.4364119, \"EndTime\": 1716353169.7123137, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 447, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31623080.0, \"count\": 1, \"min\": 31623080, \"max\": 31623080}, \"Total Batches Seen\": {\"sum\": 31809.0, \"count\": 1, \"min\": 31809, \"max\": 31809}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 449.0, \"count\": 1, \"min\": 449, \"max\": 449}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=255731.90781193718 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, batch=0 train rmse <loss>=0.7065263217739131\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, batch=0 train mse <loss>=0.499179443359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, batch=0 train absolute_loss <loss>=0.5450498046875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:09.990] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 898, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, train rmse <loss>=0.7860619590013783\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, train mse <loss>=0.6178934033890845\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #quality_metric: host=algo-1, epoch=448, train absolute_loss <loss>=0.5883454701598262\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.7121534, \"EndTime\": 1716353169.9915626, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.80120277404785, \"count\": 1, \"min\": 278.80120277404785, \"max\": 278.80120277404785}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #progress_metric: host=algo-1, completed 89.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.712737, \"EndTime\": 1716353169.9917836, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 448, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31693665.0, \"count\": 1, \"min\": 31693665, \"max\": 31693665}, \"Total Batches Seen\": {\"sum\": 31880.0, \"count\": 1, \"min\": 31880, \"max\": 31880}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 450.0, \"count\": 1, \"min\": 450, \"max\": 450}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:09 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252841.33038178788 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, batch=0 train rmse <loss>=0.7063689923264699\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, batch=0 train mse <loss>=0.4989571533203125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, batch=0 train absolute_loss <loss>=0.544921142578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:10.265] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 900, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, train rmse <loss>=0.785903770366669\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, train mse <loss>=0.617644736276546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=449, train absolute_loss <loss>=0.5882127298704335\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.9916291, \"EndTime\": 1716353170.2655556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.30613136291504, \"count\": 1, \"min\": 273.30613136291504, \"max\": 273.30613136291504}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353169.9922261, \"EndTime\": 1716353170.2657535, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 449, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31764250.0, \"count\": 1, \"min\": 31764250, \"max\": 31764250}, \"Total Batches Seen\": {\"sum\": 31951.0, \"count\": 1, \"min\": 31951, \"max\": 31951}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 451.0, \"count\": 1, \"min\": 451, \"max\": 451}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257954.7703103857 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, batch=0 train rmse <loss>=0.7062116710423344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, batch=0 train mse <loss>=0.49873492431640626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, batch=0 train absolute_loss <loss>=0.5447920532226562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:10.526] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 902, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, train rmse <loss>=0.785745631392164\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, train mse <loss>=0.6173961972518706\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=450, train absolute_loss <loss>=0.588079901896732\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.2656162, \"EndTime\": 1716353170.526651, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.4870796203613, \"count\": 1, \"min\": 260.4870796203613, \"max\": 260.4870796203613}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 90.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.2661424, \"EndTime\": 1716353170.5268466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 450, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31834835.0, \"count\": 1, \"min\": 31834835, \"max\": 31834835}, \"Total Batches Seen\": {\"sum\": 32022.0, \"count\": 1, \"min\": 32022, \"max\": 32022}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 452.0, \"count\": 1, \"min\": 452, \"max\": 452}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270630.312501714 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, batch=0 train rmse <loss>=0.7060544011496653\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, batch=0 train mse <loss>=0.4985128173828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, batch=0 train absolute_loss <loss>=0.5446627807617187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:10.798] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 904, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, train rmse <loss>=0.7855875453906833\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, train mse <loss>=0.6171477914729588\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=451, train absolute_loss <loss>=0.5879470481335277\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.5267143, \"EndTime\": 1716353170.7990105, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.7299461364746, \"count\": 1, \"min\": 271.7299461364746, \"max\": 271.7299461364746}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #progress_metric: host=algo-1, completed 90.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.5272596, \"EndTime\": 1716353170.7991967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 451, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31905420.0, \"count\": 1, \"min\": 31905420, \"max\": 31905420}, \"Total Batches Seen\": {\"sum\": 32093.0, \"count\": 1, \"min\": 32093, \"max\": 32093}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259467.898419643 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, batch=0 train rmse <loss>=0.7058972475313001\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, batch=0 train mse <loss>=0.4982909240722656\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:10 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, batch=0 train absolute_loss <loss>=0.5445333251953125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:11.070] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 906, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, train rmse <loss>=0.785429593660596\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, train mse <loss>=0.6168996465978488\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=452, train absolute_loss <loss>=0.5878144462477993\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.7990727, \"EndTime\": 1716353171.0711286, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.52419090270996, \"count\": 1, \"min\": 271.52419090270996, \"max\": 271.52419090270996}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 90.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353170.7995825, \"EndTime\": 1716353171.071278, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 452, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31976005.0, \"count\": 1, \"min\": 31976005, \"max\": 31976005}, \"Total Batches Seen\": {\"sum\": 32164.0, \"count\": 1, \"min\": 32164, \"max\": 32164}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 454.0, \"count\": 1, \"min\": 454, \"max\": 454}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259707.11863693103 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, batch=0 train rmse <loss>=0.705740102160048\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, batch=0 train mse <loss>=0.498069091796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, batch=0 train absolute_loss <loss>=0.544404052734375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:11.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 908, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, train rmse <loss>=0.7852716804952125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, train mse <loss>=0.6166516121877751\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=453, train absolute_loss <loss>=0.587681875309474\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.0711858, \"EndTime\": 1716353171.3394794, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.74072647094727, \"count\": 1, \"min\": 267.74072647094727, \"max\": 267.74072647094727}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 90.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.071716, \"EndTime\": 1716353171.339631, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 453, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32046590.0, \"count\": 1, \"min\": 32046590, \"max\": 32046590}, \"Total Batches Seen\": {\"sum\": 32235.0, \"count\": 1, \"min\": 32235, \"max\": 32235}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 455.0, \"count\": 1, \"min\": 455, \"max\": 455}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263372.7588246859 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, batch=0 train rmse <loss>=0.705582986667209\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, batch=0 train mse <loss>=0.49784735107421874\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, batch=0 train absolute_loss <loss>=0.5442753295898437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:11.622] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 910, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, train rmse <loss>=0.7851138814684465\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, train mse <loss>=0.6164038068744498\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=454, train absolute_loss <loss>=0.5875492665465449\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.3395376, \"EndTime\": 1716353171.6235335, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.7095260620117, \"count\": 1, \"min\": 283.7095260620117, \"max\": 283.7095260620117}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 91.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.3397985, \"EndTime\": 1716353171.6237438, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 454, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32117175.0, \"count\": 1, \"min\": 32117175, \"max\": 32117175}, \"Total Batches Seen\": {\"sum\": 32306.0, \"count\": 1, \"min\": 32306, \"max\": 32306}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 456.0, \"count\": 1, \"min\": 456, \"max\": 456}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248494.57680666514 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, batch=0 train rmse <loss>=0.7054259227033516\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, batch=0 train mse <loss>=0.497625732421875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, batch=0 train absolute_loss <loss>=0.5441463012695312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:11.888] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 912, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, train rmse <loss>=0.7849561402485581\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, train mse <loss>=0.616156142113914\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=455, train absolute_loss <loss>=0.5874167626609265\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.6235976, \"EndTime\": 1716353171.888831, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 264.82629776000977, \"count\": 1, \"min\": 264.82629776000977, \"max\": 264.82629776000977}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #progress_metric: host=algo-1, completed 91.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.6239808, \"EndTime\": 1716353171.8889904, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 455, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32187760.0, \"count\": 1, \"min\": 32187760, \"max\": 32187760}, \"Total Batches Seen\": {\"sum\": 32377.0, \"count\": 1, \"min\": 32377, \"max\": 32377}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 457.0, \"count\": 1, \"min\": 457, \"max\": 457}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=266252.50607725466 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, batch=0 train rmse <loss>=0.7052688886674824\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, batch=0 train mse <loss>=0.49740420532226565\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:11 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, batch=0 train absolute_loss <loss>=0.5440169677734376\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:12.161] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 914, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, train rmse <loss>=0.7847984697410824\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, train mse <loss>=0.6159086381079445\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=456, train absolute_loss <loss>=0.5872845201089348\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.8888915, \"EndTime\": 1716353172.1615522, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.3710536956787, \"count\": 1, \"min\": 272.3710536956787, \"max\": 272.3710536956787}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 91.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353171.8891585, \"EndTime\": 1716353172.1616988, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 456, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32258345.0, \"count\": 1, \"min\": 32258345, \"max\": 32258345}, \"Total Batches Seen\": {\"sum\": 32448.0, \"count\": 1, \"min\": 32448, \"max\": 32448}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 458.0, \"count\": 1, \"min\": 458, \"max\": 458}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258904.93729279426 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, batch=0 train rmse <loss>=0.7051119278600716\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, batch=0 train mse <loss>=0.49718283081054687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, batch=0 train absolute_loss <loss>=0.5438875122070312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:12.444] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 916, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, train rmse <loss>=0.7846408803968178\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, train mse <loss>=0.6156613111898933\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=457, train absolute_loss <loss>=0.5871523067850463\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.16161, \"EndTime\": 1716353172.4447434, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.85694122314453, \"count\": 1, \"min\": 282.85694122314453, \"max\": 282.85694122314453}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 91.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.1618643, \"EndTime\": 1716353172.4449503, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 457, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32328930.0, \"count\": 1, \"min\": 32328930, \"max\": 32328930}, \"Total Batches Seen\": {\"sum\": 32519.0, \"count\": 1, \"min\": 32519, \"max\": 32519}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 459.0, \"count\": 1, \"min\": 459, \"max\": 459}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=249243.10485799148 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, batch=0 train rmse <loss>=0.7049549753948718\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, batch=0 train mse <loss>=0.49696151733398436\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, batch=0 train absolute_loss <loss>=0.5437576904296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:12.716] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 918, \"duration\": 270, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, train rmse <loss>=0.7844833574711497\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, train mse <loss>=0.6154141381492078\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=458, train absolute_loss <loss>=0.5870200410225022\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.4448087, \"EndTime\": 1716353172.7173102, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.1133232116699, \"count\": 1, \"min\": 272.1133232116699, \"max\": 272.1133232116699}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 91.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.445174, \"EndTime\": 1716353172.7174556, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 458, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32399515.0, \"count\": 1, \"min\": 32399515, \"max\": 32399515}, \"Total Batches Seen\": {\"sum\": 32590.0, \"count\": 1, \"min\": 32590, \"max\": 32590}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 460.0, \"count\": 1, \"min\": 460, \"max\": 460}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259144.93477937378 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, batch=0 train rmse <loss>=0.7047980962270773\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, batch=0 train mse <loss>=0.4967403564453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, batch=0 train absolute_loss <loss>=0.5436276245117188\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:12.996] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 920, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, train rmse <loss>=0.7843258867556174\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, train mse <loss>=0.6151670966349857\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #quality_metric: host=algo-1, epoch=459, train absolute_loss <loss>=0.586887850909166\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.7173662, \"EndTime\": 1716353172.9974911, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.5238494873047, \"count\": 1, \"min\": 279.5238494873047, \"max\": 279.5238494873047}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.7179422, \"EndTime\": 1716353172.9977112, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 459, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32470100.0, \"count\": 1, \"min\": 32470100, \"max\": 32470100}, \"Total Batches Seen\": {\"sum\": 32661.0, \"count\": 1, \"min\": 32661, \"max\": 32661}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 461.0, \"count\": 1, \"min\": 461, \"max\": 461}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:12 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252188.52008998735 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, batch=0 train rmse <loss>=0.7046412037868767\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, batch=0 train mse <loss>=0.4965192260742187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, batch=0 train absolute_loss <loss>=0.5434972534179687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:13.276] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 922, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, train rmse <loss>=0.7841685135022697\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, train mse <loss>=0.6149202575683593\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=460, train absolute_loss <loss>=0.5867557192520356\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.997564, \"EndTime\": 1716353173.2770662, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.822660446167, \"count\": 1, \"min\": 278.822660446167, \"max\": 278.822660446167}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 92.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353172.998219, \"EndTime\": 1716353173.2772753, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 460, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32540685.0, \"count\": 1, \"min\": 32540685, \"max\": 32540685}, \"Total Batches Seen\": {\"sum\": 32732.0, \"count\": 1, \"min\": 32732, \"max\": 32732}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 462.0, \"count\": 1, \"min\": 462, \"max\": 462}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252833.77286931005 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, batch=0 train rmse <loss>=0.7044843413844337\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, batch=0 train mse <loss>=0.4962981872558594\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, batch=0 train absolute_loss <loss>=0.5433670654296875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:13.548] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 924, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, train rmse <loss>=0.7840111993931098\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, train mse <loss>=0.6146735607738226\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=461, train absolute_loss <loss>=0.5866236374546104\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.2771294, \"EndTime\": 1716353173.549396, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.6407775878906, \"count\": 1, \"min\": 271.6407775878906, \"max\": 271.6407775878906}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 92.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.2777336, \"EndTime\": 1716353173.5495958, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 461, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32611270.0, \"count\": 1, \"min\": 32611270, \"max\": 32611270}, \"Total Batches Seen\": {\"sum\": 32803.0, \"count\": 1, \"min\": 32803, \"max\": 32803}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 463.0, \"count\": 1, \"min\": 463, \"max\": 463}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259534.08938413297 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, batch=0 train rmse <loss>=0.7043275090398177\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, batch=0 train mse <loss>=0.4960772399902344\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, batch=0 train absolute_loss <loss>=0.54323681640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:13.816] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 926, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, train rmse <loss>=0.7838539069018821\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, train mse <loss>=0.6144269473653444\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=462, train absolute_loss <loss>=0.586491533306283\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.5494714, \"EndTime\": 1716353173.8169973, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.8333053588867, \"count\": 1, \"min\": 266.8333053588867, \"max\": 266.8333053588867}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #progress_metric: host=algo-1, completed 92.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.5501413, \"EndTime\": 1716353173.8171797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 462, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32681855.0, \"count\": 1, \"min\": 32681855, \"max\": 32681855}, \"Total Batches Seen\": {\"sum\": 32874.0, \"count\": 1, \"min\": 32874, \"max\": 32874}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 464.0, \"count\": 1, \"min\": 464, \"max\": 464}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264224.366818151 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, batch=0 train rmse <loss>=0.7041707284422734\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, batch=0 train mse <loss>=0.4958564147949219\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:13 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, batch=0 train absolute_loss <loss>=0.5431063842773437\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:14.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 928, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, train rmse <loss>=0.783696718858825\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, train mse <loss>=0.6141805471500881\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=463, train absolute_loss <loss>=0.5863595366142166\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.8170552, \"EndTime\": 1716353174.0854933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.8036689758301, \"count\": 1, \"min\": 267.8036689758301, \"max\": 267.8036689758301}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 92.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353173.8176663, \"EndTime\": 1716353174.0856757, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 463, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32752440.0, \"count\": 1, \"min\": 32752440, \"max\": 32752440}, \"Total Batches Seen\": {\"sum\": 32945.0, \"count\": 1, \"min\": 32945, \"max\": 32945}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 465.0, \"count\": 1, \"min\": 465, \"max\": 465}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263262.21638094087 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, batch=0 train rmse <loss>=0.7040139346044135\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, batch=0 train mse <loss>=0.4956356201171875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, batch=0 train absolute_loss <loss>=0.5429755859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:14.355] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 930, \"duration\": 268, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, train rmse <loss>=0.7835395450873006\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, train mse <loss>=0.613934218715614\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=464, train absolute_loss <loss>=0.5862274393430897\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.085565, \"EndTime\": 1716353174.3564854, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 270.25604248046875, \"count\": 1, \"min\": 270.25604248046875, \"max\": 270.25604248046875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 93.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.086205, \"EndTime\": 1716353174.356701, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 464, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32823025.0, \"count\": 1, \"min\": 32823025, \"max\": 32823025}, \"Total Batches Seen\": {\"sum\": 33016.0, \"count\": 1, \"min\": 33016, \"max\": 33016}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 466.0, \"count\": 1, \"min\": 466, \"max\": 466}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=260841.82336885176 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, batch=0 train rmse <loss>=0.7038571708750203\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, batch=0 train mse <loss>=0.4954149169921875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, batch=0 train absolute_loss <loss>=0.542844482421875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:14.623] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 932, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, train rmse <loss>=0.7833824486939202\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, train mse <loss>=0.6136880609216825\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=465, train absolute_loss <loss>=0.5860953773176166\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.356557, \"EndTime\": 1716353174.624437, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.25077629089355, \"count\": 1, \"min\": 267.25077629089355, \"max\": 267.25077629089355}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 93.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.3571641, \"EndTime\": 1716353174.6246405, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 465, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32893610.0, \"count\": 1, \"min\": 32893610, \"max\": 32893610}, \"Total Batches Seen\": {\"sum\": 33087.0, \"count\": 1, \"min\": 33087, \"max\": 33087}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 467.0, \"count\": 1, \"min\": 467, \"max\": 467}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263791.1766110551 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, batch=0 train rmse <loss>=0.7037004372742154\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, batch=0 train mse <loss>=0.4951943054199219\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, batch=0 train absolute_loss <loss>=0.5427132568359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:14.888] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 934, \"duration\": 261, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, train rmse <loss>=0.7832253869197464\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, train mse <loss>=0.6134420067155865\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=466, train absolute_loss <loss>=0.5859632852043904\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.624502, \"EndTime\": 1716353174.889186, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 263.9744281768799, \"count\": 1, \"min\": 263.9744281768799, \"max\": 263.9744281768799}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #progress_metric: host=algo-1, completed 93.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.6251884, \"EndTime\": 1716353174.8893902, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 466, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32964195.0, \"count\": 1, \"min\": 32964195, \"max\": 32964195}, \"Total Batches Seen\": {\"sum\": 33158.0, \"count\": 1, \"min\": 33158, \"max\": 33158}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 468.0, \"count\": 1, \"min\": 468, \"max\": 468}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=267045.2844947647 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, batch=0 train rmse <loss>=0.7035437121336616\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, batch=0 train mse <loss>=0.4949737548828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:14 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, batch=0 train absolute_loss <loss>=0.5425816650390625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:15.180] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 936, \"duration\": 288, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, train rmse <loss>=0.7830683976596056\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, train mse <loss>=0.6131961154131822\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=467, train absolute_loss <loss>=0.5858312420912192\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.8892584, \"EndTime\": 1716353175.1819096, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 291.8825149536133, \"count\": 1, \"min\": 291.8825149536133, \"max\": 291.8825149536133}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 93.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353174.889969, \"EndTime\": 1716353175.182142, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 467, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33034780.0, \"count\": 1, \"min\": 33034780, \"max\": 33034780}, \"Total Batches Seen\": {\"sum\": 33229.0, \"count\": 1, \"min\": 33229, \"max\": 33229}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 469.0, \"count\": 1, \"min\": 469, \"max\": 469}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=241435.08790357437 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, batch=0 train rmse <loss>=0.7033869303790944\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, batch=0 train mse <loss>=0.494753173828125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, batch=0 train absolute_loss <loss>=0.54244970703125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:15.484] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 938, \"duration\": 299, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, train rmse <loss>=0.7829114309973457\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, train mse <loss>=0.6129503087863116\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=468, train absolute_loss <loss>=0.5856991559955436\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.1819808, \"EndTime\": 1716353175.485253, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.41918563842773, \"count\": 1, \"min\": 302.41918563842773, \"max\": 302.41918563842773}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 93.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.1828084, \"EndTime\": 1716353175.4854853, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 468, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33105365.0, \"count\": 1, \"min\": 33105365, \"max\": 33105365}, \"Total Batches Seen\": {\"sum\": 33300.0, \"count\": 1, \"min\": 33300, \"max\": 33300}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 470.0, \"count\": 1, \"min\": 470, \"max\": 470}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=233115.96771628124 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, batch=0 train rmse <loss>=0.7032302438596525\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, batch=0 train mse <loss>=0.49453277587890626\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, batch=0 train absolute_loss <loss>=0.5423175659179688\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:15.769] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 940, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, train rmse <loss>=0.7827544987526112\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, train mse <loss>=0.6127046053174516\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=469, train absolute_loss <loss>=0.5855670767770687\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.4853268, \"EndTime\": 1716353175.7696946, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.6024761199951, \"count\": 1, \"min\": 283.6024761199951, \"max\": 283.6024761199951}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #progress_metric: host=algo-1, completed 94.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.4860673, \"EndTime\": 1716353175.769923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 469, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33175950.0, \"count\": 1, \"min\": 33175950, \"max\": 33175950}, \"Total Batches Seen\": {\"sum\": 33371.0, \"count\": 1, \"min\": 33371, \"max\": 33371}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 471.0, \"count\": 1, \"min\": 471, \"max\": 471}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248537.341966724 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, batch=0 train rmse <loss>=0.7030735007181749\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, batch=0 train mse <loss>=0.4943123474121094\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:15 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, batch=0 train absolute_loss <loss>=0.54218505859375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:16.042] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 942, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, train rmse <loss>=0.782597631428298\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, train mse <loss>=0.612459052717182\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=470, train absolute_loss <loss>=0.5854351488570092\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.769763, \"EndTime\": 1716353176.0428002, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.27163314819336, \"count\": 1, \"min\": 272.27163314819336, \"max\": 272.27163314819336}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 94.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353175.7705033, \"EndTime\": 1716353176.0430343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 470, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33246535.0, \"count\": 1, \"min\": 33246535, \"max\": 33246535}, \"Total Batches Seen\": {\"sum\": 33442.0, \"count\": 1, \"min\": 33442, \"max\": 33442}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 472.0, \"count\": 1, \"min\": 472, \"max\": 472}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258894.0697502573 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, batch=0 train rmse <loss>=0.7029168094558736\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, batch=0 train mse <loss>=0.494092041015625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, batch=0 train absolute_loss <loss>=0.5420523681640625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:16.326] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 944, \"duration\": 280, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, train rmse <loss>=0.7824407820949905\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, train mse <loss>=0.6122135774854204\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=471, train absolute_loss <loss>=0.5853032991651078\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.0428693, \"EndTime\": 1716353176.3269193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.3213806152344, \"count\": 1, \"min\": 283.3213806152344, \"max\": 283.3213806152344}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 94.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.0435743, \"EndTime\": 1716353176.3271275, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 471, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33317120.0, \"count\": 1, \"min\": 33317120, \"max\": 33317120}, \"Total Batches Seen\": {\"sum\": 33513.0, \"count\": 1, \"min\": 33513, \"max\": 33513}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 473.0, \"count\": 1, \"min\": 473, \"max\": 473}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248834.18266418326 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, batch=0 train rmse <loss>=0.702760104969483\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, batch=0 train mse <loss>=0.49387176513671877\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, batch=0 train absolute_loss <loss>=0.5419204711914063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:16.594] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 946, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, train rmse <loss>=0.7822839741150878\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, train mse <loss>=0.6119682161572954\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=472, train absolute_loss <loss>=0.5851714872978103\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.3270054, \"EndTime\": 1716353176.5947778, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.05026626586914, \"count\": 1, \"min\": 267.05026626586914, \"max\": 267.05026626586914}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 94.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.3277025, \"EndTime\": 1716353176.5950258, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 472, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33387705.0, \"count\": 1, \"min\": 33387705, \"max\": 33387705}, \"Total Batches Seen\": {\"sum\": 33584.0, \"count\": 1, \"min\": 33584, \"max\": 33584}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 474.0, \"count\": 1, \"min\": 474, \"max\": 474}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263913.2206145719 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, batch=0 train rmse <loss>=0.7026033872501546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, batch=0 train mse <loss>=0.4936515197753906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, batch=0 train absolute_loss <loss>=0.5417882690429687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:16.872] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 948, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, train rmse <loss>=0.7821271860806615\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, train mse <loss>=0.6117229352064536\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=473, train absolute_loss <loss>=0.5850396307287082\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.5948517, \"EndTime\": 1716353176.8732333, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.6460647583008, \"count\": 1, \"min\": 277.6460647583008, \"max\": 277.6460647583008}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #progress_metric: host=algo-1, completed 94.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.5955608, \"EndTime\": 1716353176.873462, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 473, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33458290.0, \"count\": 1, \"min\": 33458290, \"max\": 33458290}, \"Total Batches Seen\": {\"sum\": 33655.0, \"count\": 1, \"min\": 33655, \"max\": 33655}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 475.0, \"count\": 1, \"min\": 475, \"max\": 475}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253884.26384655887 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, batch=0 train rmse <loss>=0.7024466562890314\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, batch=0 train mse <loss>=0.4934313049316406\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:16 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, batch=0 train absolute_loss <loss>=0.54165576171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:17.139] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 950, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, train rmse <loss>=0.7819704410898143\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, train mse <loss>=0.6114777707381988\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=474, train absolute_loss <loss>=0.5849079538264744\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.8732994, \"EndTime\": 1716353177.1400669, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.99931716918945, \"count\": 1, \"min\": 265.99931716918945, \"max\": 265.99931716918945}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353176.8740437, \"EndTime\": 1716353177.1402168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 474, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33528875.0, \"count\": 1, \"min\": 33528875, \"max\": 33528875}, \"Total Batches Seen\": {\"sum\": 33726.0, \"count\": 1, \"min\": 33726, \"max\": 33726}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 476.0, \"count\": 1, \"min\": 476, \"max\": 476}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265095.26690407394 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, batch=0 train rmse <loss>=0.7022898903500538\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, batch=0 train mse <loss>=0.4932110900878906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, batch=0 train absolute_loss <loss>=0.5415228881835937\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:17.421] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 952, \"duration\": 279, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, train rmse <loss>=0.7818137317464146\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, train mse <loss>=0.6112327111472546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=475, train absolute_loss <loss>=0.584776484959562\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.1401258, \"EndTime\": 1716353177.4220848, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.25929832458496, \"count\": 1, \"min\": 281.25929832458496, \"max\": 281.25929832458496}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 95.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.1408026, \"EndTime\": 1716353177.4223073, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 475, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33599460.0, \"count\": 1, \"min\": 33599460, \"max\": 33599460}, \"Total Batches Seen\": {\"sum\": 33797.0, \"count\": 1, \"min\": 33797, \"max\": 33797}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 477.0, \"count\": 1, \"min\": 477, \"max\": 477}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=250635.31696943325 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, batch=0 train rmse <loss>=0.7021331328738851\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, batch=0 train mse <loss>=0.49299093627929685\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, batch=0 train absolute_loss <loss>=0.5413898315429687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:17.699] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 954, \"duration\": 275, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, train rmse <loss>=0.7816570096816209\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, train mse <loss>=0.6109876807844136\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=476, train absolute_loss <loss>=0.5846450160926496\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.4221525, \"EndTime\": 1716353177.7004406, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.56214141845703, \"count\": 1, \"min\": 277.56214141845703, \"max\": 277.56214141845703}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 95.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.4228537, \"EndTime\": 1716353177.7006555, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 476, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33670045.0, \"count\": 1, \"min\": 33670045, \"max\": 33670045}, \"Total Batches Seen\": {\"sum\": 33868.0, \"count\": 1, \"min\": 33868, \"max\": 33868}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 478.0, \"count\": 1, \"min\": 478, \"max\": 478}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=253977.91817938493 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, batch=0 train rmse <loss>=0.7019763621292965\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, batch=0 train mse <loss>=0.49277081298828124\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, batch=0 train absolute_loss <loss>=0.5412564086914062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:17.970] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 956, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, train rmse <loss>=0.7815003100877702\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, train mse <loss>=0.610742734667281\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=477, train absolute_loss <loss>=0.5845135076818332\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.7005105, \"EndTime\": 1716353177.9706354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.36936378479004, \"count\": 1, \"min\": 269.36936378479004, \"max\": 269.36936378479004}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #progress_metric: host=algo-1, completed 95.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.701241, \"EndTime\": 1716353177.9708824, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 477, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33740630.0, \"count\": 1, \"min\": 33740630, \"max\": 33740630}, \"Total Batches Seen\": {\"sum\": 33939.0, \"count\": 1, \"min\": 33939, \"max\": 33939}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 479.0, \"count\": 1, \"min\": 479, \"max\": 479}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261661.15851955555 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, batch=0 train rmse <loss>=0.7018195781073963\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, batch=0 train mse <loss>=0.49255072021484375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:17 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, batch=0 train absolute_loss <loss>=0.5411236572265625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:18.245] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 958, \"duration\": 272, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, train rmse <loss>=0.7813436563580624\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, train mse <loss>=0.6104979093309859\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=478, train absolute_loss <loss>=0.5843819743411641\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.970711, \"EndTime\": 1716353178.2459219, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.3868827819824, \"count\": 1, \"min\": 274.3868827819824, \"max\": 274.3868827819824}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 95.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353177.9715135, \"EndTime\": 1716353178.246138, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 478, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33811215.0, \"count\": 1, \"min\": 33811215, \"max\": 33811215}, \"Total Batches Seen\": {\"sum\": 34010.0, \"count\": 1, \"min\": 34010, \"max\": 34010}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 480.0, \"count\": 1, \"min\": 480, \"max\": 480}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=256925.2346090428 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, batch=0 train rmse <loss>=0.7016627590526707\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, batch=0 train mse <loss>=0.49233062744140627\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, batch=0 train absolute_loss <loss>=0.5409945678710938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:18.518] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 960, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, train rmse <loss>=0.7811869778167656\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, train mse <loss>=0.6102530943104919\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=479, train absolute_loss <loss>=0.5842502458599251\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.2459989, \"EndTime\": 1716353178.5191748, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.48477935791016, \"count\": 1, \"min\": 272.48477935791016, \"max\": 272.48477935791016}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 96.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.246667, \"EndTime\": 1716353178.519323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 479, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33881800.0, \"count\": 1, \"min\": 33881800, \"max\": 33881800}, \"Total Batches Seen\": {\"sum\": 34081.0, \"count\": 1, \"min\": 34081, \"max\": 34081}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 481.0, \"count\": 1, \"min\": 481, \"max\": 481}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=258757.85008639685 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, batch=0 train rmse <loss>=0.7015059484445766\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, batch=0 train mse <loss>=0.492110595703125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, batch=0 train absolute_loss <loss>=0.5408657836914063\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:18.780] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 962, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, train rmse <loss>=0.7810303448912918\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, train mse <loss>=0.6100083996410102\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=480, train absolute_loss <loss>=0.5841184847119828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.5192335, \"EndTime\": 1716353178.7815144, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.533260345459, \"count\": 1, \"min\": 261.533260345459, \"max\": 261.533260345459}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #progress_metric: host=algo-1, completed 96.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.519958, \"EndTime\": 1716353178.7817116, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 480, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33952385.0, \"count\": 1, \"min\": 33952385, \"max\": 33952385}, \"Total Batches Seen\": {\"sum\": 34152.0, \"count\": 1, \"min\": 34152, \"max\": 34152}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 482.0, \"count\": 1, \"min\": 482, \"max\": 482}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269564.32271786954 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, batch=0 train rmse <loss>=0.7013490592634224\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, batch=0 train mse <loss>=0.4918905029296875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:18 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, batch=0 train absolute_loss <loss>=0.540737060546875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:19.043] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 964, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, train rmse <loss>=0.7808736835747533\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, train mse <loss>=0.6097637096996039\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=481, train absolute_loss <loss>=0.583986738178092\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.781597, \"EndTime\": 1716353179.044342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.4335289001465, \"count\": 1, \"min\": 262.4335289001465, \"max\": 262.4335289001465}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 96.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353178.781885, \"EndTime\": 1716353179.0445292, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 481, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34022970.0, \"count\": 1, \"min\": 34022970, \"max\": 34022970}, \"Total Batches Seen\": {\"sum\": 34223.0, \"count\": 1, \"min\": 34223, \"max\": 34223}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 483.0, \"count\": 1, \"min\": 483, \"max\": 483}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268642.89543292025 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, batch=0 train rmse <loss>=0.7011922002625132\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, batch=0 train mse <loss>=0.49167050170898435\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, batch=0 train absolute_loss <loss>=0.5406095581054687\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-22 04:46:19.327] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 966, \"duration\": 281, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, train rmse <loss>=0.7807170516579821\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, train mse <loss>=0.6095191147495324\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=482, train absolute_loss <loss>=0.5838550354863556\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.0444057, \"EndTime\": 1716353179.328327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.56361389160156, \"count\": 1, \"min\": 283.56361389160156, \"max\": 283.56361389160156}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 96.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.0447423, \"EndTime\": 1716353179.328537, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 482, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34093555.0, \"count\": 1, \"min\": 34093555, \"max\": 34093555}, \"Total Batches Seen\": {\"sum\": 34294.0, \"count\": 1, \"min\": 34294, \"max\": 34294}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 484.0, \"count\": 1, \"min\": 484, \"max\": 484}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=248625.21317334694 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, batch=0 train rmse <loss>=0.7010352408656407\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, batch=0 train mse <loss>=0.49145040893554687\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, batch=0 train absolute_loss <loss>=0.5404859619140625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:19.588] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 968, \"duration\": 258, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, train rmse <loss>=0.7805604213502412\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, train mse <loss>=0.6092745713784661\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=483, train absolute_loss <loss>=0.5837235064439371\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.3283865, \"EndTime\": 1716353179.5893478, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 260.56623458862305, \"count\": 1, \"min\": 260.56623458862305, \"max\": 260.56623458862305}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 96.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.3287609, \"EndTime\": 1716353179.5895007, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 483, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34164140.0, \"count\": 1, \"min\": 34164140, \"max\": 34164140}, \"Total Batches Seen\": {\"sum\": 34365.0, \"count\": 1, \"min\": 34365, \"max\": 34365}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 485.0, \"count\": 1, \"min\": 485, \"max\": 485}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=270618.9330817776 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, batch=0 train rmse <loss>=0.7008782680891793\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, batch=0 train mse <loss>=0.4912303466796875\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, batch=0 train absolute_loss <loss>=0.5403619995117187\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:19.862] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 970, \"duration\": 271, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, train rmse <loss>=0.7804037921017267\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, train mse <loss>=0.6090300787267551\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=484, train absolute_loss <loss>=0.5835919516120158\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.589407, \"EndTime\": 1716353179.8630486, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.3592987060547, \"count\": 1, \"min\": 273.3592987060547, \"max\": 273.3592987060547}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #progress_metric: host=algo-1, completed 97.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.5896666, \"EndTime\": 1716353179.8632352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 484, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34234725.0, \"count\": 1, \"min\": 34234725, \"max\": 34234725}, \"Total Batches Seen\": {\"sum\": 34436.0, \"count\": 1, \"min\": 34436, \"max\": 34436}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 486.0, \"count\": 1, \"min\": 486, \"max\": 486}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=257930.04931996643 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, batch=0 train rmse <loss>=0.7007212383724715\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, batch=0 train mse <loss>=0.49101025390625\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:19 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, batch=0 train absolute_loss <loss>=0.5402376708984375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:20.134] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 972, \"duration\": 269, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, train rmse <loss>=0.7802471272793436\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, train mse <loss>=0.6087855796276683\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=485, train absolute_loss <loss>=0.583460263534331\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.8631334, \"EndTime\": 1716353180.1353414, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 271.9147205352783, \"count\": 1, \"min\": 271.9147205352783, \"max\": 271.9147205352783}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 97.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353179.8634048, \"EndTime\": 1716353180.13549, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 485, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34305310.0, \"count\": 1, \"min\": 34305310, \"max\": 34305310}, \"Total Batches Seen\": {\"sum\": 34507.0, \"count\": 1, \"min\": 34507, \"max\": 34507}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 487.0, \"count\": 1, \"min\": 487, \"max\": 487}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=259340.6155743679 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, batch=0 train rmse <loss>=0.7005641952386595\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, batch=0 train mse <loss>=0.4907901916503906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, batch=0 train absolute_loss <loss>=0.5401130981445312\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:20.430] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 974, \"duration\": 292, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, train rmse <loss>=0.7800904808590569\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, train mse <loss>=0.6085411583269146\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=486, train absolute_loss <loss>=0.5833285685794454\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.1353989, \"EndTime\": 1716353180.4308388, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 295.1626777648926, \"count\": 1, \"min\": 295.1626777648926, \"max\": 295.1626777648926}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 97.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.1356518, \"EndTime\": 1716353180.4310744, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 486, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34375895.0, \"count\": 1, \"min\": 34375895, \"max\": 34375895}, \"Total Batches Seen\": {\"sum\": 34578.0, \"count\": 1, \"min\": 34578, \"max\": 34578}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 488.0, \"count\": 1, \"min\": 488, \"max\": 488}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=238846.0614979 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, batch=0 train rmse <loss>=0.7004070733219183\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, batch=0 train mse <loss>=0.490570068359375\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, batch=0 train absolute_loss <loss>=0.5399881591796875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:20.709] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 976, \"duration\": 276, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, train rmse <loss>=0.7799338148257439\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, train mse <loss>=0.6082967555086377\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=487, train absolute_loss <loss>=0.5831968641684089\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.4309087, \"EndTime\": 1716353180.710107, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.79858016967773, \"count\": 1, \"min\": 278.79858016967773, \"max\": 278.79858016967773}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 97.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.4312842, \"EndTime\": 1716353180.710311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 487, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34446480.0, \"count\": 1, \"min\": 34446480, \"max\": 34446480}, \"Total Batches Seen\": {\"sum\": 34649.0, \"count\": 1, \"min\": 34649, \"max\": 34649}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 489.0, \"count\": 1, \"min\": 489, \"max\": 489}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=252868.54116807 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, batch=0 train rmse <loss>=0.700249916150198\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, batch=0 train mse <loss>=0.4903499450683594\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, batch=0 train absolute_loss <loss>=0.5398628540039062\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:20.997] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 978, \"duration\": 285, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, train rmse <loss>=0.7797771131823409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, train mse <loss>=0.6080523462429852\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #quality_metric: host=algo-1, epoch=488, train absolute_loss <loss>=0.5830650909853653\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.7101808, \"EndTime\": 1716353180.9982328, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.66846656799316, \"count\": 1, \"min\": 287.66846656799316, \"max\": 287.66846656799316}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #progress_metric: host=algo-1, completed 97.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.710539, \"EndTime\": 1716353180.998467, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 488, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34517065.0, \"count\": 1, \"min\": 34517065, \"max\": 34517065}, \"Total Batches Seen\": {\"sum\": 34720.0, \"count\": 1, \"min\": 34720, \"max\": 34720}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 490.0, \"count\": 1, \"min\": 490, \"max\": 490}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:20 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=245046.75124176743 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, batch=0 train rmse <loss>=0.7000927236997566\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, batch=0 train mse <loss>=0.49012982177734377\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, batch=0 train absolute_loss <loss>=0.5397371826171875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:21.259] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 980, \"duration\": 259, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, train rmse <loss>=0.7796204332452853\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, train mse <loss>=0.6078080199335663\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=489, train absolute_loss <loss>=0.5829333453111245\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.9983075, \"EndTime\": 1716353181.2603965, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 261.68227195739746, \"count\": 1, \"min\": 261.68227195739746, \"max\": 261.68227195739746}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 98.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353180.9986916, \"EndTime\": 1716353181.2605512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 489, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34587650.0, \"count\": 1, \"min\": 34587650, \"max\": 34587650}, \"Total Batches Seen\": {\"sum\": 34791.0, \"count\": 1, \"min\": 34791, \"max\": 34791}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 491.0, \"count\": 1, \"min\": 491, \"max\": 491}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=269455.14435473375 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, batch=0 train rmse <loss>=0.6999354523462659\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, batch=0 train mse <loss>=0.4899096374511719\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, batch=0 train absolute_loss <loss>=0.5396116943359375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:21.530] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 982, \"duration\": 267, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, train rmse <loss>=0.779463706098058\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, train mse <loss>=0.6075636691241197\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=490, train absolute_loss <loss>=0.5828015781456316\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.2604566, \"EndTime\": 1716353181.5306976, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.9594497680664, \"count\": 1, \"min\": 269.9594497680664, \"max\": 269.9594497680664}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 98.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.260717, \"EndTime\": 1716353181.530846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 490, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34658235.0, \"count\": 1, \"min\": 34658235, \"max\": 34658235}, \"Total Batches Seen\": {\"sum\": 34862.0, \"count\": 1, \"min\": 34862, \"max\": 34862}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 492.0, \"count\": 1, \"min\": 492, \"max\": 492}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261216.73333221572 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, batch=0 train rmse <loss>=0.69977814564689\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, batch=0 train mse <loss>=0.489689453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, batch=0 train absolute_loss <loss>=0.5394896240234375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:21.796] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 984, \"duration\": 263, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, train rmse <loss>=0.7793069471555147\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, train mse <loss>=0.6073193178848482\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=491, train absolute_loss <loss>=0.5826696803133252\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.5307534, \"EndTime\": 1716353181.7974226, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.176700592041, \"count\": 1, \"min\": 266.176700592041, \"max\": 266.176700592041}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #progress_metric: host=algo-1, completed 98.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.531223, \"EndTime\": 1716353181.7976298, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 491, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34728820.0, \"count\": 1, \"min\": 34728820, \"max\": 34728820}, \"Total Batches Seen\": {\"sum\": 34933.0, \"count\": 1, \"min\": 34933, \"max\": 34933}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 493.0, \"count\": 1, \"min\": 493, \"max\": 493}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264834.6502595077 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, batch=0 train rmse <loss>=0.6996207599576157\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, batch=0 train mse <loss>=0.48946920776367187\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:21 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, batch=0 train absolute_loss <loss>=0.5393671875\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:22.059] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 986, \"duration\": 260, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, train rmse <loss>=0.7791501820505984\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, train mse <loss>=0.6070750061894806\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=492, train absolute_loss <loss>=0.5825377412178147\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.7974854, \"EndTime\": 1716353182.0604725, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 262.5749111175537, \"count\": 1, \"min\": 262.5749111175537, \"max\": 262.5749111175537}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 98.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353181.7978752, \"EndTime\": 1716353182.0607064, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 492, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34799405.0, \"count\": 1, \"min\": 34799405, \"max\": 34799405}, \"Total Batches Seen\": {\"sum\": 35004.0, \"count\": 1, \"min\": 35004, \"max\": 35004}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 494.0, \"count\": 1, \"min\": 494, \"max\": 494}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=268436.09490718914 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, batch=0 train rmse <loss>=0.6994633170401188\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, batch=0 train mse <loss>=0.48924893188476565\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, batch=0 train absolute_loss <loss>=0.5392443237304687\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:22.346] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 988, \"duration\": 283, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, train rmse <loss>=0.7789933564302609\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, train mse <loss>=0.6068306493624835\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=493, train absolute_loss <loss>=0.5824057170169454\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.0605526, \"EndTime\": 1716353182.3472755, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.09657287597656, \"count\": 1, \"min\": 286.09657287597656, \"max\": 286.09657287597656}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 98.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.0611546, \"EndTime\": 1716353182.3475354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 493, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34869990.0, \"count\": 1, \"min\": 34869990, \"max\": 34869990}, \"Total Batches Seen\": {\"sum\": 35075.0, \"count\": 1, \"min\": 35075, \"max\": 35075}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 495.0, \"count\": 1, \"min\": 495, \"max\": 495}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=246378.40847450998 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, batch=0 train rmse <loss>=0.6993057732159266\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, batch=0 train mse <loss>=0.489028564453125\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, batch=0 train absolute_loss <loss>=0.53912109375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:22.612] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 990, \"duration\": 262, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, train rmse <loss>=0.7788365202031744\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, train mse <loss>=0.6065863252021897\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=494, train absolute_loss <loss>=0.5822736592897227\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.3473823, \"EndTime\": 1716353182.613061, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 265.1183605194092, \"count\": 1, \"min\": 265.1183605194092, \"max\": 265.1183605194092}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 99.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.3479195, \"EndTime\": 1716353182.6132188, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 494, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34940575.0, \"count\": 1, \"min\": 34940575, \"max\": 34940575}, \"Total Batches Seen\": {\"sum\": 35146.0, \"count\": 1, \"min\": 35146, \"max\": 35146}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 496.0, \"count\": 1, \"min\": 496, \"max\": 496}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=265967.8650427671 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, batch=0 train rmse <loss>=0.6991481720664843\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, batch=0 train mse <loss>=0.48880816650390624\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, batch=0 train absolute_loss <loss>=0.5389974365234375\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:22.880] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 992, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, train rmse <loss>=0.7786796156797512\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, train mse <loss>=0.606341943875165\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=495, train absolute_loss <loss>=0.5821415353694432\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.6131203, \"EndTime\": 1716353182.8809404, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.2924995422363, \"count\": 1, \"min\": 267.2924995422363, \"max\": 267.2924995422363}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #progress_metric: host=algo-1, completed 99.2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.613626, \"EndTime\": 1716353182.881096, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 495, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35011160.0, \"count\": 1, \"min\": 35011160, \"max\": 35011160}, \"Total Batches Seen\": {\"sum\": 35217.0, \"count\": 1, \"min\": 35217, \"max\": 35217}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 497.0, \"count\": 1, \"min\": 497, \"max\": 497}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263809.74635301705 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, batch=0 train rmse <loss>=0.6989905135530162\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, batch=0 train mse <loss>=0.48858773803710936\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:22 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, batch=0 train absolute_loss <loss>=0.5388734741210938\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:23.149] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 994, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, train rmse <loss>=0.778522713763989\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, train mse <loss>=0.6060976158464458\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=496, train absolute_loss <loss>=0.5820093822210607\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.8809996, \"EndTime\": 1716353183.1496468, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 268.36156845092773, \"count\": 1, \"min\": 268.36156845092773, \"max\": 268.36156845092773}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 99.4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353182.8812633, \"EndTime\": 1716353183.1497967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 496, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35081745.0, \"count\": 1, \"min\": 35081745, \"max\": 35081745}, \"Total Batches Seen\": {\"sum\": 35288.0, \"count\": 1, \"min\": 35288, \"max\": 35288}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 498.0, \"count\": 1, \"min\": 498, \"max\": 498}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=262766.6211999105 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, batch=0 train rmse <loss>=0.6988327539673409\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, batch=0 train mse <loss>=0.4883672180175781\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, batch=0 train absolute_loss <loss>=0.5387490844726562\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:23.417] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 996, \"duration\": 265, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, train rmse <loss>=0.7783657313491479\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, train mse <loss>=0.6058532117386939\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=497, train absolute_loss <loss>=0.5818771517041703\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.149703, \"EndTime\": 1716353183.4175816, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 267.58790016174316, \"count\": 1, \"min\": 267.58790016174316, \"max\": 267.58790016174316}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 99.6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.1499724, \"EndTime\": 1716353183.4177446, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 497, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35152330.0, \"count\": 1, \"min\": 35152330, \"max\": 35152330}, \"Total Batches Seen\": {\"sum\": 35359.0, \"count\": 1, \"min\": 35359, \"max\": 35359}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 499.0, \"count\": 1, \"min\": 499, \"max\": 499}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=263508.95660919795 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, batch=0 train rmse <loss>=0.698674915080605\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, batch=0 train mse <loss>=0.4881466369628906\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, batch=0 train absolute_loss <loss>=0.538624267578125\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:23.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 998, \"duration\": 264, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, train rmse <loss>=0.7782087012499214\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, train mse <loss>=0.6056087827010893\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=498, train absolute_loss <loss>=0.5817449383802817\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.4176366, \"EndTime\": 1716353183.6845555, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 266.62707328796387, \"count\": 1, \"min\": 266.62707328796387, \"max\": 266.62707328796387}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 99.8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.4179072, \"EndTime\": 1716353183.6847048, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 498, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35222915.0, \"count\": 1, \"min\": 35222915, \"max\": 35222915}, \"Total Batches Seen\": {\"sum\": 35430.0, \"count\": 1, \"min\": 35430, \"max\": 35430}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 500.0, \"count\": 1, \"min\": 500, \"max\": 500}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=264417.6414572781 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, batch=0 train rmse <loss>=0.6985169968390511\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, batch=0 train mse <loss>=0.4879259948730469\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, batch=0 train absolute_loss <loss>=0.5384996337890625\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:23.953] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1000, \"duration\": 266, \"num_examples\": 71, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, train rmse <loss>=0.7780516071405255\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, train mse <loss>=0.6053643033739546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, epoch=499, train absolute_loss <loss>=0.5816127603020467\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, train rmse <loss>=0.7780516071405255\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, train mse <loss>=0.6053643033739546\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #quality_metric: host=algo-1, train absolute_loss <loss>=0.5816127603020467\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.6846128, \"EndTime\": 1716353183.9544225, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 269.2224979400635, \"count\": 1, \"min\": 269.2224979400635, \"max\": 269.2224979400635}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.685174, \"EndTime\": 1716353183.9546483, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 499, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35293500.0, \"count\": 1, \"min\": 35293500, \"max\": 35293500}, \"Total Batches Seen\": {\"sum\": 35501.0, \"count\": 1, \"min\": 35501, \"max\": 35501}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Reset Count\": {\"sum\": 501.0, \"count\": 1, \"min\": 501, \"max\": 501}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] #throughput_metric: host=algo-1, train throughput=261831.9420256017 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 WARNING 140374101440320] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.954495, \"EndTime\": 1716353183.9582326, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 3.307342529296875, \"count\": 1, \"min\": 3.307342529296875, \"max\": 3.307342529296875}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:23 INFO 140374101440320] Saved checkpoint to \"/tmp/tmppwt1czkg/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:23.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 138999, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2024-05-22 04:46:24.029] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 66, \"num_examples\": 31, \"num_bytes\": 1936064}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.9627004, \"EndTime\": 1716353184.029736, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Total Batches Seen\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Max Records Seen Between Resets\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Max Batches Seen Between Resets\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Number of Batches Since Last Reset\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #test_score (algo-1) : ('rmse', 0.8710947856288073)\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #test_score (algo-1) : ('mse', 0.7588061255496977)\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #test_score (algo-1) : ('absolute_loss', 0.6717369228641847)\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #quality_metric: host=algo-1, test rmse <loss>=0.8710947856288073\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #quality_metric: host=algo-1, test mse <loss>=0.7588061255496977\u001b[0m\n",
      "\u001b[34m[05/22/2024 04:46:24 INFO 140374101440320] #quality_metric: host=algo-1, test absolute_loss <loss>=0.6717369228641847\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716353183.958282, \"EndTime\": 1716353184.0304656, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 15.820503234863281, \"count\": 1, \"min\": 15.820503234863281, \"max\": 15.820503234863281}, \"totaltime\": {\"sum\": 139088.36388587952, \"count\": 1, \"min\": 139088.36388587952, \"max\": 139088.36388587952}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-05-22 04:46:39 Uploading - Uploading generated training model\n",
      "2024-05-22 04:46:39 Completed - Training job completed\n",
      "Training seconds: 385\n",
      "Billable seconds: 172\n",
      "Managed Spot Training savings: 55.3%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':s3_training_file_location, 'test': s3_test_file_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e21ce",
   "metadata": {},
   "source": [
    "### Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a5cfbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: fm-movie-v1-2024-05-22-04-47-56-577\n",
      "INFO:sagemaker:Creating endpoint-config with name fm-movie-v1\n",
      "INFO:sagemaker:Creating endpoint with name fm-movie-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m5.xlarge',\n",
    "                             endpoint_name = job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3dfefc",
   "metadata": {},
   "source": [
    "### Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b307a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create libSVM formatted file. Convenient text format\n",
    "# Output is stored as rating, user_index:value, movie_index:value\n",
    "#  For example: 5.0 314:1 215:1  (user with index 314 and movie with index 215 in the one hot encoded table has a rating of 5 )\n",
    "\n",
    "# This file can be used for two purposes: \n",
    "#   1. directly traing with libFM binary in local mode\n",
    "#   2. It is easy to run inference with this format against sagemaker cloud as we need to\n",
    "#      send only sparse input to sagemaker prediction service\n",
    "\n",
    "# \n",
    "# Store in libSVM format as well for directly testing with libFM\n",
    "dump_svmlight_file(X[:train],y[:train],r'ml-latest-small/user_movie_train.svm')\n",
    "dump_svmlight_file(X[train:],y[train:],r'ml-latest-small/user_movie_test.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53cabf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "       \n",
    "        js['instances'].append({'data':{'features': { 'keys': column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e9bf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK 2\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0beeef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify custom serializer\n",
    "predictor.serializer.serialize = fm_sparse_serializer\n",
    "predictor.serializer.content_type = 'application/json'\n",
    "\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3efb6803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}]}'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fm_sparse_serializer([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff2fa4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ['4', '291:1', '1028:1']\n",
      "  Actual Rating:\t4\n",
      "  Predicted Rating:\t3.9805212020874023\n",
      "\n",
      "Movie ['4', '579:1', '2570:1']\n",
      "  Actual Rating:\t4\n",
      "  Predicted Rating:\t3.3526663780212402\n",
      "\n",
      "Movie ['4', '231:1', '3822:1']\n",
      "  Actual Rating:\t4\n",
      "  Predicted Rating:\t3.0857391357421875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test with few entries from test file\n",
    "# Movie dataset is updated regularly...so, instead of hard coding userid and movie id, let's\n",
    "# use actual values\n",
    "\n",
    "# Each row is in this format: ['2.5', '426:1', '943:1']\n",
    "# ActualRating, UserID, MovieID\n",
    "\n",
    "with open(r'ml-latest-small/user_movie_test.svm','r') as f:\n",
    "    for i in range(3):\n",
    "        rating = f.readline().split()\n",
    "        print(f\"Movie {rating}\")\n",
    "        userID = rating[1].split(':')[0]\n",
    "        movieID = rating[2].split(':')[0]\n",
    "        predicted_rating = predictor.predict([np.array([int(userID),int(movieID)])])\n",
    "        print(f'  Actual Rating:\\t{rating[0]}')\n",
    "        print(f\"  Predicted Rating:\\t{predicted_rating['predictions'][0]['score']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2dcbca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictor and point to an existing endpoint\n",
    "\n",
    "endpoint_name = 'fm-movie-v1'\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06e58f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom serializer\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "       \n",
    "        js['instances'].append({'data':{'features': { 'keys': column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baf05b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify custom serializer\n",
    "predictor.serializer.serialize = fm_sparse_serializer\n",
    "predictor.serializer.content_type = 'application/json'\n",
    "\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d66c7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dimension: Number of unique users + Number of unique movies in our dataset\n",
    "dim_movie = 0\n",
    "\n",
    "# Update movie dimension - from file used for training \n",
    "with open(r'ml-latest-small/movie_dimension.txt','r') as f:\n",
    "    dim_movie = int(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "469f2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}, {\"data\": {\"features\": {\"keys\": [209, 2640], \"shape\": [10334], \"values\": [1, 1]}}}, {\"data\": {\"features\": {\"keys\": [164, 1346], \"shape\": [10334], \"values\": [1, 1]}}}]}\n"
     ]
    }
   ],
   "source": [
    "print(fm_sparse_serializer([np.array([341,1416]),np.array([209,2640]),np.array([164,1346])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ea79bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test libSVM\n",
    "# Load the test file in svm format. '5 341:1 1416:1'\n",
    "test_file = r'ml-latest-small/user_movie_test.svm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4ee52c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_index</th>\n",
       "      <th>movie_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>291:1</td>\n",
       "      <td>1028:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>579:1</td>\n",
       "      <td>2570:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>231:1</td>\n",
       "      <td>3822:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>17:1</td>\n",
       "      <td>3598:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>413:1</td>\n",
       "      <td>4894:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30246</th>\n",
       "      <td>2.0</td>\n",
       "      <td>386:1</td>\n",
       "      <td>1609:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30247</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38:1</td>\n",
       "      <td>2152:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30248</th>\n",
       "      <td>3.0</td>\n",
       "      <td>134:1</td>\n",
       "      <td>1884:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30249</th>\n",
       "      <td>3.5</td>\n",
       "      <td>118:1</td>\n",
       "      <td>7429:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30250</th>\n",
       "      <td>3.0</td>\n",
       "      <td>239:1</td>\n",
       "      <td>1086:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating user_index movie_index\n",
       "0         4.0      291:1      1028:1\n",
       "1         4.0      579:1      2570:1\n",
       "2         4.0      231:1      3822:1\n",
       "3         4.0       17:1      3598:1\n",
       "4         4.0      413:1      4894:1\n",
       "...       ...        ...         ...\n",
       "30246     2.0      386:1      1609:1\n",
       "30247     3.0       38:1      2152:1\n",
       "30248     3.0      134:1      1884:1\n",
       "30249     3.5      118:1      7429:1\n",
       "30250     3.0      239:1      1086:1\n",
       "\n",
       "[30251 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(test_file, sep=' ', names=['rating','user_index','movie_index'])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9e9bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update column to contain only the one hot encoded index\n",
    "df_test.user_index = df_test.user_index.map(lambda value: int(value.split(':')[0]))\n",
    "df_test.movie_index = df_test.movie_index.map(lambda value: int(value.split(':')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c70affff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30251, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16dac57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large number of predictions, we can split the input data and\n",
    "# Query the prediction service.\n",
    "# array_split is convenient to specify how many splits are needed\n",
    "def get_predictions(predictor, arr_features):\n",
    "    predictions = []\n",
    "    for arr in np.array_split(arr_features,100):        \n",
    "        if arr.shape[0] > 0:\n",
    "            print (arr.shape, end=' ')\n",
    "            result = predictor.predict(arr)\n",
    "            predictions += [values['score'] for values in result['predictions']]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "202c5fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (303, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) (302, 2) CPU times: user 502 ms, sys: 13 ms, total: 515 ms\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "# %time predictions = get_predictions(predictor_sparse, df_test[['user_index','movie_index']].as_matrix())\n",
    "%time predictions = get_predictions(predictor, df_test[['user_index','movie_index']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99fadcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
